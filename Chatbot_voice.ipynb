{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chatbot_voice","provenance":[],"mount_file_id":"1-UAGXxdUIcNEQlxF0BtvE3GIceL27bnL","authorship_tag":"ABX9TyOgQ6eZySHUv5R940gL/fpw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1d7kyV5XV3tq","colab_type":"code","cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596892845456,"user_tz":-180,"elapsed":1200,"user":{"displayName":"Mohammed Buallay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5kKjTotsiVfFyh_UBKjF5IzlejzIE4inAGqASEA=s64","userId":"12854686241086794145"}},"outputId":"973d99f6-b677-444e-b814-2c22dcbe68c4"},"source":["#@title After exciting this cell you Have to connect it with You Google Drive. \n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"evCzI3JvMPUV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1596892869282,"user_tz":-180,"elapsed":7535,"user":{"displayName":"Mohammed Buallay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5kKjTotsiVfFyh_UBKjF5IzlejzIE4inAGqASEA=s64","userId":"12854686241086794145"}},"outputId":"b07796fd-4b7d-4526-c8a4-45a47390f2e2"},"source":["import os\n","Main_folder_path = \"trump_public\" #@param {type:\"string\"}\n","os.chdir(os.path.join(\"/content/drive/My Drive\",Main_folder_path)) ##cd \n","\n","%tensorflow_version 1.x \n","\n","!pip install unidecode"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 7.0MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NUDVxCKLHMy_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1596893778277,"user_tz":-180,"elapsed":102667,"user":{"displayName":"Mohammed Buallay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5kKjTotsiVfFyh_UBKjF5IzlejzIE4inAGqASEA=s64","userId":"12854686241086794145"}},"outputId":"72b8686d-d93f-42c1-b44d-c9a2869a69c0"},"source":["!python preprocess.py --base_dir /content/drive/My*Drive/trump_public --output training --dataset_folder_dir mohd_voice"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","  0% 0/161 [00:00<?, ?it/s]Traceback (most recent call last):\n","  File \"preprocess.py\", line 37, in <module>\n","    main()\n","  File \"preprocess.py\", line 33, in main\n","    preprocess_trump(args)\n","  File \"preprocess.py\", line 12, in preprocess_trump\n","    metadata = trump.build_from_path(in_dir, out_dir, args.num_workers, tqdm=tqdm)\n","  File \"/content/drive/My Drive/trump_public/datasets/trump.py\", line 32, in build_from_path\n","    return [future.result() for future in tqdm(futures)]\n","  File \"/content/drive/My Drive/trump_public/datasets/trump.py\", line 32, in <listcomp>\n","    return [future.result() for future in tqdm(futures)]\n","  File \"/usr/lib/python3.6/concurrent/futures/_base.py\", line 427, in result\n","    self._condition.wait(timeout)\n","  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n","    waiter.acquire()\n","KeyboardInterrupt\n","  0% 0/161 [01:34<?, ?it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XSuarMxxRF8E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"69b7ebb2-5604-49e9-8765-68f2d61811f5"},"source":["!python train.py --base_dir /content/drive/My*Drive/trump_public --restore_step 488000"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Checkpoint path: /content/drive/My Drive/trump_public/logs-tacotron/model.ckpt\n","Loading training data from: /content/drive/My Drive/trump_public/training/train.txt\n","Using model: tacotron\n","Hyperparameters:\n","  adam_beta1: 0.9\n","  adam_beta2: 0.999\n","  attention_depth: 256\n","  batch_size: 16\n","  cleaners: english_cleaners\n","  decay_learning_rate: True\n","  decoder_depth: 256\n","  embed_depth: 256\n","  encoder_depth: 256\n","  frame_length_ms: 50\n","  frame_shift_ms: 12.5\n","  griffin_lim_iters: 60\n","  initial_learning_rate: 0.002\n","  max_iters: 800\n","  min_level_db: -100\n","  num_freq: 1025\n","  num_mels: 80\n","  outputs_per_step: 5\n","  postnet_depth: 256\n","  power: 1.5\n","  preemphasis: 0.97\n","  prenet_depths: [256, 128]\n","  ref_level_db: 20\n","  sample_rate: 20000\n","  use_cmudict: False\n","WARNING:tensorflow:From train.py:56: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","Loaded metadata for 161 examples (0.65 hours)\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/datasets/datafeeder.py:37: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/datasets/datafeeder.py:44: The name tf.FIFOQueue is deprecated. Please use tf.queue.FIFOQueue instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/tacotron.py:40: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:10: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:11: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dropout instead.\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:106: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv1D` instead.\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:107: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:52: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.MaxPooling1D instead.\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:75: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:79: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/tacotron.py:68: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:Entity <bound method ConcatOutputAndAttentionWrapper.call of <models.rnn_wrappers.ConcatOutputAndAttentionWrapper object at 0x7f21a547aa58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method DecoderPrenetWrapper.call of <models.rnn_wrappers.DecoderPrenetWrapper object at 0x7f21a55cce10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","Initialized Tacotron model. Dimensions: \n","  embedding:               256\n","  prenet out:              128\n","  encoder out:             256\n","  attention out:           256\n","  concat attn & out:       512\n","  decoder cell out:        256\n","  decoder out (5 frames):  400\n","  decoder out (1 frame):   80\n","  postnet out:             256\n","  linear out:              1025\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/tacotron.py:138: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/tacotron.py:145: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/tacotron.py:145: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From train.py:27: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n","\n","WARNING:tensorflow:From train.py:31: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","WARNING:tensorflow:From train.py:38: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From train.py:72: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From train.py:75: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-08-03 11:09:31.915641: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","WARNING:tensorflow:From train.py:77: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","WARNING:tensorflow:From train.py:78: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","Resuming from checkpoint: /content/drive/My Drive/trump_public/logs-tacotron/model.ckpt-488000 at commit: None\n","Generated 32 batches of size 16 in 391.554 sec\n","Step 488001  [397.179 sec/step, loss=0.07484, avg_loss=0.07484]\n","Step 488002  [201.487 sec/step, loss=0.07734, avg_loss=0.07609]\n","Step 488003  [136.810 sec/step, loss=0.07791, avg_loss=0.07670]\n","Step 488004  [103.995 sec/step, loss=0.07849, avg_loss=0.07715]\n","Step 488005  [84.191 sec/step, loss=0.07410, avg_loss=0.07654]\n","Step 488006  [71.955 sec/step, loss=0.08055, avg_loss=0.07720]\n","Step 488007  [62.393 sec/step, loss=0.07656, avg_loss=0.07711]\n","Step 488008  [55.287 sec/step, loss=0.06913, avg_loss=0.07612]\n","Step 488009  [49.873 sec/step, loss=0.07919, avg_loss=0.07646]\n","Step 488010  [45.306 sec/step, loss=0.07736, avg_loss=0.07655]\n","Step 488011  [41.875 sec/step, loss=0.07969, avg_loss=0.07683]\n","Step 488012  [38.743 sec/step, loss=0.07571, avg_loss=0.07674]\n","Step 488013  [36.253 sec/step, loss=0.07782, avg_loss=0.07682]\n","Step 488014  [34.002 sec/step, loss=0.07688, avg_loss=0.07683]\n","Step 488015  [32.024 sec/step, loss=0.06653, avg_loss=0.07614]\n","Step 488016  [30.360 sec/step, loss=0.07762, avg_loss=0.07623]\n","Step 488017  [28.882 sec/step, loss=0.06425, avg_loss=0.07553]\n","Step 488018  [27.617 sec/step, loss=0.07117, avg_loss=0.07529]\n","Step 488019  [26.362 sec/step, loss=0.07263, avg_loss=0.07515]\n","Step 488020  [25.528 sec/step, loss=0.07407, avg_loss=0.07509]\n","Step 488021  [24.645 sec/step, loss=0.07979, avg_loss=0.07532]\n","Step 488022  [24.140 sec/step, loss=0.07844, avg_loss=0.07546]\n","Step 488023  [23.325 sec/step, loss=0.06834, avg_loss=0.07515]\n","Step 488024  [22.617 sec/step, loss=0.07268, avg_loss=0.07505]\n","Generated 32 batches of size 16 in 9.732 sec\n","Step 488025  [21.937 sec/step, loss=0.07489, avg_loss=0.07504]\n","Step 488026  [21.324 sec/step, loss=0.07001, avg_loss=0.07485]\n","Step 488027  [20.728 sec/step, loss=0.07773, avg_loss=0.07495]\n","Step 488028  [20.265 sec/step, loss=0.08022, avg_loss=0.07514]\n","Step 488029  [19.802 sec/step, loss=0.07995, avg_loss=0.07531]\n","Step 488030  [19.424 sec/step, loss=0.08059, avg_loss=0.07548]\n","Step 488031  [18.971 sec/step, loss=0.07716, avg_loss=0.07554]\n","Step 488032  [18.483 sec/step, loss=0.07355, avg_loss=0.07548]\n","Step 488033  [18.051 sec/step, loss=0.07327, avg_loss=0.07541]\n","Step 488034  [17.728 sec/step, loss=0.07848, avg_loss=0.07550]\n","Step 488035  [17.363 sec/step, loss=0.07715, avg_loss=0.07555]\n","Step 488036  [16.920 sec/step, loss=0.06714, avg_loss=0.07531]\n","Step 488037  [16.546 sec/step, loss=0.07337, avg_loss=0.07526]\n","Step 488038  [16.171 sec/step, loss=0.06397, avg_loss=0.07496]\n","Step 488039  [15.842 sec/step, loss=0.07488, avg_loss=0.07496]\n","Step 488040  [15.611 sec/step, loss=0.07343, avg_loss=0.07492]\n","Step 488041  [15.326 sec/step, loss=0.07434, avg_loss=0.07491]\n","Step 488042  [15.092 sec/step, loss=0.07878, avg_loss=0.07500]\n","Step 488043  [14.832 sec/step, loss=0.07735, avg_loss=0.07506]\n","Step 488044  [14.659 sec/step, loss=0.08072, avg_loss=0.07518]\n","Step 488045  [14.398 sec/step, loss=0.07081, avg_loss=0.07509]\n","Step 488046  [14.190 sec/step, loss=0.07738, avg_loss=0.07514]\n","Step 488047  [14.068 sec/step, loss=0.07933, avg_loss=0.07523]\n","Step 488048  [13.971 sec/step, loss=0.07925, avg_loss=0.07531]\n","Step 488049  [13.783 sec/step, loss=0.07856, avg_loss=0.07538]\n","Step 488050  [13.627 sec/step, loss=0.07983, avg_loss=0.07547]\n","Step 488051  [13.407 sec/step, loss=0.07352, avg_loss=0.07543]\n","Step 488052  [13.185 sec/step, loss=0.06920, avg_loss=0.07531]\n","Step 488053  [13.054 sec/step, loss=0.07793, avg_loss=0.07536]\n","Step 488054  [12.962 sec/step, loss=0.07913, avg_loss=0.07543]\n","Step 488055  [12.847 sec/step, loss=0.07891, avg_loss=0.07549]\n","Step 488056  [12.668 sec/step, loss=0.06613, avg_loss=0.07532]\n","Generated 32 batches of size 16 in 8.966 sec\n","Step 488057  [12.577 sec/step, loss=0.07579, avg_loss=0.07533]\n","Step 488058  [12.490 sec/step, loss=0.08000, avg_loss=0.07541]\n","Step 488059  [12.336 sec/step, loss=0.07511, avg_loss=0.07541]\n","Step 488060  [12.222 sec/step, loss=0.07738, avg_loss=0.07544]\n","Step 488061  [12.217 sec/step, loss=0.07758, avg_loss=0.07547]\n","Step 488062  [12.092 sec/step, loss=0.07747, avg_loss=0.07551]\n","Step 488063  [12.001 sec/step, loss=0.07836, avg_loss=0.07555]\n","Step 488064  [11.892 sec/step, loss=0.07788, avg_loss=0.07559]\n","Step 488065  [11.751 sec/step, loss=0.07399, avg_loss=0.07556]\n","Step 488066  [11.669 sec/step, loss=0.07931, avg_loss=0.07562]\n","Step 488067  [11.568 sec/step, loss=0.06729, avg_loss=0.07550]\n","Step 488068  [11.435 sec/step, loss=0.07209, avg_loss=0.07545]\n","Step 488069  [11.345 sec/step, loss=0.07789, avg_loss=0.07548]\n","Step 488070  [11.219 sec/step, loss=0.07359, avg_loss=0.07545]\n","Step 488071  [11.117 sec/step, loss=0.07643, avg_loss=0.07547]\n","Step 488072  [10.996 sec/step, loss=0.07082, avg_loss=0.07540]\n","Step 488073  [10.946 sec/step, loss=0.07893, avg_loss=0.07545]\n","Step 488074  [10.889 sec/step, loss=0.07865, avg_loss=0.07550]\n","Step 488075  [10.770 sec/step, loss=0.06791, avg_loss=0.07539]\n","Step 488076  [10.770 sec/step, loss=0.07816, avg_loss=0.07543]\n","Step 488077  [10.645 sec/step, loss=0.06693, avg_loss=0.07532]\n","Step 488078  [10.573 sec/step, loss=0.07686, avg_loss=0.07534]\n","Step 488079  [10.508 sec/step, loss=0.08056, avg_loss=0.07541]\n","Step 488080  [10.435 sec/step, loss=0.07819, avg_loss=0.07544]\n","Step 488081  [10.451 sec/step, loss=0.07956, avg_loss=0.07549]\n","Step 488082  [10.406 sec/step, loss=0.07943, avg_loss=0.07554]\n","Step 488083  [10.353 sec/step, loss=0.07936, avg_loss=0.07559]\n","Step 488084  [10.314 sec/step, loss=0.07810, avg_loss=0.07562]\n","Step 488085  [10.235 sec/step, loss=0.07380, avg_loss=0.07559]\n","Step 488086  [10.155 sec/step, loss=0.07397, avg_loss=0.07558]\n","Step 488087  [10.067 sec/step, loss=0.06864, avg_loss=0.07550]\n","Generated 32 batches of size 16 in 9.802 sec\n","Step 488088  [10.104 sec/step, loss=0.07551, avg_loss=0.07550]\n","Step 488089  [10.029 sec/step, loss=0.07545, avg_loss=0.07550]\n","Step 488090  [9.934 sec/step, loss=0.06175, avg_loss=0.07534]\n","Step 488091  [9.868 sec/step, loss=0.07534, avg_loss=0.07534]\n","Step 488092  [9.811 sec/step, loss=0.07725, avg_loss=0.07536]\n","Step 488093  [9.751 sec/step, loss=0.07872, avg_loss=0.07540]\n","Step 488094  [9.690 sec/step, loss=0.07413, avg_loss=0.07539]\n","Step 488095  [9.645 sec/step, loss=0.07782, avg_loss=0.07541]\n","Step 488096  [9.599 sec/step, loss=0.07646, avg_loss=0.07542]\n","Step 488097  [9.559 sec/step, loss=0.08039, avg_loss=0.07547]\n","Step 488098  [9.484 sec/step, loss=0.07058, avg_loss=0.07542]\n","Step 488099  [9.418 sec/step, loss=0.07579, avg_loss=0.07543]\n","Step 488100  [9.367 sec/step, loss=0.07748, avg_loss=0.07545]\n","Writing summary at step: 488100\n","Step 488101  [5.446 sec/step, loss=0.07837, avg_loss=0.07548]\n","Step 488102  [5.426 sec/step, loss=0.07346, avg_loss=0.07544]\n","Step 488103  [5.367 sec/step, loss=0.06535, avg_loss=0.07532]\n","Step 488104  [5.366 sec/step, loss=0.07855, avg_loss=0.07532]\n","Step 488105  [5.351 sec/step, loss=0.07621, avg_loss=0.07534]\n","Step 488106  [5.364 sec/step, loss=0.07814, avg_loss=0.07532]\n","Step 488107  [5.355 sec/step, loss=0.07788, avg_loss=0.07533]\n","Step 488108  [5.330 sec/step, loss=0.07148, avg_loss=0.07535]\n","Step 488109  [5.276 sec/step, loss=0.06562, avg_loss=0.07522]\n","Step 488110  [5.311 sec/step, loss=0.07915, avg_loss=0.07524]\n","Step 488111  [5.254 sec/step, loss=0.06400, avg_loss=0.07508]\n","Step 488112  [5.264 sec/step, loss=0.07750, avg_loss=0.07510]\n","Step 488113  [5.264 sec/step, loss=0.07988, avg_loss=0.07512]\n","Step 488114  [5.244 sec/step, loss=0.07321, avg_loss=0.07508]\n","Step 488115  [5.266 sec/step, loss=0.08071, avg_loss=0.07522]\n","Step 488116  [5.237 sec/step, loss=0.07248, avg_loss=0.07517]\n","Step 488117  [5.225 sec/step, loss=0.07701, avg_loss=0.07530]\n","Step 488118  [5.230 sec/step, loss=0.08014, avg_loss=0.07539]\n","Generated 32 batches of size 16 in 9.926 sec\n","Step 488119  [5.333 sec/step, loss=0.08031, avg_loss=0.07546]\n","Step 488120  [5.282 sec/step, loss=0.07781, avg_loss=0.07550]\n","Step 488121  [5.272 sec/step, loss=0.07977, avg_loss=0.07550]\n","Step 488122  [5.170 sec/step, loss=0.07479, avg_loss=0.07547]\n","Step 488123  [5.158 sec/step, loss=0.07815, avg_loss=0.07556]\n","Step 488124  [5.165 sec/step, loss=0.08046, avg_loss=0.07564]\n","Step 488125  [5.124 sec/step, loss=0.06855, avg_loss=0.07558]\n","Step 488126  [5.091 sec/step, loss=0.07312, avg_loss=0.07561]\n","Step 488127  [5.073 sec/step, loss=0.07809, avg_loss=0.07561]\n","Step 488128  [5.058 sec/step, loss=0.07818, avg_loss=0.07559]\n","Step 488129  [5.040 sec/step, loss=0.07882, avg_loss=0.07558]\n","Step 488130  [4.980 sec/step, loss=0.07362, avg_loss=0.07551]\n","Step 488131  [5.020 sec/step, loss=0.07967, avg_loss=0.07554]\n","Step 488132  [5.067 sec/step, loss=0.08076, avg_loss=0.07561]\n","Step 488133  [5.040 sec/step, loss=0.06726, avg_loss=0.07555]\n","Step 488134  [4.996 sec/step, loss=0.07400, avg_loss=0.07550]\n","Step 488135  [4.983 sec/step, loss=0.07324, avg_loss=0.07546]\n","Step 488136  [4.981 sec/step, loss=0.06720, avg_loss=0.07546]\n","Step 488137  [4.965 sec/step, loss=0.06580, avg_loss=0.07539]\n","Step 488138  [4.983 sec/step, loss=0.07698, avg_loss=0.07552]\n","Step 488139  [5.009 sec/step, loss=0.08008, avg_loss=0.07557]\n","Step 488140  [5.014 sec/step, loss=0.08014, avg_loss=0.07564]\n","Step 488141  [4.998 sec/step, loss=0.07114, avg_loss=0.07561]\n","Step 488142  [4.989 sec/step, loss=0.07781, avg_loss=0.07560]\n","Step 488143  [4.975 sec/step, loss=0.07085, avg_loss=0.07553]\n","Step 488144  [4.960 sec/step, loss=0.07974, avg_loss=0.07552]\n","Step 488145  [4.983 sec/step, loss=0.07965, avg_loss=0.07561]\n","Step 488146  [4.984 sec/step, loss=0.07749, avg_loss=0.07561]\n","Step 488147  [4.919 sec/step, loss=0.06337, avg_loss=0.07545]\n","Step 488148  [4.871 sec/step, loss=0.07808, avg_loss=0.07544]\n","Step 488149  [4.940 sec/step, loss=0.07754, avg_loss=0.07543]\n","Step 488150  [4.956 sec/step, loss=0.08071, avg_loss=0.07544]\n","Step 488151  [5.019 sec/step, loss=0.07798, avg_loss=0.07548]\n","Generated 32 batches of size 16 in 8.744 sec\n","Step 488152  [5.032 sec/step, loss=0.07290, avg_loss=0.07552]\n","Step 488153  [5.047 sec/step, loss=0.07924, avg_loss=0.07553]\n","Step 488154  [5.024 sec/step, loss=0.07670, avg_loss=0.07551]\n","Step 488155  [5.000 sec/step, loss=0.07800, avg_loss=0.07550]\n","Step 488156  [5.010 sec/step, loss=0.07575, avg_loss=0.07560]\n","Step 488157  [4.981 sec/step, loss=0.07765, avg_loss=0.07561]\n","Step 488158  [4.933 sec/step, loss=0.07566, avg_loss=0.07557]\n","Step 488159  [4.937 sec/step, loss=0.07610, avg_loss=0.07558]\n","Step 488160  [4.941 sec/step, loss=0.08004, avg_loss=0.07561]\n","Step 488161  [4.837 sec/step, loss=0.06480, avg_loss=0.07548]\n","Step 488162  [4.818 sec/step, loss=0.07207, avg_loss=0.07543]\n","Step 488163  [4.802 sec/step, loss=0.07852, avg_loss=0.07543]\n","Step 488164  [4.783 sec/step, loss=0.07335, avg_loss=0.07538]\n","Step 488165  [4.791 sec/step, loss=0.07541, avg_loss=0.07540]\n","Step 488166  [4.776 sec/step, loss=0.07794, avg_loss=0.07538]\n","Step 488167  [4.786 sec/step, loss=0.07981, avg_loss=0.07551]\n","Step 488168  [4.808 sec/step, loss=0.07658, avg_loss=0.07555]\n","Step 488169  [4.768 sec/step, loss=0.06536, avg_loss=0.07543]\n","Step 488170  [4.806 sec/step, loss=0.08006, avg_loss=0.07549]\n","Step 488171  [4.805 sec/step, loss=0.07701, avg_loss=0.07550]\n","Step 488172  [4.829 sec/step, loss=0.07728, avg_loss=0.07556]\n","Step 488173  [4.771 sec/step, loss=0.06783, avg_loss=0.07545]\n","Step 488174  [4.725 sec/step, loss=0.07006, avg_loss=0.07537]\n","Step 488175  [4.762 sec/step, loss=0.07725, avg_loss=0.07546]\n","Step 488176  [4.747 sec/step, loss=0.07996, avg_loss=0.07548]\n","Step 488177  [4.770 sec/step, loss=0.07725, avg_loss=0.07558]\n","Step 488178  [4.784 sec/step, loss=0.07967, avg_loss=0.07561]\n","Step 488179  [4.776 sec/step, loss=0.07805, avg_loss=0.07558]\n","Step 488180  [4.747 sec/step, loss=0.06948, avg_loss=0.07550]\n","Step 488181  [4.747 sec/step, loss=0.07757, avg_loss=0.07548]\n","Step 488182  [4.730 sec/step, loss=0.07756, avg_loss=0.07546]\n","Generated 32 batches of size 16 in 9.404 sec\n","Step 488183  [4.786 sec/step, loss=0.07800, avg_loss=0.07544]\n","Step 488184  [4.746 sec/step, loss=0.07454, avg_loss=0.07541]\n","Step 488185  [4.762 sec/step, loss=0.07908, avg_loss=0.07546]\n","Step 488186  [4.804 sec/step, loss=0.07913, avg_loss=0.07551]\n","Step 488187  [4.811 sec/step, loss=0.07376, avg_loss=0.07556]\n","Step 488188  [4.714 sec/step, loss=0.07527, avg_loss=0.07556]\n","Step 488189  [4.748 sec/step, loss=0.08085, avg_loss=0.07562]\n","Step 488190  [4.765 sec/step, loss=0.07509, avg_loss=0.07575]\n","Step 488191  [4.760 sec/step, loss=0.07354, avg_loss=0.07573]\n","Step 488192  [4.728 sec/step, loss=0.06544, avg_loss=0.07561]\n","Step 488193  [4.805 sec/step, loss=0.07717, avg_loss=0.07560]\n","Step 488194  [4.804 sec/step, loss=0.07285, avg_loss=0.07558]\n","Step 488195  [4.807 sec/step, loss=0.07965, avg_loss=0.07560]\n","Step 488196  [4.803 sec/step, loss=0.07734, avg_loss=0.07561]\n","Step 488197  [4.761 sec/step, loss=0.06756, avg_loss=0.07548]\n","Step 488198  [4.792 sec/step, loss=0.07588, avg_loss=0.07554]\n","Step 488199  [4.789 sec/step, loss=0.07397, avg_loss=0.07552]\n","Step 488200  [4.839 sec/step, loss=0.07875, avg_loss=0.07553]\n","Writing summary at step: 488200\n","Step 488201  [4.820 sec/step, loss=0.07304, avg_loss=0.07548]\n","Step 488202  [4.826 sec/step, loss=0.07785, avg_loss=0.07552]\n","Step 488203  [4.875 sec/step, loss=0.07990, avg_loss=0.07567]\n","Step 488204  [4.841 sec/step, loss=0.06974, avg_loss=0.07558]\n","Step 488205  [4.855 sec/step, loss=0.07832, avg_loss=0.07560]\n","Step 488206  [4.746 sec/step, loss=0.06524, avg_loss=0.07547]\n","Step 488207  [4.759 sec/step, loss=0.07666, avg_loss=0.07546]\n","Step 488208  [4.745 sec/step, loss=0.06984, avg_loss=0.07544]\n","Step 488209  [4.768 sec/step, loss=0.07579, avg_loss=0.07554]\n","Step 488210  [4.769 sec/step, loss=0.07826, avg_loss=0.07554]\n","Step 488211  [4.772 sec/step, loss=0.07228, avg_loss=0.07562]\n","Step 488212  [4.752 sec/step, loss=0.07344, avg_loss=0.07558]\n","Step 488213  [4.725 sec/step, loss=0.07746, avg_loss=0.07555]\n","Step 488214  [4.756 sec/step, loss=0.07422, avg_loss=0.07556]\n","Generated 32 batches of size 16 in 9.749 sec\n","Step 488215  [4.749 sec/step, loss=0.07812, avg_loss=0.07554]\n","Step 488216  [4.749 sec/step, loss=0.07376, avg_loss=0.07555]\n","Step 488217  [4.753 sec/step, loss=0.07767, avg_loss=0.07556]\n","Step 488218  [4.752 sec/step, loss=0.08027, avg_loss=0.07556]\n","Step 488219  [4.682 sec/step, loss=0.08030, avg_loss=0.07556]\n","Step 488220  [4.678 sec/step, loss=0.07689, avg_loss=0.07555]\n","Step 488221  [4.673 sec/step, loss=0.07917, avg_loss=0.07554]\n","Step 488222  [4.701 sec/step, loss=0.08044, avg_loss=0.07560]\n","Step 488223  [4.696 sec/step, loss=0.07561, avg_loss=0.07557]\n","Step 488224  [4.643 sec/step, loss=0.06753, avg_loss=0.07544]\n","Step 488225  [4.648 sec/step, loss=0.07059, avg_loss=0.07547]\n","Step 488226  [4.680 sec/step, loss=0.07906, avg_loss=0.07552]\n","Step 488227  [4.671 sec/step, loss=0.07021, avg_loss=0.07545]\n","Step 488228  [4.652 sec/step, loss=0.07746, avg_loss=0.07544]\n","Step 488229  [4.644 sec/step, loss=0.07768, avg_loss=0.07543]\n","Step 488230  [4.682 sec/step, loss=0.08055, avg_loss=0.07550]\n","Step 488231  [4.616 sec/step, loss=0.07221, avg_loss=0.07542]\n","Step 488232  [4.563 sec/step, loss=0.07399, avg_loss=0.07535]\n","Step 488233  [4.624 sec/step, loss=0.08014, avg_loss=0.07548]\n","Step 488234  [4.653 sec/step, loss=0.07846, avg_loss=0.07553]\n","Step 488235  [4.696 sec/step, loss=0.07988, avg_loss=0.07559]\n","Step 488236  [4.722 sec/step, loss=0.07736, avg_loss=0.07570]\n","Step 488237  [4.806 sec/step, loss=0.07754, avg_loss=0.07581]\n","Step 488238  [4.811 sec/step, loss=0.07627, avg_loss=0.07581]\n","Step 488239  [4.806 sec/step, loss=0.07982, avg_loss=0.07580]\n","Step 488240  [4.766 sec/step, loss=0.07460, avg_loss=0.07575]\n","Step 488241  [4.758 sec/step, loss=0.06358, avg_loss=0.07567]\n","Step 488242  [4.769 sec/step, loss=0.07876, avg_loss=0.07568]\n","Step 488243  [4.778 sec/step, loss=0.07672, avg_loss=0.07574]\n","Step 488244  [4.771 sec/step, loss=0.07917, avg_loss=0.07573]\n","Step 488245  [4.780 sec/step, loss=0.07837, avg_loss=0.07572]\n","Step 488246  [4.756 sec/step, loss=0.06718, avg_loss=0.07562]\n","Step 488247  [4.794 sec/step, loss=0.07415, avg_loss=0.07573]\n","Generated 32 batches of size 16 in 9.319 sec\n","Step 488248  [4.792 sec/step, loss=0.07375, avg_loss=0.07568]\n","Step 488249  [4.730 sec/step, loss=0.06134, avg_loss=0.07552]\n","Step 488250  [4.778 sec/step, loss=0.08050, avg_loss=0.07552]\n","Step 488251  [4.736 sec/step, loss=0.07820, avg_loss=0.07552]\n","Step 488252  [4.757 sec/step, loss=0.07827, avg_loss=0.07558]\n","Step 488253  [4.776 sec/step, loss=0.07927, avg_loss=0.07558]\n","Step 488254  [4.752 sec/step, loss=0.07755, avg_loss=0.07558]\n","Step 488255  [4.735 sec/step, loss=0.07287, avg_loss=0.07553]\n","Step 488256  [4.737 sec/step, loss=0.07733, avg_loss=0.07555]\n","Step 488257  [4.754 sec/step, loss=0.07836, avg_loss=0.07556]\n","Step 488258  [4.797 sec/step, loss=0.08111, avg_loss=0.07561]\n","Step 488259  [4.825 sec/step, loss=0.07993, avg_loss=0.07565]\n","Step 488260  [4.801 sec/step, loss=0.07505, avg_loss=0.07560]\n","Step 488261  [4.837 sec/step, loss=0.07767, avg_loss=0.07573]\n","Step 488262  [4.850 sec/step, loss=0.07590, avg_loss=0.07577]\n","Step 488263  [4.844 sec/step, loss=0.07863, avg_loss=0.07577]\n","Step 488264  [4.859 sec/step, loss=0.07554, avg_loss=0.07579]\n","Step 488265  [4.845 sec/step, loss=0.06923, avg_loss=0.07573]\n","Step 488266  [4.826 sec/step, loss=0.07232, avg_loss=0.07567]\n","Step 488267  [4.790 sec/step, loss=0.07193, avg_loss=0.07559]\n","Step 488268  [4.776 sec/step, loss=0.07409, avg_loss=0.07557]\n","Step 488269  [4.830 sec/step, loss=0.08008, avg_loss=0.07571]\n","Step 488270  [4.857 sec/step, loss=0.07875, avg_loss=0.07570]\n","Step 488271  [4.896 sec/step, loss=0.07825, avg_loss=0.07571]\n","Step 488272  [4.878 sec/step, loss=0.07394, avg_loss=0.07568]\n","Step 488273  [4.915 sec/step, loss=0.07848, avg_loss=0.07579]\n","Step 488274  [4.907 sec/step, loss=0.06530, avg_loss=0.07574]\n","Step 488275  [4.887 sec/step, loss=0.07378, avg_loss=0.07570]\n","Step 488276  [4.806 sec/step, loss=0.06746, avg_loss=0.07558]\n","Step 488277  [4.828 sec/step, loss=0.08006, avg_loss=0.07561]\n","Generated 32 batches of size 16 in 8.975 sec\n","Step 488278  [4.858 sec/step, loss=0.07832, avg_loss=0.07559]\n","Step 488279  [4.839 sec/step, loss=0.07362, avg_loss=0.07555]\n","Step 488280  [4.940 sec/step, loss=0.07664, avg_loss=0.07562]\n","Step 488281  [4.872 sec/step, loss=0.07727, avg_loss=0.07562]\n","Step 488282  [4.865 sec/step, loss=0.07623, avg_loss=0.07560]\n","Step 488283  [4.783 sec/step, loss=0.07620, avg_loss=0.07559]\n","Step 488284  [4.806 sec/step, loss=0.07894, avg_loss=0.07563]\n","Step 488285  [4.771 sec/step, loss=0.06830, avg_loss=0.07552]\n","Step 488286  [4.713 sec/step, loss=0.06865, avg_loss=0.07542]\n","Step 488287  [4.708 sec/step, loss=0.07377, avg_loss=0.07542]\n","Step 488288  [4.703 sec/step, loss=0.07292, avg_loss=0.07539]\n","Step 488289  [4.696 sec/step, loss=0.07877, avg_loss=0.07537]\n","Step 488290  [4.719 sec/step, loss=0.07955, avg_loss=0.07542]\n","Step 488291  [4.701 sec/step, loss=0.06622, avg_loss=0.07535]\n","Step 488292  [4.708 sec/step, loss=0.07180, avg_loss=0.07541]\n","Step 488293  [4.626 sec/step, loss=0.07344, avg_loss=0.07537]\n","Step 488294  [4.706 sec/step, loss=0.07875, avg_loss=0.07543]\n","Step 488295  [4.725 sec/step, loss=0.07972, avg_loss=0.07543]\n","Step 488296  [4.702 sec/step, loss=0.07392, avg_loss=0.07540]\n","Step 488297  [4.781 sec/step, loss=0.07982, avg_loss=0.07552]\n","Step 488298  [4.755 sec/step, loss=0.07210, avg_loss=0.07548]\n","Step 488299  [4.762 sec/step, loss=0.07727, avg_loss=0.07551]\n","Step 488300  [4.703 sec/step, loss=0.07618, avg_loss=0.07549]\n","Writing summary at step: 488300\n","Step 488301  [4.737 sec/step, loss=0.08043, avg_loss=0.07556]\n","Step 488302  [4.733 sec/step, loss=0.07805, avg_loss=0.07556]\n","Step 488303  [4.710 sec/step, loss=0.07706, avg_loss=0.07554]\n","Step 488304  [4.752 sec/step, loss=0.08000, avg_loss=0.07564]\n","Step 488305  [4.760 sec/step, loss=0.08043, avg_loss=0.07566]\n","Step 488306  [4.793 sec/step, loss=0.07742, avg_loss=0.07578]\n","Step 488307  [4.772 sec/step, loss=0.07363, avg_loss=0.07575]\n","Step 488308  [4.803 sec/step, loss=0.07800, avg_loss=0.07583]\n","Generated 32 batches of size 16 in 9.264 sec\n","Step 488309  [4.874 sec/step, loss=0.07654, avg_loss=0.07584]\n","Step 488310  [4.815 sec/step, loss=0.06545, avg_loss=0.07571]\n","Step 488311  [4.805 sec/step, loss=0.06669, avg_loss=0.07566]\n","Step 488312  [4.837 sec/step, loss=0.07984, avg_loss=0.07572]\n","Step 488313  [4.830 sec/step, loss=0.07442, avg_loss=0.07569]\n","Step 488314  [4.789 sec/step, loss=0.06937, avg_loss=0.07564]\n","Step 488315  [4.780 sec/step, loss=0.07859, avg_loss=0.07565]\n","Step 488316  [4.794 sec/step, loss=0.07789, avg_loss=0.07569]\n","Step 488317  [4.825 sec/step, loss=0.08065, avg_loss=0.07572]\n","Step 488318  [4.829 sec/step, loss=0.08075, avg_loss=0.07572]\n","Step 488319  [4.821 sec/step, loss=0.07802, avg_loss=0.07570]\n","Step 488320  [4.846 sec/step, loss=0.07978, avg_loss=0.07573]\n","Step 488321  [4.808 sec/step, loss=0.06759, avg_loss=0.07561]\n","Step 488322  [4.866 sec/step, loss=0.07868, avg_loss=0.07560]\n","Step 488323  [4.907 sec/step, loss=0.07929, avg_loss=0.07563]\n","Step 488324  [4.934 sec/step, loss=0.07767, avg_loss=0.07573]\n","Step 488325  [4.940 sec/step, loss=0.07410, avg_loss=0.07577]\n","Step 488326  [4.979 sec/step, loss=0.07812, avg_loss=0.07576]\n","Step 488327  [5.003 sec/step, loss=0.07724, avg_loss=0.07583]\n","Step 488328  [4.985 sec/step, loss=0.07276, avg_loss=0.07578]\n","Step 488329  [4.963 sec/step, loss=0.07000, avg_loss=0.07571]\n","Step 488330  [4.922 sec/step, loss=0.07085, avg_loss=0.07561]\n","Step 488331  [4.906 sec/step, loss=0.06741, avg_loss=0.07556]\n","Step 488332  [4.913 sec/step, loss=0.07548, avg_loss=0.07558]\n","Step 488333  [4.869 sec/step, loss=0.07469, avg_loss=0.07552]\n","Step 488334  [4.829 sec/step, loss=0.06788, avg_loss=0.07541]\n","Step 488335  [4.764 sec/step, loss=0.06393, avg_loss=0.07526]\n","Step 488336  [4.783 sec/step, loss=0.07979, avg_loss=0.07528]\n","Step 488337  [4.748 sec/step, loss=0.07987, avg_loss=0.07530]\n","Step 488338  [4.751 sec/step, loss=0.07867, avg_loss=0.07533]\n","Step 488339  [4.749 sec/step, loss=0.07885, avg_loss=0.07532]\n","Step 488340  [4.764 sec/step, loss=0.07714, avg_loss=0.07534]\n","Step 488341  [4.810 sec/step, loss=0.07399, avg_loss=0.07545]\n","Generated 32 batches of size 16 in 9.652 sec\n","Step 488342  [4.807 sec/step, loss=0.07458, avg_loss=0.07541]\n","Step 488343  [4.803 sec/step, loss=0.07303, avg_loss=0.07537]\n","Step 488344  [4.789 sec/step, loss=0.07661, avg_loss=0.07534]\n","Step 488345  [4.767 sec/step, loss=0.07749, avg_loss=0.07533]\n","Step 488346  [4.782 sec/step, loss=0.07658, avg_loss=0.07543]\n","Step 488347  [4.771 sec/step, loss=0.07720, avg_loss=0.07546]\n","Step 488348  [4.770 sec/step, loss=0.07747, avg_loss=0.07550]\n","Step 488349  [4.772 sec/step, loss=0.07954, avg_loss=0.07568]\n","Step 488350  [4.698 sec/step, loss=0.07852, avg_loss=0.07566]\n","Step 488351  [4.697 sec/step, loss=0.07746, avg_loss=0.07565]\n","Step 488352  [4.678 sec/step, loss=0.07740, avg_loss=0.07564]\n","Step 488353  [4.625 sec/step, loss=0.07753, avg_loss=0.07562]\n","Step 488354  [4.617 sec/step, loss=0.07388, avg_loss=0.07559]\n","Step 488355  [4.608 sec/step, loss=0.06941, avg_loss=0.07555]\n","Step 488356  [4.644 sec/step, loss=0.07821, avg_loss=0.07556]\n","Step 488357  [4.675 sec/step, loss=0.07901, avg_loss=0.07557]\n","Step 488358  [4.725 sec/step, loss=0.07718, avg_loss=0.07553]\n","Step 488359  [4.714 sec/step, loss=0.07933, avg_loss=0.07552]\n","Step 488360  [4.693 sec/step, loss=0.06439, avg_loss=0.07542]\n","Step 488361  [4.685 sec/step, loss=0.07766, avg_loss=0.07542]\n","Step 488362  [4.699 sec/step, loss=0.07897, avg_loss=0.07545]\n","Step 488363  [4.697 sec/step, loss=0.07647, avg_loss=0.07543]\n","Step 488364  [4.681 sec/step, loss=0.07311, avg_loss=0.07540]\n","Step 488365  [4.728 sec/step, loss=0.08187, avg_loss=0.07553]\n","Step 488366  [4.758 sec/step, loss=0.07792, avg_loss=0.07558]\n","Step 488367  [4.783 sec/step, loss=0.07726, avg_loss=0.07564]\n","Step 488368  [4.762 sec/step, loss=0.06740, avg_loss=0.07557]\n","Step 488369  [4.722 sec/step, loss=0.07377, avg_loss=0.07551]\n","Step 488370  [4.646 sec/step, loss=0.06870, avg_loss=0.07541]\n","Step 488371  [4.634 sec/step, loss=0.08011, avg_loss=0.07542]\n","Step 488372  [4.638 sec/step, loss=0.07600, avg_loss=0.07545]\n","Step 488373  [4.653 sec/step, loss=0.07392, avg_loss=0.07540]\n","Generated 32 batches of size 16 in 9.497 sec\n","Step 488374  [4.680 sec/step, loss=0.07136, avg_loss=0.07546]\n","Step 488375  [4.680 sec/step, loss=0.07512, avg_loss=0.07547]\n","Step 488376  [4.720 sec/step, loss=0.07612, avg_loss=0.07556]\n","Step 488377  [4.703 sec/step, loss=0.07665, avg_loss=0.07553]\n","Step 488378  [4.636 sec/step, loss=0.07324, avg_loss=0.07548]\n","Step 488379  [4.666 sec/step, loss=0.08043, avg_loss=0.07554]\n","Step 488380  [4.613 sec/step, loss=0.08008, avg_loss=0.07558]\n","Step 488381  [4.584 sec/step, loss=0.07022, avg_loss=0.07551]\n","Step 488382  [4.585 sec/step, loss=0.07690, avg_loss=0.07551]\n","Step 488383  [4.638 sec/step, loss=0.07574, avg_loss=0.07551]\n","Step 488384  [4.614 sec/step, loss=0.07415, avg_loss=0.07546]\n","Step 488385  [4.617 sec/step, loss=0.06376, avg_loss=0.07542]\n","Step 488386  [4.647 sec/step, loss=0.07853, avg_loss=0.07552]\n","Step 488387  [4.679 sec/step, loss=0.07997, avg_loss=0.07558]\n","Step 488388  [4.688 sec/step, loss=0.07775, avg_loss=0.07563]\n","Step 488389  [4.637 sec/step, loss=0.06701, avg_loss=0.07551]\n","Step 488390  [4.630 sec/step, loss=0.07741, avg_loss=0.07549]\n","Step 488391  [4.643 sec/step, loss=0.07354, avg_loss=0.07556]\n","Step 488392  [4.665 sec/step, loss=0.07775, avg_loss=0.07562]\n","Step 488393  [4.680 sec/step, loss=0.07953, avg_loss=0.07568]\n","Step 488394  [4.597 sec/step, loss=0.07657, avg_loss=0.07566]\n","Step 488395  [4.537 sec/step, loss=0.06861, avg_loss=0.07555]\n","Step 488396  [4.634 sec/step, loss=0.08002, avg_loss=0.07561]\n","Step 488397  [4.576 sec/step, loss=0.07610, avg_loss=0.07557]\n","Step 488398  [4.591 sec/step, loss=0.07752, avg_loss=0.07563]\n","Step 488399  [4.612 sec/step, loss=0.07954, avg_loss=0.07565]\n","Step 488400  [4.644 sec/step, loss=0.07986, avg_loss=0.07569]\n","Writing summary at step: 488400\n","Step 488401  [4.674 sec/step, loss=0.07817, avg_loss=0.07566]\n","Step 488402  [4.664 sec/step, loss=0.07294, avg_loss=0.07561]\n","Step 488403  [4.697 sec/step, loss=0.07995, avg_loss=0.07564]\n","Step 488404  [4.708 sec/step, loss=0.07557, avg_loss=0.07560]\n","Generated 32 batches of size 16 in 9.440 sec\n","Step 488405  [4.685 sec/step, loss=0.07083, avg_loss=0.07550]\n","Step 488406  [4.655 sec/step, loss=0.06522, avg_loss=0.07538]\n","Step 488407  [4.674 sec/step, loss=0.07707, avg_loss=0.07541]\n","Step 488408  [4.667 sec/step, loss=0.07702, avg_loss=0.07540]\n","Step 488409  [4.632 sec/step, loss=0.07775, avg_loss=0.07541]\n","Step 488410  [4.676 sec/step, loss=0.08086, avg_loss=0.07557]\n","Step 488411  [4.688 sec/step, loss=0.07150, avg_loss=0.07562]\n","Step 488412  [4.650 sec/step, loss=0.07394, avg_loss=0.07556]\n","Step 488413  [4.687 sec/step, loss=0.07989, avg_loss=0.07561]\n","Step 488414  [4.695 sec/step, loss=0.07341, avg_loss=0.07565]\n","Step 488415  [4.696 sec/step, loss=0.07806, avg_loss=0.07565]\n","Step 488416  [4.698 sec/step, loss=0.07645, avg_loss=0.07563]\n","Step 488417  [4.685 sec/step, loss=0.07762, avg_loss=0.07560]\n","Step 488418  [4.655 sec/step, loss=0.07655, avg_loss=0.07556]\n","Step 488419  [4.611 sec/step, loss=0.06116, avg_loss=0.07539]\n","Step 488420  [4.614 sec/step, loss=0.07984, avg_loss=0.07539]\n","Step 488421  [4.636 sec/step, loss=0.07522, avg_loss=0.07547]\n","Step 488422  [4.530 sec/step, loss=0.06465, avg_loss=0.07533]\n","Step 488423  [4.545 sec/step, loss=0.08039, avg_loss=0.07534]\n","Step 488424  [4.521 sec/step, loss=0.07059, avg_loss=0.07527]\n","Step 488425  [4.526 sec/step, loss=0.07400, avg_loss=0.07527]\n","Step 488426  [4.456 sec/step, loss=0.07421, avg_loss=0.07523]\n","Step 488427  [4.418 sec/step, loss=0.06746, avg_loss=0.07513]\n","Step 488428  [4.437 sec/step, loss=0.07699, avg_loss=0.07517]\n","Step 488429  [4.465 sec/step, loss=0.07765, avg_loss=0.07525]\n","Step 488430  [4.493 sec/step, loss=0.07685, avg_loss=0.07531]\n","Step 488431  [4.535 sec/step, loss=0.07931, avg_loss=0.07543]\n","Step 488432  [4.527 sec/step, loss=0.07387, avg_loss=0.07541]\n","Step 488433  [4.550 sec/step, loss=0.07907, avg_loss=0.07546]\n","Step 488434  [4.569 sec/step, loss=0.07752, avg_loss=0.07555]\n","Step 488435  [4.578 sec/step, loss=0.07060, avg_loss=0.07562]\n","Step 488436  [4.552 sec/step, loss=0.06928, avg_loss=0.07551]\n","Generated 32 batches of size 16 in 9.270 sec\n","Step 488437  [4.558 sec/step, loss=0.07583, avg_loss=0.07547]\n","Step 488438  [4.573 sec/step, loss=0.08030, avg_loss=0.07549]\n","Step 488439  [4.594 sec/step, loss=0.07951, avg_loss=0.07550]\n","Step 488440  [4.668 sec/step, loss=0.07663, avg_loss=0.07549]\n","Step 488441  [4.648 sec/step, loss=0.07780, avg_loss=0.07553]\n","Step 488442  [4.636 sec/step, loss=0.07789, avg_loss=0.07556]\n","Step 488443  [4.665 sec/step, loss=0.07966, avg_loss=0.07563]\n","Step 488444  [4.662 sec/step, loss=0.07368, avg_loss=0.07560]\n","Step 488445  [4.666 sec/step, loss=0.07755, avg_loss=0.07560]\n","Step 488446  [4.660 sec/step, loss=0.07470, avg_loss=0.07558]\n","Step 488447  [4.669 sec/step, loss=0.07965, avg_loss=0.07561]\n","Step 488448  [4.692 sec/step, loss=0.07935, avg_loss=0.07563]\n","Step 488449  [4.682 sec/step, loss=0.07750, avg_loss=0.07561]\n","Step 488450  [4.655 sec/step, loss=0.07069, avg_loss=0.07553]\n","Step 488451  [4.635 sec/step, loss=0.07320, avg_loss=0.07548]\n","Step 488452  [4.643 sec/step, loss=0.07784, avg_loss=0.07549]\n","Step 488453  [4.630 sec/step, loss=0.07360, avg_loss=0.07545]\n","Step 488454  [4.655 sec/step, loss=0.07626, avg_loss=0.07547]\n","Step 488455  [4.687 sec/step, loss=0.07877, avg_loss=0.07557]\n","Step 488456  [4.622 sec/step, loss=0.06641, avg_loss=0.07545]\n","Step 488457  [4.589 sec/step, loss=0.07950, avg_loss=0.07545]\n","Step 488458  [4.534 sec/step, loss=0.07966, avg_loss=0.07548]\n","Step 488459  [4.532 sec/step, loss=0.07930, avg_loss=0.07548]\n","Step 488460  [4.563 sec/step, loss=0.07711, avg_loss=0.07561]\n","Step 488461  [4.641 sec/step, loss=0.07969, avg_loss=0.07563]\n","Step 488462  [4.614 sec/step, loss=0.07245, avg_loss=0.07556]\n","Step 488463  [4.590 sec/step, loss=0.06963, avg_loss=0.07549]\n","Step 488464  [4.602 sec/step, loss=0.07719, avg_loss=0.07553]\n","Step 488465  [4.604 sec/step, loss=0.08127, avg_loss=0.07553]\n","Step 488466  [4.560 sec/step, loss=0.06772, avg_loss=0.07542]\n","Step 488467  [4.606 sec/step, loss=0.07816, avg_loss=0.07543]\n","Step 488468  [4.668 sec/step, loss=0.07407, avg_loss=0.07550]\n","Generated 32 batches of size 16 in 9.460 sec\n","Step 488469  [4.693 sec/step, loss=0.07602, avg_loss=0.07552]\n","Step 488470  [4.705 sec/step, loss=0.07452, avg_loss=0.07558]\n","Step 488471  [4.680 sec/step, loss=0.07400, avg_loss=0.07552]\n","Step 488472  [4.673 sec/step, loss=0.07192, avg_loss=0.07548]\n","Step 488473  [4.689 sec/step, loss=0.07403, avg_loss=0.07548]\n","Step 488474  [4.668 sec/step, loss=0.06358, avg_loss=0.07540]\n","Step 488475  [4.672 sec/step, loss=0.07850, avg_loss=0.07544]\n","Step 488476  [4.686 sec/step, loss=0.07836, avg_loss=0.07546]\n","Step 488477  [4.718 sec/step, loss=0.07841, avg_loss=0.07548]\n","Step 488478  [4.737 sec/step, loss=0.07712, avg_loss=0.07552]\n","Step 488479  [4.694 sec/step, loss=0.06728, avg_loss=0.07538]\n","Step 488480  [4.664 sec/step, loss=0.07422, avg_loss=0.07532]\n","Step 488481  [4.680 sec/step, loss=0.07387, avg_loss=0.07536]\n","Step 488482  [4.701 sec/step, loss=0.07962, avg_loss=0.07539]\n","Step 488483  [4.632 sec/step, loss=0.06818, avg_loss=0.07531]\n","Step 488484  [4.617 sec/step, loss=0.06483, avg_loss=0.07522]\n","Step 488485  [4.640 sec/step, loss=0.07682, avg_loss=0.07535]\n","Step 488486  [4.614 sec/step, loss=0.06857, avg_loss=0.07525]\n","Step 488487  [4.603 sec/step, loss=0.07663, avg_loss=0.07522]\n","Step 488488  [4.599 sec/step, loss=0.07649, avg_loss=0.07520]\n","Step 488489  [4.645 sec/step, loss=0.07937, avg_loss=0.07533]\n","Step 488490  [4.651 sec/step, loss=0.07854, avg_loss=0.07534]\n","Step 488491  [4.682 sec/step, loss=0.07990, avg_loss=0.07540]\n","Step 488492  [4.672 sec/step, loss=0.07449, avg_loss=0.07537]\n","Step 488493  [4.713 sec/step, loss=0.07977, avg_loss=0.07537]\n","Step 488494  [4.744 sec/step, loss=0.08037, avg_loss=0.07541]\n","Step 488495  [4.849 sec/step, loss=0.07851, avg_loss=0.07551]\n","Step 488496  [4.779 sec/step, loss=0.07731, avg_loss=0.07548]\n","Step 488497  [4.785 sec/step, loss=0.07755, avg_loss=0.07550]\n","Step 488498  [4.783 sec/step, loss=0.07511, avg_loss=0.07547]\n","Step 488499  [4.806 sec/step, loss=0.07945, avg_loss=0.07547]\n","Step 488500  [4.796 sec/step, loss=0.07192, avg_loss=0.07539]\n","Writing summary at step: 488500\n","Generated 32 batches of size 16 in 10.042 sec\n","Step 488501  [4.723 sec/step, loss=0.07074, avg_loss=0.07532]\n","Step 488502  [4.724 sec/step, loss=0.07569, avg_loss=0.07535]\n","Step 488503  [4.691 sec/step, loss=0.07829, avg_loss=0.07533]\n","Step 488504  [4.644 sec/step, loss=0.07392, avg_loss=0.07531]\n","Step 488505  [4.644 sec/step, loss=0.07439, avg_loss=0.07535]\n","Step 488506  [4.642 sec/step, loss=0.06828, avg_loss=0.07538]\n","Step 488507  [4.642 sec/step, loss=0.07925, avg_loss=0.07540]\n","Step 488508  [4.651 sec/step, loss=0.07899, avg_loss=0.07542]\n","Step 488509  [4.592 sec/step, loss=0.06673, avg_loss=0.07531]\n","Step 488510  [4.571 sec/step, loss=0.07772, avg_loss=0.07528]\n","Step 488511  [4.607 sec/step, loss=0.07987, avg_loss=0.07536]\n","Step 488512  [4.703 sec/step, loss=0.07849, avg_loss=0.07541]\n","Step 488513  [4.686 sec/step, loss=0.07786, avg_loss=0.07539]\n","Step 488514  [4.684 sec/step, loss=0.07002, avg_loss=0.07535]\n","Step 488515  [4.660 sec/step, loss=0.07338, avg_loss=0.07531]\n","Step 488516  [4.671 sec/step, loss=0.07682, avg_loss=0.07531]\n","Step 488517  [4.676 sec/step, loss=0.08042, avg_loss=0.07534]\n","Step 488518  [4.671 sec/step, loss=0.07562, avg_loss=0.07533]\n","Step 488519  [4.696 sec/step, loss=0.07734, avg_loss=0.07549]\n","Step 488520  [4.641 sec/step, loss=0.06433, avg_loss=0.07534]\n","Step 488521  [4.645 sec/step, loss=0.07658, avg_loss=0.07535]\n","Step 488522  [4.659 sec/step, loss=0.07432, avg_loss=0.07545]\n","Step 488523  [4.598 sec/step, loss=0.07430, avg_loss=0.07539]\n","Step 488524  [4.635 sec/step, loss=0.07935, avg_loss=0.07547]\n","Step 488525  [4.627 sec/step, loss=0.07067, avg_loss=0.07544]\n","Step 488526  [4.634 sec/step, loss=0.07765, avg_loss=0.07547]\n","Step 488527  [4.638 sec/step, loss=0.06793, avg_loss=0.07548]\n","Step 488528  [4.660 sec/step, loss=0.07801, avg_loss=0.07549]\n","Step 488529  [4.666 sec/step, loss=0.07961, avg_loss=0.07551]\n","Step 488530  [4.650 sec/step, loss=0.07394, avg_loss=0.07548]\n","Generated 32 batches of size 16 in 9.290 sec\n","Step 488531  [4.695 sec/step, loss=0.07763, avg_loss=0.07546]\n","Step 488532  [4.732 sec/step, loss=0.08068, avg_loss=0.07553]\n","Step 488533  [4.694 sec/step, loss=0.06907, avg_loss=0.07543]\n","Step 488534  [4.732 sec/step, loss=0.08105, avg_loss=0.07547]\n","Step 488535  [4.736 sec/step, loss=0.07358, avg_loss=0.07550]\n","Step 488536  [4.743 sec/step, loss=0.07739, avg_loss=0.07558]\n","Step 488537  [4.767 sec/step, loss=0.08617, avg_loss=0.07568]\n","Step 488538  [4.781 sec/step, loss=0.07916, avg_loss=0.07567]\n","Step 488539  [4.745 sec/step, loss=0.07603, avg_loss=0.07563]\n","Step 488540  [4.668 sec/step, loss=0.07673, avg_loss=0.07564]\n","Step 488541  [4.671 sec/step, loss=0.07741, avg_loss=0.07563]\n","Step 488542  [4.651 sec/step, loss=0.07126, avg_loss=0.07557]\n","Step 488543  [4.615 sec/step, loss=0.07037, avg_loss=0.07547]\n","Step 488544  [4.610 sec/step, loss=0.07362, avg_loss=0.07547]\n","Step 488545  [4.597 sec/step, loss=0.07217, avg_loss=0.07542]\n","Step 488546  [4.605 sec/step, loss=0.07616, avg_loss=0.07543]\n","Step 488547  [4.606 sec/step, loss=0.07893, avg_loss=0.07543]\n","Step 488548  [4.613 sec/step, loss=0.08013, avg_loss=0.07543]\n","Step 488549  [4.583 sec/step, loss=0.06885, avg_loss=0.07535]\n","Step 488550  [4.574 sec/step, loss=0.06787, avg_loss=0.07532]\n","Step 488551  [4.582 sec/step, loss=0.07428, avg_loss=0.07533]\n","Step 488552  [4.590 sec/step, loss=0.07862, avg_loss=0.07534]\n","Step 488553  [4.617 sec/step, loss=0.07876, avg_loss=0.07539]\n","Step 488554  [4.651 sec/step, loss=0.07921, avg_loss=0.07542]\n","Step 488555  [4.662 sec/step, loss=0.07801, avg_loss=0.07541]\n","Step 488556  [4.688 sec/step, loss=0.07528, avg_loss=0.07550]\n","Step 488557  [4.675 sec/step, loss=0.07682, avg_loss=0.07547]\n","Step 488558  [4.705 sec/step, loss=0.07856, avg_loss=0.07546]\n","Step 488559  [4.685 sec/step, loss=0.07535, avg_loss=0.07542]\n","Step 488560  [4.668 sec/step, loss=0.07352, avg_loss=0.07539]\n","Step 488561  [4.574 sec/step, loss=0.07318, avg_loss=0.07532]\n","Step 488562  [4.611 sec/step, loss=0.07909, avg_loss=0.07539]\n","Generated 32 batches of size 16 in 9.373 sec\n","Step 488563  [4.706 sec/step, loss=0.07770, avg_loss=0.07547]\n","Step 488564  [4.740 sec/step, loss=0.07987, avg_loss=0.07549]\n","Step 488565  [4.683 sec/step, loss=0.06385, avg_loss=0.07532]\n","Step 488566  [4.714 sec/step, loss=0.07632, avg_loss=0.07541]\n","Step 488567  [4.635 sec/step, loss=0.06785, avg_loss=0.07530]\n","Step 488568  [4.597 sec/step, loss=0.07683, avg_loss=0.07533]\n","Step 488569  [4.588 sec/step, loss=0.07761, avg_loss=0.07535]\n","Step 488570  [4.629 sec/step, loss=0.07903, avg_loss=0.07539]\n","Step 488571  [4.709 sec/step, loss=0.07655, avg_loss=0.07542]\n","Step 488572  [4.716 sec/step, loss=0.07683, avg_loss=0.07547]\n","Step 488573  [4.676 sec/step, loss=0.07755, avg_loss=0.07550]\n","Step 488574  [4.709 sec/step, loss=0.07626, avg_loss=0.07563]\n","Step 488575  [4.784 sec/step, loss=0.08010, avg_loss=0.07565]\n","Step 488576  [4.747 sec/step, loss=0.07387, avg_loss=0.07560]\n","Step 488577  [4.738 sec/step, loss=0.07746, avg_loss=0.07559]\n","Step 488578  [4.787 sec/step, loss=0.07884, avg_loss=0.07561]\n","Step 488579  [4.788 sec/step, loss=0.06810, avg_loss=0.07562]\n","Step 488580  [4.771 sec/step, loss=0.06963, avg_loss=0.07557]\n","Step 488581  [4.774 sec/step, loss=0.07682, avg_loss=0.07560]\n","Step 488582  [4.735 sec/step, loss=0.07147, avg_loss=0.07552]\n","Step 488583  [4.802 sec/step, loss=0.07475, avg_loss=0.07558]\n","Step 488584  [4.827 sec/step, loss=0.07744, avg_loss=0.07571]\n","Step 488585  [4.837 sec/step, loss=0.07900, avg_loss=0.07573]\n","Step 488586  [4.830 sec/step, loss=0.06547, avg_loss=0.07570]\n","Step 488587  [4.841 sec/step, loss=0.07861, avg_loss=0.07572]\n","Step 488588  [4.851 sec/step, loss=0.07723, avg_loss=0.07573]\n","Step 488589  [4.815 sec/step, loss=0.07038, avg_loss=0.07564]\n","Step 488590  [4.787 sec/step, loss=0.07084, avg_loss=0.07556]\n","Step 488591  [4.755 sec/step, loss=0.07399, avg_loss=0.07550]\n","Step 488592  [4.785 sec/step, loss=0.08060, avg_loss=0.07556]\n","Step 488593  [4.757 sec/step, loss=0.07977, avg_loss=0.07556]\n","Step 488594  [4.739 sec/step, loss=0.07864, avg_loss=0.07555]\n","Step 488595  [4.683 sec/step, loss=0.07264, avg_loss=0.07549]\n","Step 488596  [4.658 sec/step, loss=0.06657, avg_loss=0.07538]\n","Generated 32 batches of size 16 in 9.368 sec\n","Step 488597  [4.654 sec/step, loss=0.07487, avg_loss=0.07535]\n","Step 488598  [4.657 sec/step, loss=0.07667, avg_loss=0.07537]\n","Step 488599  [4.652 sec/step, loss=0.08002, avg_loss=0.07537]\n","Step 488600  [4.642 sec/step, loss=0.07772, avg_loss=0.07543]\n","Writing summary at step: 488600\n","Step 488601  [4.678 sec/step, loss=0.07936, avg_loss=0.07552]\n","Step 488602  [4.682 sec/step, loss=0.07560, avg_loss=0.07552]\n","Step 488603  [4.685 sec/step, loss=0.07730, avg_loss=0.07551]\n","Step 488604  [4.694 sec/step, loss=0.07473, avg_loss=0.07552]\n","Step 488605  [4.738 sec/step, loss=0.07750, avg_loss=0.07555]\n","Step 488606  [4.777 sec/step, loss=0.07611, avg_loss=0.07563]\n","Step 488607  [4.766 sec/step, loss=0.07723, avg_loss=0.07560]\n","Step 488608  [4.762 sec/step, loss=0.07718, avg_loss=0.07559]\n","Step 488609  [4.785 sec/step, loss=0.07675, avg_loss=0.07569]\n","Step 488610  [4.811 sec/step, loss=0.08076, avg_loss=0.07572]\n","Step 488611  [4.770 sec/step, loss=0.06293, avg_loss=0.07555]\n","Step 488612  [4.676 sec/step, loss=0.07386, avg_loss=0.07550]\n","Step 488613  [4.644 sec/step, loss=0.06890, avg_loss=0.07541]\n","Step 488614  [4.631 sec/step, loss=0.06504, avg_loss=0.07536]\n","Step 488615  [4.664 sec/step, loss=0.07937, avg_loss=0.07542]\n","Step 488616  [4.664 sec/step, loss=0.07909, avg_loss=0.07544]\n","Step 488617  [4.611 sec/step, loss=0.06515, avg_loss=0.07529]\n","Step 488618  [4.609 sec/step, loss=0.07424, avg_loss=0.07528]\n","Step 488619  [4.627 sec/step, loss=0.07819, avg_loss=0.07529]\n","Step 488620  [4.733 sec/step, loss=0.07660, avg_loss=0.07541]\n","Step 488621  [4.749 sec/step, loss=0.07943, avg_loss=0.07544]\n","Step 488622  [4.770 sec/step, loss=0.07832, avg_loss=0.07548]\n","Step 488623  [4.784 sec/step, loss=0.07683, avg_loss=0.07550]\n","Step 488624  [4.768 sec/step, loss=0.07641, avg_loss=0.07547]\n","Step 488625  [4.810 sec/step, loss=0.07956, avg_loss=0.07556]\n","Step 488626  [4.823 sec/step, loss=0.07001, avg_loss=0.07549]\n","Generated 32 batches of size 16 in 10.248 sec\n","Step 488627  [4.896 sec/step, loss=0.07978, avg_loss=0.07560]\n","Step 488628  [4.923 sec/step, loss=0.07853, avg_loss=0.07561]\n","Step 488629  [4.910 sec/step, loss=0.07762, avg_loss=0.07559]\n","Step 488630  [4.903 sec/step, loss=0.07177, avg_loss=0.07557]\n","Step 488631  [4.831 sec/step, loss=0.07344, avg_loss=0.07553]\n","Step 488632  [4.790 sec/step, loss=0.07027, avg_loss=0.07542]\n","Step 488633  [4.809 sec/step, loss=0.07482, avg_loss=0.07548]\n","Step 488634  [4.768 sec/step, loss=0.07509, avg_loss=0.07542]\n","Step 488635  [4.756 sec/step, loss=0.06677, avg_loss=0.07535]\n","Step 488636  [4.811 sec/step, loss=0.07846, avg_loss=0.07536]\n","Step 488637  [4.842 sec/step, loss=0.07876, avg_loss=0.07529]\n","Step 488638  [4.806 sec/step, loss=0.07664, avg_loss=0.07526]\n","Step 488639  [4.831 sec/step, loss=0.07719, avg_loss=0.07528]\n","Step 488640  [4.815 sec/step, loss=0.07294, avg_loss=0.07524]\n","Step 488641  [4.794 sec/step, loss=0.07148, avg_loss=0.07518]\n","Step 488642  [4.837 sec/step, loss=0.07918, avg_loss=0.07526]\n","Step 488643  [4.829 sec/step, loss=0.06193, avg_loss=0.07517]\n","Step 488644  [4.818 sec/step, loss=0.06874, avg_loss=0.07512]\n","Step 488645  [4.818 sec/step, loss=0.07303, avg_loss=0.07513]\n","Step 488646  [4.834 sec/step, loss=0.07971, avg_loss=0.07517]\n","Step 488647  [4.842 sec/step, loss=0.08016, avg_loss=0.07518]\n","Step 488648  [4.790 sec/step, loss=0.07002, avg_loss=0.07508]\n","Step 488649  [4.807 sec/step, loss=0.07689, avg_loss=0.07516]\n","Step 488650  [4.840 sec/step, loss=0.07744, avg_loss=0.07526]\n","Step 488651  [4.855 sec/step, loss=0.07840, avg_loss=0.07530]\n","Step 488652  [4.849 sec/step, loss=0.07719, avg_loss=0.07528]\n","Step 488653  [4.802 sec/step, loss=0.06663, avg_loss=0.07516]\n","Step 488654  [4.801 sec/step, loss=0.07747, avg_loss=0.07514]\n","Step 488655  [4.776 sec/step, loss=0.07536, avg_loss=0.07512]\n","Step 488656  [4.793 sec/step, loss=0.07919, avg_loss=0.07516]\n","Step 488657  [4.819 sec/step, loss=0.07945, avg_loss=0.07518]\n","Generated 32 batches of size 16 in 8.983 sec\n","Step 488658  [4.824 sec/step, loss=0.07700, avg_loss=0.07517]\n","Step 488659  [4.815 sec/step, loss=0.07299, avg_loss=0.07514]\n","Step 488660  [4.827 sec/step, loss=0.07290, avg_loss=0.07514]\n","Step 488661  [4.858 sec/step, loss=0.07895, avg_loss=0.07519]\n","Step 488662  [4.832 sec/step, loss=0.07686, avg_loss=0.07517]\n","Step 488663  [4.748 sec/step, loss=0.07372, avg_loss=0.07513]\n","Step 488664  [4.713 sec/step, loss=0.07775, avg_loss=0.07511]\n","Step 488665  [4.752 sec/step, loss=0.07628, avg_loss=0.07524]\n","Step 488666  [4.735 sec/step, loss=0.07329, avg_loss=0.07521]\n","Step 488667  [4.752 sec/step, loss=0.07275, avg_loss=0.07525]\n","Step 488668  [4.778 sec/step, loss=0.07763, avg_loss=0.07526]\n","Step 488669  [4.759 sec/step, loss=0.07288, avg_loss=0.07522]\n","Step 488670  [4.766 sec/step, loss=0.07874, avg_loss=0.07521]\n","Step 488671  [4.685 sec/step, loss=0.07504, avg_loss=0.07520]\n","Step 488672  [4.665 sec/step, loss=0.06485, avg_loss=0.07508]\n","Step 488673  [4.634 sec/step, loss=0.06461, avg_loss=0.07495]\n","Step 488674  [4.646 sec/step, loss=0.07972, avg_loss=0.07498]\n","Step 488675  [4.585 sec/step, loss=0.07889, avg_loss=0.07497]\n","Step 488676  [4.579 sec/step, loss=0.07026, avg_loss=0.07493]\n","Step 488677  [4.565 sec/step, loss=0.07799, avg_loss=0.07494]\n","Step 488678  [4.486 sec/step, loss=0.06897, avg_loss=0.07484]\n","Step 488679  [4.522 sec/step, loss=0.07699, avg_loss=0.07493]\n","Step 488680  [4.551 sec/step, loss=0.07655, avg_loss=0.07500]\n","Step 488681  [4.634 sec/step, loss=0.07707, avg_loss=0.07500]\n","Step 488682  [4.649 sec/step, loss=0.07748, avg_loss=0.07506]\n","Step 488683  [4.608 sec/step, loss=0.07645, avg_loss=0.07508]\n","Step 488684  [4.634 sec/step, loss=0.08056, avg_loss=0.07511]\n","Step 488685  [4.645 sec/step, loss=0.07972, avg_loss=0.07512]\n","Step 488686  [4.683 sec/step, loss=0.07835, avg_loss=0.07525]\n","Step 488687  [4.660 sec/step, loss=0.07529, avg_loss=0.07521]\n","Step 488688  [4.643 sec/step, loss=0.07489, avg_loss=0.07519]\n","Step 488689  [4.643 sec/step, loss=0.07195, avg_loss=0.07521]\n","Step 488690  [4.695 sec/step, loss=0.07417, avg_loss=0.07524]\n","Generated 32 batches of size 16 in 9.628 sec\n","Step 488691  [4.702 sec/step, loss=0.07387, avg_loss=0.07524]\n","Step 488692  [4.672 sec/step, loss=0.07692, avg_loss=0.07520]\n","Step 488693  [4.648 sec/step, loss=0.07752, avg_loss=0.07518]\n","Step 488694  [4.629 sec/step, loss=0.07270, avg_loss=0.07512]\n","Step 488695  [4.657 sec/step, loss=0.07828, avg_loss=0.07517]\n","Step 488696  [4.671 sec/step, loss=0.07684, avg_loss=0.07528]\n","Step 488697  [4.690 sec/step, loss=0.07891, avg_loss=0.07532]\n","Step 488698  [4.662 sec/step, loss=0.06785, avg_loss=0.07523]\n","Step 488699  [4.623 sec/step, loss=0.07662, avg_loss=0.07520]\n","Step 488700  [4.608 sec/step, loss=0.07560, avg_loss=0.07517]\n","Writing summary at step: 488700\n","Step 488701  [4.627 sec/step, loss=0.07893, avg_loss=0.07517]\n","Step 488702  [4.636 sec/step, loss=0.07664, avg_loss=0.07518]\n","Step 488703  [4.631 sec/step, loss=0.07728, avg_loss=0.07518]\n","Step 488704  [4.714 sec/step, loss=0.07798, avg_loss=0.07521]\n","Step 488705  [4.702 sec/step, loss=0.08005, avg_loss=0.07524]\n","Step 488706  [4.669 sec/step, loss=0.06137, avg_loss=0.07509]\n","Step 488707  [4.656 sec/step, loss=0.07321, avg_loss=0.07505]\n","Step 488708  [4.634 sec/step, loss=0.07061, avg_loss=0.07499]\n","Step 488709  [4.662 sec/step, loss=0.07737, avg_loss=0.07499]\n","Step 488710  [4.636 sec/step, loss=0.07754, avg_loss=0.07496]\n","Step 488711  [4.656 sec/step, loss=0.07712, avg_loss=0.07510]\n","Step 488712  [4.653 sec/step, loss=0.07339, avg_loss=0.07510]\n","Step 488713  [4.658 sec/step, loss=0.07039, avg_loss=0.07511]\n","Step 488714  [4.703 sec/step, loss=0.07962, avg_loss=0.07526]\n","Step 488715  [4.702 sec/step, loss=0.07894, avg_loss=0.07525]\n","Step 488716  [4.661 sec/step, loss=0.06642, avg_loss=0.07513]\n","Step 488717  [4.739 sec/step, loss=0.08001, avg_loss=0.07527]\n","Step 488718  [4.746 sec/step, loss=0.07319, avg_loss=0.07526]\n","Step 488719  [4.731 sec/step, loss=0.07763, avg_loss=0.07526]\n","Step 488720  [4.638 sec/step, loss=0.07379, avg_loss=0.07523]\n","Generated 32 batches of size 16 in 9.409 sec\n","Step 488721  [4.689 sec/step, loss=0.07932, avg_loss=0.07523]\n","Step 488722  [4.686 sec/step, loss=0.07707, avg_loss=0.07522]\n","Step 488723  [4.691 sec/step, loss=0.07682, avg_loss=0.07522]\n","Step 488724  [4.665 sec/step, loss=0.06373, avg_loss=0.07509]\n","Step 488725  [4.629 sec/step, loss=0.07341, avg_loss=0.07503]\n","Step 488726  [4.646 sec/step, loss=0.08011, avg_loss=0.07513]\n","Step 488727  [4.628 sec/step, loss=0.08028, avg_loss=0.07513]\n","Step 488728  [4.550 sec/step, loss=0.06768, avg_loss=0.07503]\n","Step 488729  [4.556 sec/step, loss=0.07865, avg_loss=0.07504]\n","Step 488730  [4.550 sec/step, loss=0.06910, avg_loss=0.07501]\n","Step 488731  [4.554 sec/step, loss=0.07422, avg_loss=0.07502]\n","Step 488732  [4.594 sec/step, loss=0.07926, avg_loss=0.07511]\n","Step 488733  [4.631 sec/step, loss=0.07809, avg_loss=0.07514]\n","Step 488734  [4.626 sec/step, loss=0.07315, avg_loss=0.07512]\n","Step 488735  [4.637 sec/step, loss=0.07235, avg_loss=0.07518]\n","Step 488736  [4.559 sec/step, loss=0.06769, avg_loss=0.07507]\n","Step 488737  [4.450 sec/step, loss=0.06290, avg_loss=0.07491]\n","Step 488738  [4.443 sec/step, loss=0.07470, avg_loss=0.07489]\n","Step 488739  [4.403 sec/step, loss=0.07150, avg_loss=0.07483]\n","Step 488740  [4.404 sec/step, loss=0.07350, avg_loss=0.07484]\n","Step 488741  [4.458 sec/step, loss=0.07967, avg_loss=0.07492]\n","Step 488742  [4.403 sec/step, loss=0.06704, avg_loss=0.07480]\n","Step 488743  [4.442 sec/step, loss=0.07864, avg_loss=0.07497]\n","Step 488744  [4.487 sec/step, loss=0.07818, avg_loss=0.07506]\n","Step 488745  [4.513 sec/step, loss=0.07998, avg_loss=0.07513]\n","Step 488746  [4.491 sec/step, loss=0.07670, avg_loss=0.07510]\n","Step 488747  [4.468 sec/step, loss=0.07774, avg_loss=0.07508]\n","Step 488748  [4.512 sec/step, loss=0.07979, avg_loss=0.07517]\n","Step 488749  [4.517 sec/step, loss=0.07526, avg_loss=0.07516]\n","Step 488750  [4.487 sec/step, loss=0.06714, avg_loss=0.07505]\n","Step 488751  [4.531 sec/step, loss=0.07962, avg_loss=0.07507]\n","Step 488752  [4.539 sec/step, loss=0.07558, avg_loss=0.07505]\n","Generated 32 batches of size 16 in 9.122 sec\n","Step 488753  [4.625 sec/step, loss=0.07724, avg_loss=0.07516]\n","Step 488754  [4.585 sec/step, loss=0.07748, avg_loss=0.07516]\n","Step 488755  [4.607 sec/step, loss=0.07990, avg_loss=0.07520]\n","Step 488756  [4.597 sec/step, loss=0.07660, avg_loss=0.07518]\n","Step 488757  [4.561 sec/step, loss=0.07401, avg_loss=0.07512]\n","Step 488758  [4.508 sec/step, loss=0.07815, avg_loss=0.07513]\n","Step 488759  [4.523 sec/step, loss=0.07708, avg_loss=0.07517]\n","Step 488760  [4.514 sec/step, loss=0.07185, avg_loss=0.07516]\n","Step 488761  [4.577 sec/step, loss=0.07716, avg_loss=0.07515]\n","Step 488762  [4.550 sec/step, loss=0.06739, avg_loss=0.07505]\n","Step 488763  [4.551 sec/step, loss=0.07296, avg_loss=0.07504]\n","Step 488764  [4.560 sec/step, loss=0.07869, avg_loss=0.07505]\n","Step 488765  [4.527 sec/step, loss=0.06161, avg_loss=0.07491]\n","Step 488766  [4.562 sec/step, loss=0.07948, avg_loss=0.07497]\n","Step 488767  [4.571 sec/step, loss=0.07750, avg_loss=0.07502]\n","Step 488768  [4.586 sec/step, loss=0.07749, avg_loss=0.07501]\n","Step 488769  [4.616 sec/step, loss=0.07982, avg_loss=0.07508]\n","Step 488770  [4.636 sec/step, loss=0.07839, avg_loss=0.07508]\n","Step 488771  [4.612 sec/step, loss=0.06448, avg_loss=0.07497]\n","Step 488772  [4.634 sec/step, loss=0.07567, avg_loss=0.07508]\n","Step 488773  [4.643 sec/step, loss=0.07075, avg_loss=0.07514]\n","Step 488774  [4.604 sec/step, loss=0.07289, avg_loss=0.07508]\n","Step 488775  [4.582 sec/step, loss=0.07715, avg_loss=0.07506]\n","Step 488776  [4.591 sec/step, loss=0.07283, avg_loss=0.07508]\n","Step 488777  [4.565 sec/step, loss=0.07170, avg_loss=0.07502]\n","Step 488778  [4.611 sec/step, loss=0.07863, avg_loss=0.07512]\n","Step 488779  [4.611 sec/step, loss=0.07787, avg_loss=0.07513]\n","Step 488780  [4.596 sec/step, loss=0.07533, avg_loss=0.07511]\n","Step 488781  [4.515 sec/step, loss=0.07686, avg_loss=0.07511]\n","Step 488782  [4.506 sec/step, loss=0.07286, avg_loss=0.07507]\n","Step 488783  [4.511 sec/step, loss=0.07659, avg_loss=0.07507]\n","Step 488784  [4.504 sec/step, loss=0.07862, avg_loss=0.07505]\n","Step 488785  [4.474 sec/step, loss=0.06834, avg_loss=0.07493]\n","Generated 32 batches of size 16 in 10.297 sec\n","Step 488786  [4.522 sec/step, loss=0.08080, avg_loss=0.07496]\n","Step 488787  [4.529 sec/step, loss=0.07759, avg_loss=0.07498]\n","Step 488788  [4.546 sec/step, loss=0.07760, avg_loss=0.07501]\n","Step 488789  [4.552 sec/step, loss=0.07402, avg_loss=0.07503]\n","Step 488790  [4.596 sec/step, loss=0.07628, avg_loss=0.07505]\n","Step 488791  [4.608 sec/step, loss=0.07860, avg_loss=0.07510]\n","Step 488792  [4.632 sec/step, loss=0.07828, avg_loss=0.07511]\n","Step 488793  [4.628 sec/step, loss=0.07690, avg_loss=0.07511]\n","Step 488794  [4.692 sec/step, loss=0.07828, avg_loss=0.07516]\n","Step 488795  [4.634 sec/step, loss=0.07650, avg_loss=0.07514]\n","Step 488796  [4.658 sec/step, loss=0.08054, avg_loss=0.07518]\n","Step 488797  [4.647 sec/step, loss=0.07728, avg_loss=0.07516]\n","Step 488798  [4.658 sec/step, loss=0.07283, avg_loss=0.07521]\n","Step 488799  [4.677 sec/step, loss=0.07752, avg_loss=0.07522]\n","Step 488800  [4.674 sec/step, loss=0.07307, avg_loss=0.07520]\n","Writing summary at step: 488800\n","Step 488801  [4.631 sec/step, loss=0.07548, avg_loss=0.07516]\n","Step 488802  [4.629 sec/step, loss=0.07621, avg_loss=0.07516]\n","Step 488803  [4.609 sec/step, loss=0.07079, avg_loss=0.07509]\n","Step 488804  [4.519 sec/step, loss=0.07381, avg_loss=0.07505]\n","Step 488805  [4.491 sec/step, loss=0.07416, avg_loss=0.07499]\n","Step 488806  [4.535 sec/step, loss=0.07808, avg_loss=0.07516]\n","Step 488807  [4.557 sec/step, loss=0.07804, avg_loss=0.07521]\n","Step 488808  [4.557 sec/step, loss=0.07156, avg_loss=0.07522]\n","Step 488809  [4.507 sec/step, loss=0.06566, avg_loss=0.07510]\n","Step 488810  [4.522 sec/step, loss=0.07880, avg_loss=0.07511]\n","Step 488811  [4.599 sec/step, loss=0.07948, avg_loss=0.07514]\n","Step 488812  [4.587 sec/step, loss=0.06758, avg_loss=0.07508]\n","Step 488813  [4.627 sec/step, loss=0.07812, avg_loss=0.07516]\n","Step 488814  [4.590 sec/step, loss=0.06316, avg_loss=0.07499]\n","Step 488815  [4.574 sec/step, loss=0.07762, avg_loss=0.07498]\n","Step 488816  [4.595 sec/step, loss=0.06805, avg_loss=0.07500]\n","Generated 32 batches of size 16 in 9.615 sec\n","Step 488817  [4.587 sec/step, loss=0.08029, avg_loss=0.07500]\n","Step 488818  [4.619 sec/step, loss=0.07982, avg_loss=0.07506]\n","Step 488819  [4.616 sec/step, loss=0.07681, avg_loss=0.07506]\n","Step 488820  [4.621 sec/step, loss=0.07502, avg_loss=0.07507]\n","Step 488821  [4.559 sec/step, loss=0.07627, avg_loss=0.07504]\n","Step 488822  [4.593 sec/step, loss=0.07649, avg_loss=0.07503]\n","Step 488823  [4.583 sec/step, loss=0.07639, avg_loss=0.07503]\n","Step 488824  [4.592 sec/step, loss=0.07378, avg_loss=0.07513]\n","Step 488825  [4.580 sec/step, loss=0.06798, avg_loss=0.07507]\n","Step 488826  [4.592 sec/step, loss=0.07897, avg_loss=0.07506]\n","Step 488827  [4.572 sec/step, loss=0.07735, avg_loss=0.07503]\n","Step 488828  [4.626 sec/step, loss=0.07953, avg_loss=0.07515]\n","Step 488829  [4.698 sec/step, loss=0.07866, avg_loss=0.07515]\n","Step 488830  [4.739 sec/step, loss=0.07764, avg_loss=0.07524]\n","Step 488831  [4.763 sec/step, loss=0.07845, avg_loss=0.07528]\n","Step 488832  [4.729 sec/step, loss=0.07169, avg_loss=0.07520]\n","Step 488833  [4.690 sec/step, loss=0.07705, avg_loss=0.07519]\n","Step 488834  [4.687 sec/step, loss=0.07072, avg_loss=0.07517]\n","Step 488835  [4.701 sec/step, loss=0.07810, avg_loss=0.07523]\n","Step 488836  [4.745 sec/step, loss=0.07890, avg_loss=0.07534]\n","Step 488837  [4.764 sec/step, loss=0.07469, avg_loss=0.07546]\n","Step 488838  [4.778 sec/step, loss=0.07782, avg_loss=0.07549]\n","Step 488839  [4.803 sec/step, loss=0.07540, avg_loss=0.07553]\n","Step 488840  [4.833 sec/step, loss=0.07895, avg_loss=0.07558]\n","Step 488841  [4.783 sec/step, loss=0.07406, avg_loss=0.07553]\n","Step 488842  [4.797 sec/step, loss=0.07314, avg_loss=0.07559]\n","Step 488843  [4.797 sec/step, loss=0.07747, avg_loss=0.07557]\n","Step 488844  [4.771 sec/step, loss=0.07464, avg_loss=0.07554]\n","Step 488845  [4.724 sec/step, loss=0.06686, avg_loss=0.07541]\n","Step 488846  [4.705 sec/step, loss=0.06730, avg_loss=0.07531]\n","Step 488847  [4.697 sec/step, loss=0.07538, avg_loss=0.07529]\n","Step 488848  [4.685 sec/step, loss=0.07252, avg_loss=0.07522]\n","Generated 32 batches of size 16 in 9.567 sec\n","Step 488849  [4.706 sec/step, loss=0.07578, avg_loss=0.07522]\n","Step 488850  [4.734 sec/step, loss=0.07673, avg_loss=0.07532]\n","Step 488851  [4.684 sec/step, loss=0.07667, avg_loss=0.07529]\n","Step 488852  [4.696 sec/step, loss=0.07963, avg_loss=0.07533]\n","Step 488853  [4.643 sec/step, loss=0.07724, avg_loss=0.07533]\n","Step 488854  [4.620 sec/step, loss=0.06783, avg_loss=0.07523]\n","Step 488855  [4.659 sec/step, loss=0.07789, avg_loss=0.07521]\n","Step 488856  [4.629 sec/step, loss=0.06263, avg_loss=0.07507]\n","Step 488857  [4.634 sec/step, loss=0.07651, avg_loss=0.07510]\n","Step 488858  [4.601 sec/step, loss=0.06496, avg_loss=0.07497]\n","Step 488859  [4.627 sec/step, loss=0.07980, avg_loss=0.07499]\n","Step 488860  [4.644 sec/step, loss=0.07817, avg_loss=0.07506]\n","Step 488861  [4.588 sec/step, loss=0.07799, avg_loss=0.07507]\n","Step 488862  [4.648 sec/step, loss=0.08041, avg_loss=0.07520]\n","Step 488863  [4.647 sec/step, loss=0.07214, avg_loss=0.07519]\n","Step 488864  [4.639 sec/step, loss=0.07761, avg_loss=0.07518]\n","Step 488865  [4.672 sec/step, loss=0.07611, avg_loss=0.07532]\n","Step 488866  [4.682 sec/step, loss=0.07926, avg_loss=0.07532]\n","Step 488867  [4.705 sec/step, loss=0.07996, avg_loss=0.07534]\n","Step 488868  [4.672 sec/step, loss=0.07674, avg_loss=0.07534]\n","Step 488869  [4.644 sec/step, loss=0.07170, avg_loss=0.07526]\n","Step 488870  [4.583 sec/step, loss=0.07550, avg_loss=0.07523]\n","Step 488871  [4.594 sec/step, loss=0.07002, avg_loss=0.07528]\n","Step 488872  [4.579 sec/step, loss=0.07058, avg_loss=0.07523]\n","Step 488873  [4.588 sec/step, loss=0.07436, avg_loss=0.07527]\n","Step 488874  [4.611 sec/step, loss=0.07740, avg_loss=0.07531]\n","Step 488875  [4.612 sec/step, loss=0.07676, avg_loss=0.07531]\n","Step 488876  [4.626 sec/step, loss=0.07704, avg_loss=0.07535]\n","Step 488877  [4.698 sec/step, loss=0.07899, avg_loss=0.07542]\n","Step 488878  [4.655 sec/step, loss=0.06393, avg_loss=0.07528]\n","Step 488879  [4.619 sec/step, loss=0.06840, avg_loss=0.07518]\n","Generated 32 batches of size 16 in 8.996 sec\n","Step 488880  [4.692 sec/step, loss=0.07900, avg_loss=0.07522]\n","Step 488881  [4.681 sec/step, loss=0.07392, avg_loss=0.07519]\n","Step 488882  [4.685 sec/step, loss=0.07285, avg_loss=0.07519]\n","Step 488883  [4.676 sec/step, loss=0.07720, avg_loss=0.07519]\n","Step 488884  [4.674 sec/step, loss=0.07949, avg_loss=0.07520]\n","Step 488885  [4.653 sec/step, loss=0.06523, avg_loss=0.07517]\n","Step 488886  [4.671 sec/step, loss=0.07697, avg_loss=0.07513]\n","Step 488887  [4.660 sec/step, loss=0.07359, avg_loss=0.07509]\n","Step 488888  [4.670 sec/step, loss=0.07907, avg_loss=0.07511]\n","Step 488889  [4.692 sec/step, loss=0.07789, avg_loss=0.07515]\n","Step 488890  [4.598 sec/step, loss=0.07267, avg_loss=0.07511]\n","Step 488891  [4.593 sec/step, loss=0.07724, avg_loss=0.07510]\n","Step 488892  [4.550 sec/step, loss=0.06379, avg_loss=0.07495]\n","Step 488893  [4.546 sec/step, loss=0.07553, avg_loss=0.07494]\n","Step 488894  [4.476 sec/step, loss=0.07010, avg_loss=0.07486]\n","Step 488895  [4.482 sec/step, loss=0.07621, avg_loss=0.07485]\n","Step 488896  [4.465 sec/step, loss=0.07702, avg_loss=0.07482]\n","Step 488897  [4.475 sec/step, loss=0.07895, avg_loss=0.07484]\n","Step 488898  [4.509 sec/step, loss=0.07837, avg_loss=0.07489]\n","Step 488899  [4.551 sec/step, loss=0.07999, avg_loss=0.07492]\n","Step 488900  [4.586 sec/step, loss=0.07963, avg_loss=0.07498]\n","Writing summary at step: 488900\n","Step 488901  [4.578 sec/step, loss=0.07366, avg_loss=0.07496]\n","Step 488902  [4.569 sec/step, loss=0.07270, avg_loss=0.07493]\n","Step 488903  [4.620 sec/step, loss=0.07827, avg_loss=0.07500]\n","Step 488904  [4.650 sec/step, loss=0.07893, avg_loss=0.07505]\n","Step 488905  [4.648 sec/step, loss=0.07686, avg_loss=0.07508]\n","Step 488906  [4.623 sec/step, loss=0.07536, avg_loss=0.07505]\n","Step 488907  [4.614 sec/step, loss=0.07742, avg_loss=0.07505]\n","Step 488908  [4.631 sec/step, loss=0.07610, avg_loss=0.07509]\n","Step 488909  [4.670 sec/step, loss=0.07875, avg_loss=0.07522]\n","Step 488910  [4.696 sec/step, loss=0.07401, avg_loss=0.07518]\n","Step 488911  [4.642 sec/step, loss=0.07247, avg_loss=0.07511]\n","Step 488912  [4.651 sec/step, loss=0.06738, avg_loss=0.07510]\n","Generated 32 batches of size 16 in 9.253 sec\n","Step 488913  [4.615 sec/step, loss=0.06130, avg_loss=0.07494]\n","Step 488914  [4.647 sec/step, loss=0.07629, avg_loss=0.07507]\n","Step 488915  [4.725 sec/step, loss=0.07793, avg_loss=0.07507]\n","Step 488916  [4.719 sec/step, loss=0.07291, avg_loss=0.07512]\n","Step 488917  [4.679 sec/step, loss=0.07632, avg_loss=0.07508]\n","Step 488918  [4.671 sec/step, loss=0.07979, avg_loss=0.07508]\n","Step 488919  [4.649 sec/step, loss=0.07001, avg_loss=0.07501]\n","Step 488920  [4.699 sec/step, loss=0.07399, avg_loss=0.07500]\n","Step 488921  [4.694 sec/step, loss=0.07798, avg_loss=0.07502]\n","Step 488922  [4.624 sec/step, loss=0.06747, avg_loss=0.07493]\n","Step 488923  [4.603 sec/step, loss=0.06895, avg_loss=0.07485]\n","Step 488924  [4.620 sec/step, loss=0.07756, avg_loss=0.07489]\n","Step 488925  [4.651 sec/step, loss=0.07795, avg_loss=0.07499]\n","Step 488926  [4.694 sec/step, loss=0.07758, avg_loss=0.07498]\n","Step 488927  [4.670 sec/step, loss=0.07365, avg_loss=0.07494]\n","Step 488928  [4.652 sec/step, loss=0.07716, avg_loss=0.07492]\n","Step 488929  [4.559 sec/step, loss=0.07314, avg_loss=0.07486]\n","Step 488930  [4.545 sec/step, loss=0.07759, avg_loss=0.07486]\n","Step 488931  [4.507 sec/step, loss=0.06859, avg_loss=0.07476]\n","Step 488932  [4.523 sec/step, loss=0.07584, avg_loss=0.07480]\n","Step 488933  [4.541 sec/step, loss=0.07983, avg_loss=0.07483]\n","Step 488934  [4.611 sec/step, loss=0.08028, avg_loss=0.07493]\n","Step 488935  [4.619 sec/step, loss=0.07862, avg_loss=0.07493]\n","Step 488936  [4.614 sec/step, loss=0.07850, avg_loss=0.07493]\n","Step 488937  [4.608 sec/step, loss=0.07267, avg_loss=0.07491]\n","Step 488938  [4.582 sec/step, loss=0.07102, avg_loss=0.07484]\n","Step 488939  [4.567 sec/step, loss=0.07458, avg_loss=0.07483]\n","Step 488940  [4.570 sec/step, loss=0.07934, avg_loss=0.07484]\n","Step 488941  [4.614 sec/step, loss=0.07895, avg_loss=0.07488]\n","Step 488942  [4.624 sec/step, loss=0.07542, avg_loss=0.07491]\n","Generated 32 batches of size 16 in 9.588 sec\n","Step 488943  [4.691 sec/step, loss=0.07963, avg_loss=0.07493]\n","Step 488944  [4.685 sec/step, loss=0.07528, avg_loss=0.07494]\n","Step 488945  [4.709 sec/step, loss=0.07596, avg_loss=0.07503]\n","Step 488946  [4.755 sec/step, loss=0.07792, avg_loss=0.07513]\n","Step 488947  [4.759 sec/step, loss=0.07420, avg_loss=0.07512]\n","Step 488948  [4.719 sec/step, loss=0.06400, avg_loss=0.07504]\n","Step 488949  [4.675 sec/step, loss=0.06821, avg_loss=0.07496]\n","Step 488950  [4.696 sec/step, loss=0.08036, avg_loss=0.07500]\n","Step 488951  [4.698 sec/step, loss=0.07682, avg_loss=0.07500]\n","Step 488952  [4.685 sec/step, loss=0.07823, avg_loss=0.07498]\n","Step 488953  [4.684 sec/step, loss=0.07727, avg_loss=0.07498]\n","Step 488954  [4.696 sec/step, loss=0.07402, avg_loss=0.07505]\n","Step 488955  [4.649 sec/step, loss=0.07742, avg_loss=0.07504]\n","Step 488956  [4.655 sec/step, loss=0.06986, avg_loss=0.07511]\n","Step 488957  [4.639 sec/step, loss=0.07202, avg_loss=0.07507]\n","Step 488958  [4.638 sec/step, loss=0.06699, avg_loss=0.07509]\n","Step 488959  [4.665 sec/step, loss=0.08000, avg_loss=0.07509]\n","Step 488960  [4.647 sec/step, loss=0.07538, avg_loss=0.07506]\n","Step 488961  [4.602 sec/step, loss=0.06833, avg_loss=0.07497]\n","Step 488962  [4.567 sec/step, loss=0.07380, avg_loss=0.07490]\n","Step 488963  [4.580 sec/step, loss=0.07669, avg_loss=0.07495]\n","Step 488964  [4.603 sec/step, loss=0.07903, avg_loss=0.07496]\n","Step 488965  [4.613 sec/step, loss=0.07905, avg_loss=0.07499]\n","Step 488966  [4.568 sec/step, loss=0.07216, avg_loss=0.07492]\n","Step 488967  [4.574 sec/step, loss=0.08065, avg_loss=0.07493]\n","Step 488968  [4.649 sec/step, loss=0.07889, avg_loss=0.07495]\n","Step 488969  [4.638 sec/step, loss=0.06336, avg_loss=0.07486]\n","Step 488970  [4.648 sec/step, loss=0.07749, avg_loss=0.07488]\n","Step 488971  [4.674 sec/step, loss=0.07729, avg_loss=0.07496]\n","Step 488972  [4.687 sec/step, loss=0.07649, avg_loss=0.07502]\n","Step 488973  [4.672 sec/step, loss=0.06738, avg_loss=0.07495]\n","Step 488974  [4.646 sec/step, loss=0.07157, avg_loss=0.07489]\n","Generated 32 batches of size 16 in 9.363 sec\n","Step 488975  [4.721 sec/step, loss=0.08008, avg_loss=0.07492]\n","Step 488976  [4.730 sec/step, loss=0.08118, avg_loss=0.07496]\n","Step 488977  [4.696 sec/step, loss=0.07774, avg_loss=0.07495]\n","Step 488978  [4.703 sec/step, loss=0.07409, avg_loss=0.07505]\n","Step 488979  [4.727 sec/step, loss=0.07530, avg_loss=0.07512]\n","Step 488980  [4.667 sec/step, loss=0.07581, avg_loss=0.07509]\n","Step 488981  [4.714 sec/step, loss=0.07845, avg_loss=0.07513]\n","Step 488982  [4.720 sec/step, loss=0.07697, avg_loss=0.07517]\n","Step 488983  [4.708 sec/step, loss=0.07397, avg_loss=0.07514]\n","Step 488984  [4.698 sec/step, loss=0.07698, avg_loss=0.07512]\n","Step 488985  [4.750 sec/step, loss=0.07925, avg_loss=0.07526]\n","Step 488986  [4.653 sec/step, loss=0.07085, avg_loss=0.07520]\n","Step 488987  [4.681 sec/step, loss=0.08011, avg_loss=0.07526]\n","Step 488988  [4.642 sec/step, loss=0.06820, avg_loss=0.07515]\n","Step 488989  [4.637 sec/step, loss=0.07634, avg_loss=0.07514]\n","Step 488990  [4.662 sec/step, loss=0.07798, avg_loss=0.07519]\n","Step 488991  [4.635 sec/step, loss=0.06068, avg_loss=0.07502]\n","Step 488992  [4.687 sec/step, loss=0.07985, avg_loss=0.07519]\n","Step 488993  [4.677 sec/step, loss=0.07039, avg_loss=0.07513]\n","Step 488994  [4.674 sec/step, loss=0.06260, avg_loss=0.07506]\n","Step 488995  [4.697 sec/step, loss=0.07752, avg_loss=0.07507]\n","Step 488996  [4.676 sec/step, loss=0.07359, avg_loss=0.07504]\n","Step 488997  [4.676 sec/step, loss=0.07956, avg_loss=0.07504]\n","Step 488998  [4.643 sec/step, loss=0.07391, avg_loss=0.07500]\n","Step 488999  [4.585 sec/step, loss=0.07484, avg_loss=0.07495]\n","Step 489000  [4.563 sec/step, loss=0.07750, avg_loss=0.07493]\n","Writing summary at step: 489000\n","Saving checkpoint to: /content/drive/My Drive/trump_public/logs-tacotron/model.ckpt-489000\n","Saving audio and alignment...\n","Input: network effects can be powerful but you never recap them unless your product is valuable to his very first users when the network is necessarily small~_________\n","Step 489001  [4.577 sec/step, loss=0.07723, avg_loss=0.07496]\n","Step 489002  [4.667 sec/step, loss=0.07814, avg_loss=0.07502]\n","Step 489003  [4.631 sec/step, loss=0.07681, avg_loss=0.07500]\n","Step 489004  [4.598 sec/step, loss=0.07352, avg_loss=0.07495]\n","Generated 32 batches of size 16 in 9.836 sec\n","Step 489005  [4.690 sec/step, loss=0.08010, avg_loss=0.07498]\n","Step 489006  [4.687 sec/step, loss=0.07310, avg_loss=0.07496]\n","Step 489007  [4.687 sec/step, loss=0.07669, avg_loss=0.07495]\n","Step 489008  [4.696 sec/step, loss=0.07799, avg_loss=0.07497]\n","Step 489009  [4.659 sec/step, loss=0.06746, avg_loss=0.07486]\n","Step 489010  [4.607 sec/step, loss=0.07257, avg_loss=0.07484]\n","Step 489011  [4.622 sec/step, loss=0.07890, avg_loss=0.07491]\n","Step 489012  [4.650 sec/step, loss=0.07715, avg_loss=0.07500]\n","Step 489013  [4.673 sec/step, loss=0.07785, avg_loss=0.07517]\n","Step 489014  [4.690 sec/step, loss=0.07989, avg_loss=0.07521]\n","Step 489015  [4.614 sec/step, loss=0.07699, avg_loss=0.07520]\n","Step 489016  [4.645 sec/step, loss=0.07943, avg_loss=0.07526]\n","Step 489017  [4.645 sec/step, loss=0.07673, avg_loss=0.07526]\n","Step 489018  [4.655 sec/step, loss=0.07978, avg_loss=0.07526]\n","Step 489019  [4.712 sec/step, loss=0.07820, avg_loss=0.07535]\n","Step 489020  [4.694 sec/step, loss=0.07933, avg_loss=0.07540]\n","Step 489021  [4.713 sec/step, loss=0.07872, avg_loss=0.07541]\n","Step 489022  [4.737 sec/step, loss=0.07540, avg_loss=0.07549]\n","Step 489023  [4.839 sec/step, loss=0.07670, avg_loss=0.07556]\n","Step 489024  [4.861 sec/step, loss=0.07738, avg_loss=0.07556]\n","Step 489025  [4.859 sec/step, loss=0.07719, avg_loss=0.07556]\n","Step 489026  [4.751 sec/step, loss=0.06647, avg_loss=0.07544]\n","Step 489027  [4.762 sec/step, loss=0.07389, avg_loss=0.07545]\n","Step 489028  [4.753 sec/step, loss=0.07660, avg_loss=0.07544]\n","Step 489029  [4.779 sec/step, loss=0.07544, avg_loss=0.07546]\n","Step 489030  [4.762 sec/step, loss=0.07339, avg_loss=0.07542]\n","Step 489031  [4.769 sec/step, loss=0.06986, avg_loss=0.07543]\n","Step 489032  [4.765 sec/step, loss=0.07574, avg_loss=0.07543]\n","Step 489033  [4.733 sec/step, loss=0.06930, avg_loss=0.07533]\n","Step 489034  [4.667 sec/step, loss=0.07301, avg_loss=0.07526]\n","Step 489035  [4.634 sec/step, loss=0.06196, avg_loss=0.07509]\n","Step 489036  [4.627 sec/step, loss=0.07785, avg_loss=0.07508]\n","Generated 32 batches of size 16 in 9.281 sec\n","Step 489037  [4.699 sec/step, loss=0.07722, avg_loss=0.07513]\n","Step 489038  [4.732 sec/step, loss=0.07857, avg_loss=0.07520]\n","Step 489039  [4.732 sec/step, loss=0.07272, avg_loss=0.07518]\n","Step 489040  [4.768 sec/step, loss=0.07831, avg_loss=0.07517]\n","Step 489041  [4.713 sec/step, loss=0.06740, avg_loss=0.07506]\n","Step 489042  [4.705 sec/step, loss=0.07314, avg_loss=0.07504]\n","Step 489043  [4.603 sec/step, loss=0.06851, avg_loss=0.07492]\n","Step 489044  [4.605 sec/step, loss=0.07279, avg_loss=0.07490]\n","Step 489045  [4.606 sec/step, loss=0.07686, avg_loss=0.07491]\n","Step 489046  [4.566 sec/step, loss=0.06766, avg_loss=0.07481]\n","Step 489047  [4.585 sec/step, loss=0.07838, avg_loss=0.07485]\n","Step 489048  [4.587 sec/step, loss=0.06715, avg_loss=0.07488]\n","Step 489049  [4.631 sec/step, loss=0.07894, avg_loss=0.07499]\n","Step 489050  [4.608 sec/step, loss=0.07582, avg_loss=0.07494]\n","Step 489051  [4.630 sec/step, loss=0.07984, avg_loss=0.07497]\n","Step 489052  [4.614 sec/step, loss=0.07628, avg_loss=0.07495]\n","Step 489053  [4.670 sec/step, loss=0.08056, avg_loss=0.07499]\n","Step 489054  [4.659 sec/step, loss=0.07060, avg_loss=0.07495]\n","Step 489055  [4.626 sec/step, loss=0.06342, avg_loss=0.07481]\n","Step 489056  [4.673 sec/step, loss=0.07977, avg_loss=0.07491]\n","Step 489057  [4.688 sec/step, loss=0.07460, avg_loss=0.07494]\n","Step 489058  [4.694 sec/step, loss=0.06783, avg_loss=0.07494]\n","Step 489059  [4.649 sec/step, loss=0.07640, avg_loss=0.07491]\n","Step 489060  [4.644 sec/step, loss=0.07148, avg_loss=0.07487]\n","Step 489061  [4.661 sec/step, loss=0.07411, avg_loss=0.07493]\n","Step 489062  [4.685 sec/step, loss=0.07911, avg_loss=0.07498]\n","Step 489063  [4.680 sec/step, loss=0.07488, avg_loss=0.07496]\n","Step 489064  [4.688 sec/step, loss=0.08019, avg_loss=0.07497]\n","Step 489065  [4.668 sec/step, loss=0.07656, avg_loss=0.07495]\n","Step 489066  [4.692 sec/step, loss=0.07701, avg_loss=0.07500]\n","Step 489067  [4.674 sec/step, loss=0.07763, avg_loss=0.07497]\n","Step 489068  [4.602 sec/step, loss=0.07568, avg_loss=0.07494]\n","Generated 32 batches of size 16 in 10.238 sec\n","Step 489069  [4.727 sec/step, loss=0.07357, avg_loss=0.07504]\n","Step 489070  [4.729 sec/step, loss=0.07714, avg_loss=0.07503]\n","Step 489071  [4.706 sec/step, loss=0.07309, avg_loss=0.07499]\n","Step 489072  [4.703 sec/step, loss=0.07161, avg_loss=0.07494]\n","Step 489073  [4.700 sec/step, loss=0.06702, avg_loss=0.07494]\n","Step 489074  [4.722 sec/step, loss=0.07766, avg_loss=0.07500]\n","Step 489075  [4.679 sec/step, loss=0.07806, avg_loss=0.07498]\n","Step 489076  [4.749 sec/step, loss=0.07804, avg_loss=0.07495]\n","Step 489077  [4.715 sec/step, loss=0.07310, avg_loss=0.07490]\n","Step 489078  [4.753 sec/step, loss=0.07707, avg_loss=0.07493]\n","Step 489079  [4.755 sec/step, loss=0.07624, avg_loss=0.07494]\n","Step 489080  [4.768 sec/step, loss=0.07874, avg_loss=0.07497]\n","Step 489081  [4.789 sec/step, loss=0.07916, avg_loss=0.07498]\n","Step 489082  [4.775 sec/step, loss=0.07177, avg_loss=0.07493]\n","Step 489083  [4.779 sec/step, loss=0.07430, avg_loss=0.07493]\n","Step 489084  [4.859 sec/step, loss=0.07756, avg_loss=0.07494]\n","Step 489085  [4.862 sec/step, loss=0.07896, avg_loss=0.07493]\n","Step 489086  [4.866 sec/step, loss=0.07205, avg_loss=0.07494]\n","Step 489087  [4.860 sec/step, loss=0.07896, avg_loss=0.07493]\n","Step 489088  [4.868 sec/step, loss=0.07084, avg_loss=0.07496]\n","Step 489089  [4.845 sec/step, loss=0.07233, avg_loss=0.07492]\n","Step 489090  [4.805 sec/step, loss=0.06507, avg_loss=0.07479]\n","Step 489091  [4.850 sec/step, loss=0.08004, avg_loss=0.07498]\n","Step 489092  [4.860 sec/step, loss=0.08017, avg_loss=0.07499]\n","Step 489093  [4.878 sec/step, loss=0.07809, avg_loss=0.07506]\n","Step 489094  [4.893 sec/step, loss=0.07725, avg_loss=0.07521]\n","Step 489095  [4.851 sec/step, loss=0.06512, avg_loss=0.07509]\n","Step 489096  [4.852 sec/step, loss=0.07403, avg_loss=0.07509]\n","Step 489097  [4.810 sec/step, loss=0.06617, avg_loss=0.07496]\n","Step 489098  [4.818 sec/step, loss=0.07703, avg_loss=0.07499]\n","Step 489099  [4.816 sec/step, loss=0.07435, avg_loss=0.07498]\n","Step 489100  [4.789 sec/step, loss=0.06771, avg_loss=0.07489]\n","Writing summary at step: 489100\n","Generated 32 batches of size 16 in 10.088 sec\n","Step 489101  [4.799 sec/step, loss=0.07822, avg_loss=0.07490]\n","Step 489102  [4.754 sec/step, loss=0.07909, avg_loss=0.07490]\n","Step 489103  [4.759 sec/step, loss=0.07796, avg_loss=0.07492]\n","Step 489104  [4.773 sec/step, loss=0.07347, avg_loss=0.07492]\n","Step 489105  [4.699 sec/step, loss=0.07568, avg_loss=0.07487]\n","Step 489106  [4.714 sec/step, loss=0.07821, avg_loss=0.07492]\n","Step 489107  [4.717 sec/step, loss=0.07585, avg_loss=0.07491]\n","Step 489108  [4.723 sec/step, loss=0.07652, avg_loss=0.07490]\n","Step 489109  [4.751 sec/step, loss=0.07638, avg_loss=0.07499]\n","Step 489110  [4.794 sec/step, loss=0.08015, avg_loss=0.07506]\n","Step 489111  [4.739 sec/step, loss=0.07048, avg_loss=0.07498]\n","Step 489112  [4.728 sec/step, loss=0.07403, avg_loss=0.07495]\n","Step 489113  [4.700 sec/step, loss=0.06679, avg_loss=0.07484]\n","Step 489114  [4.755 sec/step, loss=0.07725, avg_loss=0.07481]\n","Step 489115  [4.733 sec/step, loss=0.06795, avg_loss=0.07472]\n","Step 489116  [4.691 sec/step, loss=0.06517, avg_loss=0.07458]\n","Step 489117  [4.658 sec/step, loss=0.06604, avg_loss=0.07447]\n","Step 489118  [4.665 sec/step, loss=0.07875, avg_loss=0.07446]\n","Step 489119  [4.635 sec/step, loss=0.07546, avg_loss=0.07443]\n","Step 489120  [4.606 sec/step, loss=0.07619, avg_loss=0.07440]\n","Step 489121  [4.563 sec/step, loss=0.06703, avg_loss=0.07429]\n","Step 489122  [4.561 sec/step, loss=0.07536, avg_loss=0.07429]\n","Step 489123  [4.466 sec/step, loss=0.07196, avg_loss=0.07424]\n","Step 489124  [4.453 sec/step, loss=0.07816, avg_loss=0.07425]\n","Step 489125  [4.438 sec/step, loss=0.07175, avg_loss=0.07419]\n","Step 489126  [4.455 sec/step, loss=0.07294, avg_loss=0.07426]\n","Step 489127  [4.471 sec/step, loss=0.07829, avg_loss=0.07430]\n","Step 489128  [4.524 sec/step, loss=0.07933, avg_loss=0.07433]\n","Step 489129  [4.499 sec/step, loss=0.07430, avg_loss=0.07432]\n","Step 489130  [4.530 sec/step, loss=0.07905, avg_loss=0.07437]\n","Step 489131  [4.544 sec/step, loss=0.07401, avg_loss=0.07441]\n","Generated 32 batches of size 16 in 9.446 sec\n","Step 489132  [4.601 sec/step, loss=0.07696, avg_loss=0.07443]\n","Step 489133  [4.646 sec/step, loss=0.07761, avg_loss=0.07451]\n","Step 489134  [4.689 sec/step, loss=0.07875, avg_loss=0.07457]\n","Step 489135  [4.720 sec/step, loss=0.07817, avg_loss=0.07473]\n","Step 489136  [4.721 sec/step, loss=0.07672, avg_loss=0.07472]\n","Step 489137  [4.692 sec/step, loss=0.07975, avg_loss=0.07474]\n","Step 489138  [4.672 sec/step, loss=0.07489, avg_loss=0.07471]\n","Step 489139  [4.683 sec/step, loss=0.07685, avg_loss=0.07475]\n","Step 489140  [4.647 sec/step, loss=0.07905, avg_loss=0.07476]\n","Step 489141  [4.666 sec/step, loss=0.07505, avg_loss=0.07483]\n","Step 489142  [4.675 sec/step, loss=0.07431, avg_loss=0.07484]\n","Step 489143  [4.688 sec/step, loss=0.07399, avg_loss=0.07490]\n","Step 489144  [4.736 sec/step, loss=0.07785, avg_loss=0.07495]\n","Step 489145  [4.758 sec/step, loss=0.07891, avg_loss=0.07497]\n","Step 489146  [4.770 sec/step, loss=0.07277, avg_loss=0.07502]\n","Step 489147  [4.756 sec/step, loss=0.07658, avg_loss=0.07500]\n","Step 489148  [4.863 sec/step, loss=0.07753, avg_loss=0.07511]\n","Step 489149  [4.832 sec/step, loss=0.07115, avg_loss=0.07503]\n","Step 489150  [4.830 sec/step, loss=0.07619, avg_loss=0.07503]\n","Step 489151  [4.840 sec/step, loss=0.07982, avg_loss=0.07503]\n","Step 489152  [4.830 sec/step, loss=0.07314, avg_loss=0.07500]\n","Step 489153  [4.753 sec/step, loss=0.06499, avg_loss=0.07484]\n","Step 489154  [4.796 sec/step, loss=0.08024, avg_loss=0.07494]\n","Step 489155  [4.816 sec/step, loss=0.07606, avg_loss=0.07507]\n","Step 489156  [4.802 sec/step, loss=0.07863, avg_loss=0.07506]\n","Step 489157  [4.783 sec/step, loss=0.07134, avg_loss=0.07502]\n","Step 489158  [4.780 sec/step, loss=0.06663, avg_loss=0.07501]\n","Step 489159  [4.781 sec/step, loss=0.07676, avg_loss=0.07502]\n","Step 489160  [4.787 sec/step, loss=0.07337, avg_loss=0.07503]\n","Step 489161  [4.765 sec/step, loss=0.06473, avg_loss=0.07494]\n","Step 489162  [4.764 sec/step, loss=0.07901, avg_loss=0.07494]\n","Step 489163  [4.794 sec/step, loss=0.07661, avg_loss=0.07496]\n","Step 489164  [4.814 sec/step, loss=0.07645, avg_loss=0.07492]\n","Generated 32 batches of size 16 in 9.249 sec\n","Step 489165  [4.817 sec/step, loss=0.07731, avg_loss=0.07493]\n","Step 489166  [4.780 sec/step, loss=0.06915, avg_loss=0.07485]\n","Step 489167  [4.779 sec/step, loss=0.07800, avg_loss=0.07485]\n","Step 489168  [4.758 sec/step, loss=0.07102, avg_loss=0.07480]\n","Step 489169  [4.669 sec/step, loss=0.07602, avg_loss=0.07483]\n","Step 489170  [4.721 sec/step, loss=0.07910, avg_loss=0.07485]\n","Step 489171  [4.760 sec/step, loss=0.07944, avg_loss=0.07491]\n","Step 489172  [4.784 sec/step, loss=0.07606, avg_loss=0.07496]\n","Step 489173  [4.808 sec/step, loss=0.07287, avg_loss=0.07502]\n","Step 489174  [4.786 sec/step, loss=0.07001, avg_loss=0.07494]\n","Step 489175  [4.778 sec/step, loss=0.07864, avg_loss=0.07494]\n","Step 489176  [4.717 sec/step, loss=0.07946, avg_loss=0.07496]\n","Step 489177  [4.757 sec/step, loss=0.07930, avg_loss=0.07502]\n","Step 489178  [4.734 sec/step, loss=0.07648, avg_loss=0.07502]\n","Step 489179  [4.738 sec/step, loss=0.07676, avg_loss=0.07502]\n","Step 489180  [4.716 sec/step, loss=0.07679, avg_loss=0.07500]\n","Step 489181  [4.679 sec/step, loss=0.07912, avg_loss=0.07500]\n","Step 489182  [4.715 sec/step, loss=0.07740, avg_loss=0.07506]\n","Step 489183  [4.780 sec/step, loss=0.08025, avg_loss=0.07512]\n","Step 489184  [4.704 sec/step, loss=0.07750, avg_loss=0.07512]\n","Step 489185  [4.662 sec/step, loss=0.07276, avg_loss=0.07505]\n","Step 489186  [4.652 sec/step, loss=0.06753, avg_loss=0.07501]\n","Step 489187  [4.634 sec/step, loss=0.07502, avg_loss=0.07497]\n","Step 489188  [4.634 sec/step, loss=0.07002, avg_loss=0.07496]\n","Step 489189  [4.640 sec/step, loss=0.07298, avg_loss=0.07497]\n","Step 489190  [4.696 sec/step, loss=0.07890, avg_loss=0.07511]\n","Step 489191  [4.722 sec/step, loss=0.07392, avg_loss=0.07504]\n","Step 489192  [4.696 sec/step, loss=0.07805, avg_loss=0.07502]\n","Step 489193  [4.671 sec/step, loss=0.06895, avg_loss=0.07493]\n","Step 489194  [4.675 sec/step, loss=0.07679, avg_loss=0.07493]\n","Step 489195  [4.730 sec/step, loss=0.07805, avg_loss=0.07506]\n","Step 489196  [4.771 sec/step, loss=0.07276, avg_loss=0.07504]\n","Generated 32 batches of size 16 in 9.884 sec\n","Step 489197  [4.813 sec/step, loss=0.07772, avg_loss=0.07516]\n","Step 489198  [4.832 sec/step, loss=0.07586, avg_loss=0.07515]\n","Step 489199  [4.834 sec/step, loss=0.07489, avg_loss=0.07515]\n","Step 489200  [4.942 sec/step, loss=0.07706, avg_loss=0.07525]\n","Writing summary at step: 489200\n","Step 489201  [4.920 sec/step, loss=0.07379, avg_loss=0.07520]\n","Step 489202  [4.889 sec/step, loss=0.07667, avg_loss=0.07518]\n","Step 489203  [4.861 sec/step, loss=0.06709, avg_loss=0.07507]\n","Step 489204  [4.885 sec/step, loss=0.07719, avg_loss=0.07511]\n","Step 489205  [4.887 sec/step, loss=0.07880, avg_loss=0.07514]\n","Step 489206  [4.909 sec/step, loss=0.07980, avg_loss=0.07515]\n","Step 489207  [4.924 sec/step, loss=0.07906, avg_loss=0.07519]\n","Step 489208  [4.897 sec/step, loss=0.07243, avg_loss=0.07514]\n","Step 489209  [4.869 sec/step, loss=0.06386, avg_loss=0.07502]\n","Step 489210  [4.891 sec/step, loss=0.07996, avg_loss=0.07502]\n","Step 489211  [4.910 sec/step, loss=0.07648, avg_loss=0.07508]\n","Step 489212  [4.912 sec/step, loss=0.07712, avg_loss=0.07511]\n","Step 489213  [4.936 sec/step, loss=0.07722, avg_loss=0.07521]\n","Step 489214  [4.860 sec/step, loss=0.07742, avg_loss=0.07521]\n","Step 489215  [4.891 sec/step, loss=0.07612, avg_loss=0.07530]\n","Step 489216  [4.957 sec/step, loss=0.07892, avg_loss=0.07543]\n","Step 489217  [5.011 sec/step, loss=0.07997, avg_loss=0.07557]\n","Step 489218  [4.944 sec/step, loss=0.06616, avg_loss=0.07545]\n","Step 489219  [5.020 sec/step, loss=0.07806, avg_loss=0.07547]\n","Step 489220  [5.042 sec/step, loss=0.07897, avg_loss=0.07550]\n","Step 489221  [5.046 sec/step, loss=0.06104, avg_loss=0.07544]\n","Step 489222  [5.048 sec/step, loss=0.07505, avg_loss=0.07544]\n","Step 489223  [5.046 sec/step, loss=0.06964, avg_loss=0.07541]\n","Step 489224  [5.047 sec/step, loss=0.07842, avg_loss=0.07542]\n","Step 489225  [5.084 sec/step, loss=0.07949, avg_loss=0.07549]\n","Step 489226  [5.085 sec/step, loss=0.07473, avg_loss=0.07551]\n","Step 489227  [5.116 sec/step, loss=0.07702, avg_loss=0.07550]\n","Generated 32 batches of size 16 in 9.240 sec\n","Step 489228  [5.051 sec/step, loss=0.07292, avg_loss=0.07544]\n","Step 489229  [5.063 sec/step, loss=0.07248, avg_loss=0.07542]\n","Step 489230  [5.026 sec/step, loss=0.06983, avg_loss=0.07533]\n","Step 489231  [5.003 sec/step, loss=0.06832, avg_loss=0.07527]\n","Step 489232  [4.952 sec/step, loss=0.07724, avg_loss=0.07527]\n","Step 489233  [4.919 sec/step, loss=0.07236, avg_loss=0.07522]\n","Step 489234  [4.885 sec/step, loss=0.07279, avg_loss=0.07516]\n","Step 489235  [4.881 sec/step, loss=0.07698, avg_loss=0.07515]\n","Step 489236  [4.876 sec/step, loss=0.07601, avg_loss=0.07514]\n","Step 489237  [4.864 sec/step, loss=0.07857, avg_loss=0.07513]\n","Step 489238  [4.962 sec/step, loss=0.07700, avg_loss=0.07515]\n","Step 489239  [4.957 sec/step, loss=0.07525, avg_loss=0.07513]\n","Step 489240  [4.911 sec/step, loss=0.06671, avg_loss=0.07501]\n","Step 489241  [4.896 sec/step, loss=0.06697, avg_loss=0.07493]\n","Step 489242  [4.910 sec/step, loss=0.07782, avg_loss=0.07496]\n","Step 489243  [4.934 sec/step, loss=0.07580, avg_loss=0.07498]\n","Step 489244  [4.886 sec/step, loss=0.07551, avg_loss=0.07496]\n","Step 489245  [4.844 sec/step, loss=0.06414, avg_loss=0.07481]\n","Step 489246  [4.875 sec/step, loss=0.07956, avg_loss=0.07488]\n","Step 489247  [4.910 sec/step, loss=0.07848, avg_loss=0.07490]\n","Step 489248  [4.825 sec/step, loss=0.07421, avg_loss=0.07487]\n","Step 489249  [4.845 sec/step, loss=0.07712, avg_loss=0.07492]\n","Step 489250  [4.832 sec/step, loss=0.07118, avg_loss=0.07487]\n","Step 489251  [4.778 sec/step, loss=0.06884, avg_loss=0.07476]\n","Step 489252  [4.783 sec/step, loss=0.07147, avg_loss=0.07475]\n","Step 489253  [4.790 sec/step, loss=0.07332, avg_loss=0.07483]\n","Step 489254  [4.792 sec/step, loss=0.07961, avg_loss=0.07483]\n","Step 489255  [4.803 sec/step, loss=0.07751, avg_loss=0.07484]\n","Step 489256  [4.772 sec/step, loss=0.07019, avg_loss=0.07476]\n","Step 489257  [4.786 sec/step, loss=0.07618, avg_loss=0.07480]\n","Step 489258  [4.829 sec/step, loss=0.07919, avg_loss=0.07493]\n","Generated 32 batches of size 16 in 10.448 sec\n","Step 489259  [4.925 sec/step, loss=0.07879, avg_loss=0.07495]\n","Step 489260  [4.936 sec/step, loss=0.07742, avg_loss=0.07499]\n","Step 489261  [4.982 sec/step, loss=0.07920, avg_loss=0.07514]\n","Step 489262  [4.958 sec/step, loss=0.07461, avg_loss=0.07509]\n","Step 489263  [4.908 sec/step, loss=0.06728, avg_loss=0.07500]\n","Step 489264  [4.878 sec/step, loss=0.07791, avg_loss=0.07501]\n","Step 489265  [4.861 sec/step, loss=0.07437, avg_loss=0.07498]\n","Step 489266  [4.887 sec/step, loss=0.07692, avg_loss=0.07506]\n","Step 489267  [4.908 sec/step, loss=0.08031, avg_loss=0.07508]\n","Step 489268  [4.923 sec/step, loss=0.07719, avg_loss=0.07515]\n","Step 489269  [4.938 sec/step, loss=0.07723, avg_loss=0.07516]\n","Step 489270  [4.870 sec/step, loss=0.07337, avg_loss=0.07510]\n","Step 489271  [4.822 sec/step, loss=0.06883, avg_loss=0.07499]\n","Step 489272  [4.825 sec/step, loss=0.07853, avg_loss=0.07502]\n","Step 489273  [4.840 sec/step, loss=0.07780, avg_loss=0.07507]\n","Step 489274  [4.886 sec/step, loss=0.07963, avg_loss=0.07516]\n","Step 489275  [4.875 sec/step, loss=0.07683, avg_loss=0.07515]\n","Step 489276  [4.827 sec/step, loss=0.06735, avg_loss=0.07502]\n","Step 489277  [4.815 sec/step, loss=0.07893, avg_loss=0.07502]\n","Step 489278  [4.845 sec/step, loss=0.07977, avg_loss=0.07505]\n","Step 489279  [4.853 sec/step, loss=0.07593, avg_loss=0.07505]\n","Step 489280  [4.884 sec/step, loss=0.07953, avg_loss=0.07507]\n","Step 489281  [4.851 sec/step, loss=0.07324, avg_loss=0.07501]\n","Step 489282  [4.835 sec/step, loss=0.07760, avg_loss=0.07502]\n","Step 489283  [4.859 sec/step, loss=0.07699, avg_loss=0.07498]\n","Step 489284  [4.867 sec/step, loss=0.07987, avg_loss=0.07501]\n","Step 489285  [4.920 sec/step, loss=0.07908, avg_loss=0.07507]\n","Step 489286  [4.916 sec/step, loss=0.06544, avg_loss=0.07505]\n","Step 489287  [4.905 sec/step, loss=0.07320, avg_loss=0.07503]\n","Step 489288  [4.922 sec/step, loss=0.07858, avg_loss=0.07512]\n","Step 489289  [4.938 sec/step, loss=0.07543, avg_loss=0.07514]\n","Step 489290  [4.906 sec/step, loss=0.07632, avg_loss=0.07512]\n","Generated 32 batches of size 16 in 9.268 sec\n","Step 489291  [4.920 sec/step, loss=0.07803, avg_loss=0.07516]\n","Step 489292  [4.892 sec/step, loss=0.06650, avg_loss=0.07504]\n","Step 489293  [4.906 sec/step, loss=0.07589, avg_loss=0.07511]\n","Step 489294  [4.892 sec/step, loss=0.07235, avg_loss=0.07507]\n","Step 489295  [4.860 sec/step, loss=0.07873, avg_loss=0.07507]\n","Step 489296  [4.826 sec/step, loss=0.07673, avg_loss=0.07511]\n","Step 489297  [4.803 sec/step, loss=0.07533, avg_loss=0.07509]\n","Step 489298  [4.845 sec/step, loss=0.08094, avg_loss=0.07514]\n","Step 489299  [4.835 sec/step, loss=0.07511, avg_loss=0.07514]\n","Step 489300  [4.739 sec/step, loss=0.07496, avg_loss=0.07512]\n","Writing summary at step: 489300\n","Step 489301  [4.751 sec/step, loss=0.07657, avg_loss=0.07515]\n","Step 489302  [4.748 sec/step, loss=0.07821, avg_loss=0.07516]\n","Step 489303  [4.795 sec/step, loss=0.07977, avg_loss=0.07529]\n","Step 489304  [4.754 sec/step, loss=0.07210, avg_loss=0.07524]\n","Step 489305  [4.739 sec/step, loss=0.07500, avg_loss=0.07520]\n","Step 489306  [4.704 sec/step, loss=0.07644, avg_loss=0.07517]\n","Step 489307  [4.670 sec/step, loss=0.07354, avg_loss=0.07511]\n","Step 489308  [4.664 sec/step, loss=0.07090, avg_loss=0.07510]\n","Step 489309  [4.664 sec/step, loss=0.06434, avg_loss=0.07510]\n","Step 489310  [4.667 sec/step, loss=0.07964, avg_loss=0.07510]\n","Step 489311  [4.710 sec/step, loss=0.07585, avg_loss=0.07509]\n","Step 489312  [4.701 sec/step, loss=0.07504, avg_loss=0.07507]\n","Step 489313  [4.712 sec/step, loss=0.07931, avg_loss=0.07509]\n","Step 489314  [4.786 sec/step, loss=0.08079, avg_loss=0.07513]\n","Step 489315  [4.759 sec/step, loss=0.07271, avg_loss=0.07509]\n","Step 489316  [4.726 sec/step, loss=0.07706, avg_loss=0.07507]\n","Step 489317  [4.707 sec/step, loss=0.07671, avg_loss=0.07504]\n","Step 489318  [4.769 sec/step, loss=0.07929, avg_loss=0.07517]\n","Step 489319  [4.701 sec/step, loss=0.07947, avg_loss=0.07519]\n","Step 489320  [4.691 sec/step, loss=0.07844, avg_loss=0.07518]\n","Step 489321  [4.706 sec/step, loss=0.07504, avg_loss=0.07532]\n","Generated 32 batches of size 16 in 9.085 sec\n","Step 489322  [4.766 sec/step, loss=0.07736, avg_loss=0.07534]\n","Step 489323  [4.788 sec/step, loss=0.07768, avg_loss=0.07542]\n","Step 489324  [4.766 sec/step, loss=0.07226, avg_loss=0.07536]\n","Step 489325  [4.710 sec/step, loss=0.06679, avg_loss=0.07524]\n","Step 489326  [4.750 sec/step, loss=0.07985, avg_loss=0.07529]\n","Step 489327  [4.680 sec/step, loss=0.06750, avg_loss=0.07519]\n","Step 489328  [4.703 sec/step, loss=0.07605, avg_loss=0.07522]\n","Step 489329  [4.680 sec/step, loss=0.06945, avg_loss=0.07519]\n","Step 489330  [4.721 sec/step, loss=0.07805, avg_loss=0.07528]\n","Step 489331  [4.759 sec/step, loss=0.07596, avg_loss=0.07535]\n","Step 489332  [4.835 sec/step, loss=0.07816, avg_loss=0.07536]\n","Step 489333  [4.841 sec/step, loss=0.07657, avg_loss=0.07540]\n","Step 489334  [4.831 sec/step, loss=0.07040, avg_loss=0.07538]\n","Step 489335  [4.852 sec/step, loss=0.07948, avg_loss=0.07540]\n","Step 489336  [4.862 sec/step, loss=0.07973, avg_loss=0.07544]\n","Step 489337  [4.869 sec/step, loss=0.07767, avg_loss=0.07543]\n","Step 489338  [4.768 sec/step, loss=0.07460, avg_loss=0.07541]\n","Step 489339  [4.755 sec/step, loss=0.07421, avg_loss=0.07540]\n","Step 489340  [4.764 sec/step, loss=0.06968, avg_loss=0.07543]\n","Step 489341  [4.760 sec/step, loss=0.06788, avg_loss=0.07544]\n","Step 489342  [4.759 sec/step, loss=0.07751, avg_loss=0.07543]\n","Step 489343  [4.782 sec/step, loss=0.07927, avg_loss=0.07547]\n","Step 489344  [4.806 sec/step, loss=0.07897, avg_loss=0.07550]\n","Step 489345  [4.840 sec/step, loss=0.07800, avg_loss=0.07564]\n","Step 489346  [4.802 sec/step, loss=0.07509, avg_loss=0.07560]\n","Step 489347  [4.767 sec/step, loss=0.07631, avg_loss=0.07558]\n","Step 489348  [4.801 sec/step, loss=0.08077, avg_loss=0.07564]\n","Step 489349  [4.784 sec/step, loss=0.07297, avg_loss=0.07560]\n","Step 489350  [4.792 sec/step, loss=0.07515, avg_loss=0.07564]\n","Step 489351  [4.807 sec/step, loss=0.07675, avg_loss=0.07572]\n","Step 489352  [4.836 sec/step, loss=0.07976, avg_loss=0.07580]\n","Step 489353  [4.820 sec/step, loss=0.06613, avg_loss=0.07573]\n","Generated 32 batches of size 16 in 9.091 sec\n","Step 489354  [4.845 sec/step, loss=0.07750, avg_loss=0.07571]\n","Step 489355  [4.819 sec/step, loss=0.06878, avg_loss=0.07562]\n","Step 489356  [4.842 sec/step, loss=0.07692, avg_loss=0.07569]\n","Step 489357  [4.833 sec/step, loss=0.07342, avg_loss=0.07566]\n","Step 489358  [4.843 sec/step, loss=0.07930, avg_loss=0.07566]\n","Step 489359  [4.795 sec/step, loss=0.07762, avg_loss=0.07565]\n","Step 489360  [4.790 sec/step, loss=0.07597, avg_loss=0.07564]\n","Step 489361  [4.746 sec/step, loss=0.06381, avg_loss=0.07548]\n","Step 489362  [4.756 sec/step, loss=0.07714, avg_loss=0.07551]\n","Step 489363  [4.800 sec/step, loss=0.08010, avg_loss=0.07563]\n","Step 489364  [4.860 sec/step, loss=0.07711, avg_loss=0.07563]\n","Step 489365  [4.898 sec/step, loss=0.07700, avg_loss=0.07565]\n","Step 489366  [4.911 sec/step, loss=0.07890, avg_loss=0.07567]\n","Step 489367  [4.860 sec/step, loss=0.06981, avg_loss=0.07557]\n","Step 489368  [4.861 sec/step, loss=0.07650, avg_loss=0.07556]\n","Step 489369  [4.828 sec/step, loss=0.07236, avg_loss=0.07551]\n","Step 489370  [4.824 sec/step, loss=0.07180, avg_loss=0.07550]\n","Step 489371  [4.827 sec/step, loss=0.06998, avg_loss=0.07551]\n","Step 489372  [4.796 sec/step, loss=0.07301, avg_loss=0.07545]\n","Step 489373  [4.782 sec/step, loss=0.07630, avg_loss=0.07544]\n","Step 489374  [4.751 sec/step, loss=0.07490, avg_loss=0.07539]\n","Step 489375  [4.746 sec/step, loss=0.07649, avg_loss=0.07539]\n","Step 489376  [4.779 sec/step, loss=0.07592, avg_loss=0.07547]\n","Step 489377  [4.778 sec/step, loss=0.07615, avg_loss=0.07545]\n","Step 489378  [4.779 sec/step, loss=0.08014, avg_loss=0.07545]\n","Step 489379  [4.770 sec/step, loss=0.07684, avg_loss=0.07546]\n","Step 489380  [4.767 sec/step, loss=0.08014, avg_loss=0.07546]\n","Step 489381  [4.834 sec/step, loss=0.07996, avg_loss=0.07553]\n","Step 489382  [4.822 sec/step, loss=0.07491, avg_loss=0.07550]\n","Step 489383  [4.752 sec/step, loss=0.07792, avg_loss=0.07551]\n","Step 489384  [4.741 sec/step, loss=0.07664, avg_loss=0.07548]\n","Step 489385  [4.704 sec/step, loss=0.07733, avg_loss=0.07546]\n","Generated 32 batches of size 16 in 9.591 sec\n","Step 489386  [4.807 sec/step, loss=0.07893, avg_loss=0.07560]\n","Step 489387  [4.861 sec/step, loss=0.07926, avg_loss=0.07566]\n","Step 489388  [4.886 sec/step, loss=0.07965, avg_loss=0.07567]\n","Step 489389  [4.859 sec/step, loss=0.06684, avg_loss=0.07558]\n","Step 489390  [4.834 sec/step, loss=0.06694, avg_loss=0.07549]\n","Step 489391  [4.762 sec/step, loss=0.07388, avg_loss=0.07545]\n","Step 489392  [4.758 sec/step, loss=0.06750, avg_loss=0.07546]\n","Step 489393  [4.760 sec/step, loss=0.07261, avg_loss=0.07543]\n","Step 489394  [4.749 sec/step, loss=0.06360, avg_loss=0.07534]\n","Step 489395  [4.759 sec/step, loss=0.07683, avg_loss=0.07532]\n","Step 489396  [4.745 sec/step, loss=0.06283, avg_loss=0.07518]\n","Step 489397  [4.733 sec/step, loss=0.07053, avg_loss=0.07513]\n","Step 489398  [4.703 sec/step, loss=0.07941, avg_loss=0.07512]\n","Step 489399  [4.702 sec/step, loss=0.06985, avg_loss=0.07506]\n","Step 489400  [4.711 sec/step, loss=0.07525, avg_loss=0.07507]\n","Writing summary at step: 489400\n","Step 489401  [4.791 sec/step, loss=0.07694, avg_loss=0.07507]\n","Step 489402  [4.779 sec/step, loss=0.07300, avg_loss=0.07502]\n","Step 489403  [4.761 sec/step, loss=0.07655, avg_loss=0.07499]\n","Step 489404  [4.819 sec/step, loss=0.07801, avg_loss=0.07505]\n","Step 489405  [4.809 sec/step, loss=0.07371, avg_loss=0.07503]\n","Step 489406  [4.802 sec/step, loss=0.07311, avg_loss=0.07500]\n","Step 489407  [4.792 sec/step, loss=0.06805, avg_loss=0.07495]\n","Step 489408  [4.832 sec/step, loss=0.07859, avg_loss=0.07502]\n","Step 489409  [4.891 sec/step, loss=0.07978, avg_loss=0.07518]\n","Step 489410  [4.807 sec/step, loss=0.06512, avg_loss=0.07503]\n","Step 489411  [4.775 sec/step, loss=0.07762, avg_loss=0.07505]\n","Step 489412  [4.780 sec/step, loss=0.07460, avg_loss=0.07504]\n","Step 489413  [4.775 sec/step, loss=0.07623, avg_loss=0.07501]\n","Step 489414  [4.695 sec/step, loss=0.07667, avg_loss=0.07497]\n","Step 489415  [4.702 sec/step, loss=0.07249, avg_loss=0.07497]\n","Step 489416  [4.719 sec/step, loss=0.07749, avg_loss=0.07497]\n","Generated 32 batches of size 16 in 10.690 sec\n","Step 489417  [4.822 sec/step, loss=0.07902, avg_loss=0.07500]\n","Step 489418  [4.804 sec/step, loss=0.07825, avg_loss=0.07499]\n","Step 489419  [4.816 sec/step, loss=0.07938, avg_loss=0.07499]\n","Step 489420  [4.825 sec/step, loss=0.07903, avg_loss=0.07499]\n","Step 489421  [4.826 sec/step, loss=0.07280, avg_loss=0.07497]\n","Step 489422  [4.773 sec/step, loss=0.07575, avg_loss=0.07495]\n","Step 489423  [4.775 sec/step, loss=0.07692, avg_loss=0.07495]\n","Step 489424  [4.756 sec/step, loss=0.06501, avg_loss=0.07487]\n","Step 489425  [4.780 sec/step, loss=0.07679, avg_loss=0.07497]\n","Step 489426  [4.757 sec/step, loss=0.07704, avg_loss=0.07495]\n","Step 489427  [4.758 sec/step, loss=0.06802, avg_loss=0.07495]\n","Step 489428  [4.770 sec/step, loss=0.07828, avg_loss=0.07497]\n","Step 489429  [4.803 sec/step, loss=0.07625, avg_loss=0.07504]\n","Step 489430  [4.781 sec/step, loss=0.07229, avg_loss=0.07498]\n","Step 489431  [4.827 sec/step, loss=0.07711, avg_loss=0.07499]\n","Step 489432  [4.730 sec/step, loss=0.07247, avg_loss=0.07494]\n","Step 489433  [4.721 sec/step, loss=0.07288, avg_loss=0.07490]\n","Step 489434  [4.710 sec/step, loss=0.06349, avg_loss=0.07483]\n","Step 489435  [4.725 sec/step, loss=0.07816, avg_loss=0.07482]\n","Step 489436  [4.697 sec/step, loss=0.07290, avg_loss=0.07475]\n","Step 489437  [4.654 sec/step, loss=0.06850, avg_loss=0.07466]\n","Step 489438  [4.686 sec/step, loss=0.07975, avg_loss=0.07471]\n","Step 489439  [4.694 sec/step, loss=0.07300, avg_loss=0.07470]\n","Step 489440  [4.725 sec/step, loss=0.07614, avg_loss=0.07476]\n","Step 489441  [4.782 sec/step, loss=0.07988, avg_loss=0.07488]\n","Step 489442  [4.774 sec/step, loss=0.07717, avg_loss=0.07488]\n","Step 489443  [4.732 sec/step, loss=0.07607, avg_loss=0.07485]\n","Step 489444  [4.718 sec/step, loss=0.07736, avg_loss=0.07483]\n","Step 489445  [4.719 sec/step, loss=0.07804, avg_loss=0.07483]\n","Step 489446  [4.704 sec/step, loss=0.06669, avg_loss=0.07475]\n","Step 489447  [4.786 sec/step, loss=0.07886, avg_loss=0.07477]\n","Step 489448  [4.771 sec/step, loss=0.07882, avg_loss=0.07475]\n","Generated 32 batches of size 16 in 9.521 sec\n","Step 489449  [4.854 sec/step, loss=0.07687, avg_loss=0.07479]\n","Step 489450  [4.888 sec/step, loss=0.07916, avg_loss=0.07483]\n","Step 489451  [4.870 sec/step, loss=0.06688, avg_loss=0.07473]\n","Step 489452  [4.833 sec/step, loss=0.07092, avg_loss=0.07465]\n","Step 489453  [4.857 sec/step, loss=0.07550, avg_loss=0.07474]\n","Step 489454  [4.806 sec/step, loss=0.07700, avg_loss=0.07473]\n","Step 489455  [4.848 sec/step, loss=0.07966, avg_loss=0.07484]\n","Step 489456  [4.830 sec/step, loss=0.07353, avg_loss=0.07481]\n","Step 489457  [4.850 sec/step, loss=0.07643, avg_loss=0.07484]\n","Step 489458  [4.849 sec/step, loss=0.07944, avg_loss=0.07484]\n","Step 489459  [4.807 sec/step, loss=0.07822, avg_loss=0.07485]\n","Step 489460  [4.820 sec/step, loss=0.07754, avg_loss=0.07486]\n","Step 489461  [4.820 sec/step, loss=0.06398, avg_loss=0.07486]\n","Step 489462  [4.822 sec/step, loss=0.07694, avg_loss=0.07486]\n","Step 489463  [4.784 sec/step, loss=0.06942, avg_loss=0.07476]\n","Step 489464  [4.782 sec/step, loss=0.07687, avg_loss=0.07475]\n","Step 489465  [4.791 sec/step, loss=0.07908, avg_loss=0.07477]\n","Step 489466  [4.821 sec/step, loss=0.07412, avg_loss=0.07473]\n","Step 489467  [4.841 sec/step, loss=0.07636, avg_loss=0.07479]\n","Step 489468  [4.836 sec/step, loss=0.07602, avg_loss=0.07479]\n","Step 489469  [4.849 sec/step, loss=0.07667, avg_loss=0.07483]\n","Step 489470  [4.856 sec/step, loss=0.07527, avg_loss=0.07486]\n","Step 489471  [4.868 sec/step, loss=0.07428, avg_loss=0.07491]\n","Step 489472  [4.866 sec/step, loss=0.07002, avg_loss=0.07488]\n","Step 489473  [4.874 sec/step, loss=0.07689, avg_loss=0.07488]\n","Step 489474  [4.903 sec/step, loss=0.07700, avg_loss=0.07490]\n","Step 489475  [4.878 sec/step, loss=0.06741, avg_loss=0.07481]\n","Step 489476  [4.856 sec/step, loss=0.07330, avg_loss=0.07479]\n","Step 489477  [4.845 sec/step, loss=0.07591, avg_loss=0.07479]\n","Step 489478  [4.868 sec/step, loss=0.07981, avg_loss=0.07478]\n","Step 489479  [4.862 sec/step, loss=0.07380, avg_loss=0.07475]\n","Step 489480  [4.808 sec/step, loss=0.06652, avg_loss=0.07462]\n","Generated 32 batches of size 16 in 9.450 sec\n","Step 489481  [4.816 sec/step, loss=0.07682, avg_loss=0.07458]\n","Step 489482  [4.848 sec/step, loss=0.07897, avg_loss=0.07462]\n","Step 489483  [4.830 sec/step, loss=0.07218, avg_loss=0.07457]\n","Step 489484  [4.837 sec/step, loss=0.07517, avg_loss=0.07455]\n","Step 489485  [4.823 sec/step, loss=0.07353, avg_loss=0.07451]\n","Step 489486  [4.771 sec/step, loss=0.07867, avg_loss=0.07451]\n","Step 489487  [4.712 sec/step, loss=0.06156, avg_loss=0.07433]\n","Step 489488  [4.674 sec/step, loss=0.07328, avg_loss=0.07427]\n","Step 489489  [4.717 sec/step, loss=0.07913, avg_loss=0.07439]\n","Step 489490  [4.739 sec/step, loss=0.07454, avg_loss=0.07447]\n","Step 489491  [4.741 sec/step, loss=0.07335, avg_loss=0.07446]\n","Step 489492  [4.784 sec/step, loss=0.07890, avg_loss=0.07458]\n","Step 489493  [4.778 sec/step, loss=0.07271, avg_loss=0.07458]\n","Step 489494  [4.792 sec/step, loss=0.07344, avg_loss=0.07468]\n","Step 489495  [4.803 sec/step, loss=0.07735, avg_loss=0.07468]\n","Step 489496  [4.851 sec/step, loss=0.07919, avg_loss=0.07485]\n","Step 489497  [4.930 sec/step, loss=0.07667, avg_loss=0.07491]\n","Step 489498  [4.911 sec/step, loss=0.07591, avg_loss=0.07487]\n","Step 489499  [4.927 sec/step, loss=0.07400, avg_loss=0.07491]\n","Step 489500  [4.927 sec/step, loss=0.07573, avg_loss=0.07492]\n","Writing summary at step: 489500\n","Step 489501  [4.857 sec/step, loss=0.07773, avg_loss=0.07493]\n","Step 489502  [4.851 sec/step, loss=0.06998, avg_loss=0.07490]\n","Step 489503  [4.823 sec/step, loss=0.06375, avg_loss=0.07477]\n","Step 489504  [4.769 sec/step, loss=0.07174, avg_loss=0.07471]\n","Step 489505  [4.808 sec/step, loss=0.07939, avg_loss=0.07476]\n","Step 489506  [4.802 sec/step, loss=0.06905, avg_loss=0.07472]\n","Step 489507  [4.820 sec/step, loss=0.07380, avg_loss=0.07478]\n","Step 489508  [4.819 sec/step, loss=0.07915, avg_loss=0.07479]\n","Step 489509  [4.761 sec/step, loss=0.06714, avg_loss=0.07466]\n","Step 489510  [4.870 sec/step, loss=0.07752, avg_loss=0.07478]\n","Step 489511  [4.862 sec/step, loss=0.07703, avg_loss=0.07478]\n","Step 489512  [4.860 sec/step, loss=0.06681, avg_loss=0.07470]\n","Generated 32 batches of size 16 in 10.050 sec\n","Step 489513  [4.901 sec/step, loss=0.07855, avg_loss=0.07472]\n","Step 489514  [4.901 sec/step, loss=0.07619, avg_loss=0.07472]\n","Step 489515  [4.940 sec/step, loss=0.07959, avg_loss=0.07479]\n","Step 489516  [4.926 sec/step, loss=0.07704, avg_loss=0.07478]\n","Step 489517  [4.815 sec/step, loss=0.07346, avg_loss=0.07473]\n","Step 489518  [4.803 sec/step, loss=0.07691, avg_loss=0.07472]\n","Step 489519  [4.814 sec/step, loss=0.07923, avg_loss=0.07471]\n","Step 489520  [4.811 sec/step, loss=0.07577, avg_loss=0.07468]\n","Step 489521  [4.897 sec/step, loss=0.07647, avg_loss=0.07472]\n","Step 489522  [4.905 sec/step, loss=0.07647, avg_loss=0.07473]\n","Step 489523  [4.883 sec/step, loss=0.07176, avg_loss=0.07467]\n","Step 489524  [4.924 sec/step, loss=0.07658, avg_loss=0.07479]\n","Step 489525  [4.935 sec/step, loss=0.07605, avg_loss=0.07478]\n","Step 489526  [4.960 sec/step, loss=0.07906, avg_loss=0.07480]\n","Step 489527  [5.015 sec/step, loss=0.08027, avg_loss=0.07492]\n","Step 489528  [4.985 sec/step, loss=0.07577, avg_loss=0.07490]\n","Step 489529  [4.978 sec/step, loss=0.07620, avg_loss=0.07490]\n","Step 489530  [4.995 sec/step, loss=0.07854, avg_loss=0.07496]\n","Step 489531  [4.958 sec/step, loss=0.07843, avg_loss=0.07498]\n","Step 489532  [4.987 sec/step, loss=0.07788, avg_loss=0.07503]\n","Step 489533  [4.969 sec/step, loss=0.06513, avg_loss=0.07495]\n","Step 489534  [4.969 sec/step, loss=0.06480, avg_loss=0.07496]\n","Step 489535  [4.933 sec/step, loss=0.07731, avg_loss=0.07496]\n","Step 489536  [4.999 sec/step, loss=0.07961, avg_loss=0.07502]\n","Step 489537  [5.012 sec/step, loss=0.07400, avg_loss=0.07508]\n","Step 489538  [5.027 sec/step, loss=0.07814, avg_loss=0.07506]\n","Step 489539  [5.021 sec/step, loss=0.07254, avg_loss=0.07506]\n","Step 489540  [4.984 sec/step, loss=0.06822, avg_loss=0.07498]\n","Step 489541  [4.932 sec/step, loss=0.06411, avg_loss=0.07482]\n","Step 489542  [4.926 sec/step, loss=0.07720, avg_loss=0.07482]\n","Step 489543  [4.922 sec/step, loss=0.07485, avg_loss=0.07481]\n","Step 489544  [4.969 sec/step, loss=0.07310, avg_loss=0.07477]\n","Generated 32 batches of size 16 in 9.603 sec\n","Step 489545  [4.969 sec/step, loss=0.07693, avg_loss=0.07476]\n","Step 489546  [5.022 sec/step, loss=0.07748, avg_loss=0.07486]\n","Step 489547  [4.923 sec/step, loss=0.07003, avg_loss=0.07477]\n","Step 489548  [4.911 sec/step, loss=0.07716, avg_loss=0.07476]\n","Step 489549  [4.820 sec/step, loss=0.07174, avg_loss=0.07471]\n","Step 489550  [4.781 sec/step, loss=0.07406, avg_loss=0.07466]\n","Step 489551  [4.832 sec/step, loss=0.07984, avg_loss=0.07479]\n","Step 489552  [4.861 sec/step, loss=0.07772, avg_loss=0.07485]\n","Step 489553  [4.852 sec/step, loss=0.06931, avg_loss=0.07479]\n","Step 489554  [4.862 sec/step, loss=0.07762, avg_loss=0.07480]\n","Step 489555  [4.900 sec/step, loss=0.07743, avg_loss=0.07478]\n","Step 489556  [4.933 sec/step, loss=0.07907, avg_loss=0.07483]\n","Step 489557  [4.919 sec/step, loss=0.07241, avg_loss=0.07479]\n","Step 489558  [4.878 sec/step, loss=0.07240, avg_loss=0.07472]\n","Step 489559  [4.856 sec/step, loss=0.07226, avg_loss=0.07466]\n","Step 489560  [4.853 sec/step, loss=0.07638, avg_loss=0.07465]\n","Step 489561  [4.889 sec/step, loss=0.07690, avg_loss=0.07478]\n","Step 489562  [4.883 sec/step, loss=0.07612, avg_loss=0.07477]\n","Step 489563  [4.921 sec/step, loss=0.07854, avg_loss=0.07486]\n","Step 489564  [4.867 sec/step, loss=0.07981, avg_loss=0.07489]\n","Step 489565  [4.837 sec/step, loss=0.07659, avg_loss=0.07487]\n","Step 489566  [4.787 sec/step, loss=0.07475, avg_loss=0.07487]\n","Step 489567  [4.763 sec/step, loss=0.06860, avg_loss=0.07479]\n","Step 489568  [4.737 sec/step, loss=0.06645, avg_loss=0.07470]\n","Step 489569  [4.815 sec/step, loss=0.07954, avg_loss=0.07473]\n","Step 489570  [4.829 sec/step, loss=0.07696, avg_loss=0.07474]\n","Step 489571  [4.831 sec/step, loss=0.07644, avg_loss=0.07477]\n","Step 489572  [4.881 sec/step, loss=0.07860, avg_loss=0.07485]\n","Step 489573  [4.851 sec/step, loss=0.06293, avg_loss=0.07471]\n","Step 489574  [4.842 sec/step, loss=0.07555, avg_loss=0.07470]\n","Step 489575  [4.848 sec/step, loss=0.06956, avg_loss=0.07472]\n","Step 489576  [4.904 sec/step, loss=0.07489, avg_loss=0.07474]\n","Generated 32 batches of size 16 in 10.109 sec\n","Step 489577  [4.937 sec/step, loss=0.07727, avg_loss=0.07475]\n","Step 489578  [4.896 sec/step, loss=0.07860, avg_loss=0.07474]\n","Step 489579  [4.927 sec/step, loss=0.07877, avg_loss=0.07479]\n","Step 489580  [4.960 sec/step, loss=0.07597, avg_loss=0.07488]\n","Step 489581  [4.937 sec/step, loss=0.07888, avg_loss=0.07490]\n","Step 489582  [4.883 sec/step, loss=0.06728, avg_loss=0.07478]\n","Step 489583  [4.881 sec/step, loss=0.07309, avg_loss=0.07479]\n","Step 489584  [4.855 sec/step, loss=0.07321, avg_loss=0.07477]\n","Step 489585  [4.842 sec/step, loss=0.06464, avg_loss=0.07469]\n","Step 489586  [4.831 sec/step, loss=0.07743, avg_loss=0.07467]\n","Step 489587  [4.837 sec/step, loss=0.06936, avg_loss=0.07475]\n","Step 489588  [4.820 sec/step, loss=0.06460, avg_loss=0.07466]\n","Step 489589  [4.827 sec/step, loss=0.07931, avg_loss=0.07467]\n","Step 489590  [4.839 sec/step, loss=0.07698, avg_loss=0.07469]\n","Step 489591  [4.864 sec/step, loss=0.07527, avg_loss=0.07471]\n","Step 489592  [4.853 sec/step, loss=0.07656, avg_loss=0.07469]\n","Step 489593  [4.850 sec/step, loss=0.07320, avg_loss=0.07469]\n","Step 489594  [4.855 sec/step, loss=0.07281, avg_loss=0.07468]\n","Step 489595  [4.869 sec/step, loss=0.07861, avg_loss=0.07470]\n","Step 489596  [4.848 sec/step, loss=0.07615, avg_loss=0.07467]\n","Step 489597  [4.816 sec/step, loss=0.07908, avg_loss=0.07469]\n","Step 489598  [4.797 sec/step, loss=0.07326, avg_loss=0.07466]\n","Step 489599  [4.787 sec/step, loss=0.07268, avg_loss=0.07465]\n","Step 489600  [4.873 sec/step, loss=0.07684, avg_loss=0.07466]\n","Writing summary at step: 489600\n","Step 489601  [4.838 sec/step, loss=0.06811, avg_loss=0.07457]\n","Step 489602  [4.874 sec/step, loss=0.07958, avg_loss=0.07466]\n","Step 489603  [4.903 sec/step, loss=0.07682, avg_loss=0.07479]\n","Step 489604  [4.943 sec/step, loss=0.07760, avg_loss=0.07485]\n","Step 489605  [4.931 sec/step, loss=0.07842, avg_loss=0.07484]\n","Step 489606  [4.982 sec/step, loss=0.07959, avg_loss=0.07495]\n","Step 489607  [5.007 sec/step, loss=0.07411, avg_loss=0.07495]\n","Generated 32 batches of size 16 in 9.689 sec\n","Step 489608  [4.991 sec/step, loss=0.07126, avg_loss=0.07487]\n","Step 489609  [5.070 sec/step, loss=0.07887, avg_loss=0.07499]\n","Step 489610  [4.991 sec/step, loss=0.07642, avg_loss=0.07498]\n","Step 489611  [5.006 sec/step, loss=0.07938, avg_loss=0.07500]\n","Step 489612  [4.989 sec/step, loss=0.06389, avg_loss=0.07497]\n","Step 489613  [4.938 sec/step, loss=0.07480, avg_loss=0.07493]\n","Step 489614  [4.931 sec/step, loss=0.07657, avg_loss=0.07494]\n","Step 489615  [4.894 sec/step, loss=0.07512, avg_loss=0.07489]\n","Step 489616  [4.888 sec/step, loss=0.07696, avg_loss=0.07489]\n","Step 489617  [4.913 sec/step, loss=0.07903, avg_loss=0.07495]\n","Step 489618  [4.906 sec/step, loss=0.07336, avg_loss=0.07491]\n","Step 489619  [4.874 sec/step, loss=0.07698, avg_loss=0.07489]\n","Step 489620  [4.903 sec/step, loss=0.07819, avg_loss=0.07491]\n","Step 489621  [4.798 sec/step, loss=0.06648, avg_loss=0.07481]\n","Step 489622  [4.803 sec/step, loss=0.07517, avg_loss=0.07480]\n","Step 489623  [4.871 sec/step, loss=0.07941, avg_loss=0.07488]\n","Step 489624  [4.851 sec/step, loss=0.07487, avg_loss=0.07486]\n","Step 489625  [4.871 sec/step, loss=0.07939, avg_loss=0.07489]\n","Step 489626  [4.834 sec/step, loss=0.07133, avg_loss=0.07482]\n","Step 489627  [4.806 sec/step, loss=0.07612, avg_loss=0.07478]\n","Step 489628  [4.901 sec/step, loss=0.07647, avg_loss=0.07478]\n","Step 489629  [4.914 sec/step, loss=0.07812, avg_loss=0.07480]\n","Step 489630  [4.926 sec/step, loss=0.07872, avg_loss=0.07480]\n","Step 489631  [4.884 sec/step, loss=0.06830, avg_loss=0.07470]\n","Step 489632  [4.881 sec/step, loss=0.07736, avg_loss=0.07470]\n","Step 489633  [4.928 sec/step, loss=0.07834, avg_loss=0.07483]\n","Step 489634  [4.951 sec/step, loss=0.07426, avg_loss=0.07492]\n","Step 489635  [4.980 sec/step, loss=0.07993, avg_loss=0.07495]\n","Step 489636  [4.897 sec/step, loss=0.06625, avg_loss=0.07482]\n","Step 489637  [4.912 sec/step, loss=0.07663, avg_loss=0.07484]\n","Step 489638  [4.846 sec/step, loss=0.06262, avg_loss=0.07469]\n","Step 489639  [4.908 sec/step, loss=0.07478, avg_loss=0.07471]\n","Generated 32 batches of size 16 in 9.183 sec\n","Step 489640  [4.943 sec/step, loss=0.07611, avg_loss=0.07479]\n","Step 489641  [4.949 sec/step, loss=0.07179, avg_loss=0.07487]\n","Step 489642  [4.940 sec/step, loss=0.07343, avg_loss=0.07483]\n","Step 489643  [4.974 sec/step, loss=0.07656, avg_loss=0.07485]\n","Step 489644  [4.920 sec/step, loss=0.07594, avg_loss=0.07487]\n","Step 489645  [4.900 sec/step, loss=0.07359, avg_loss=0.07484]\n","Step 489646  [4.853 sec/step, loss=0.06709, avg_loss=0.07474]\n","Step 489647  [4.849 sec/step, loss=0.07012, avg_loss=0.07474]\n","Step 489648  [4.929 sec/step, loss=0.07970, avg_loss=0.07476]\n","Step 489649  [4.981 sec/step, loss=0.07762, avg_loss=0.07482]\n","Step 489650  [5.009 sec/step, loss=0.07837, avg_loss=0.07486]\n","Step 489651  [4.993 sec/step, loss=0.07796, avg_loss=0.07485]\n","Step 489652  [4.980 sec/step, loss=0.07410, avg_loss=0.07481]\n","Step 489653  [5.019 sec/step, loss=0.07958, avg_loss=0.07491]\n","Step 489654  [5.030 sec/step, loss=0.07849, avg_loss=0.07492]\n","Step 489655  [4.976 sec/step, loss=0.07627, avg_loss=0.07491]\n","Step 489656  [4.926 sec/step, loss=0.06497, avg_loss=0.07477]\n","Step 489657  [4.940 sec/step, loss=0.07684, avg_loss=0.07481]\n","Step 489658  [4.968 sec/step, loss=0.07820, avg_loss=0.07487]\n","Step 489659  [5.001 sec/step, loss=0.07774, avg_loss=0.07493]\n","Step 489660  [4.990 sec/step, loss=0.07248, avg_loss=0.07489]\n","Step 489661  [4.994 sec/step, loss=0.07605, avg_loss=0.07488]\n","Step 489662  [4.970 sec/step, loss=0.06836, avg_loss=0.07480]\n","Step 489663  [4.938 sec/step, loss=0.07252, avg_loss=0.07474]\n","Step 489664  [4.905 sec/step, loss=0.07494, avg_loss=0.07469]\n","Step 489665  [4.906 sec/step, loss=0.07682, avg_loss=0.07469]\n","Step 489666  [4.899 sec/step, loss=0.07300, avg_loss=0.07468]\n","Step 489667  [4.897 sec/step, loss=0.06764, avg_loss=0.07467]\n","Step 489668  [4.933 sec/step, loss=0.07699, avg_loss=0.07477]\n","Step 489669  [4.889 sec/step, loss=0.07906, avg_loss=0.07477]\n","Step 489670  [4.893 sec/step, loss=0.07679, avg_loss=0.07477]\n","Step 489671  [4.917 sec/step, loss=0.07350, avg_loss=0.07474]\n","Generated 32 batches of size 16 in 10.258 sec\n","Step 489672  [4.932 sec/step, loss=0.07920, avg_loss=0.07474]\n","Step 489673  [4.953 sec/step, loss=0.07656, avg_loss=0.07488]\n","Step 489674  [4.993 sec/step, loss=0.07755, avg_loss=0.07490]\n","Step 489675  [4.995 sec/step, loss=0.07081, avg_loss=0.07491]\n","Step 489676  [4.954 sec/step, loss=0.07642, avg_loss=0.07493]\n","Step 489677  [4.908 sec/step, loss=0.07202, avg_loss=0.07487]\n","Step 489678  [4.867 sec/step, loss=0.06394, avg_loss=0.07473]\n","Step 489679  [4.820 sec/step, loss=0.06913, avg_loss=0.07463]\n","Step 489680  [4.838 sec/step, loss=0.07799, avg_loss=0.07465]\n","Step 489681  [4.833 sec/step, loss=0.07975, avg_loss=0.07466]\n","Step 489682  [4.858 sec/step, loss=0.07717, avg_loss=0.07476]\n","Step 489683  [4.887 sec/step, loss=0.07802, avg_loss=0.07481]\n","Step 489684  [4.895 sec/step, loss=0.07532, avg_loss=0.07483]\n","Step 489685  [4.916 sec/step, loss=0.07624, avg_loss=0.07494]\n","Step 489686  [4.891 sec/step, loss=0.07055, avg_loss=0.07488]\n","Step 489687  [4.893 sec/step, loss=0.07209, avg_loss=0.07490]\n","Step 489688  [4.941 sec/step, loss=0.07869, avg_loss=0.07504]\n","Step 489689  [4.924 sec/step, loss=0.07675, avg_loss=0.07502]\n","Step 489690  [4.982 sec/step, loss=0.07741, avg_loss=0.07502]\n","Step 489691  [4.964 sec/step, loss=0.07340, avg_loss=0.07500]\n","Step 489692  [4.969 sec/step, loss=0.07652, avg_loss=0.07500]\n","Step 489693  [4.965 sec/step, loss=0.07279, avg_loss=0.07500]\n","Step 489694  [4.962 sec/step, loss=0.07258, avg_loss=0.07500]\n","Step 489695  [4.926 sec/step, loss=0.07695, avg_loss=0.07498]\n","Step 489696  [4.893 sec/step, loss=0.06609, avg_loss=0.07488]\n","Step 489697  [4.903 sec/step, loss=0.07854, avg_loss=0.07487]\n","Step 489698  [4.944 sec/step, loss=0.07947, avg_loss=0.07494]\n","Step 489699  [5.035 sec/step, loss=0.07350, avg_loss=0.07495]\n","Step 489700  [4.952 sec/step, loss=0.07353, avg_loss=0.07491]\n","Writing summary at step: 489700\n","Step 489701  [4.982 sec/step, loss=0.07719, avg_loss=0.07500]\n","Step 489702  [4.987 sec/step, loss=0.07274, avg_loss=0.07493]\n","Generated 32 batches of size 16 in 9.935 sec\n","Step 489703  [5.025 sec/step, loss=0.07871, avg_loss=0.07495]\n","Step 489704  [4.974 sec/step, loss=0.06771, avg_loss=0.07485]\n","Step 489705  [4.980 sec/step, loss=0.07835, avg_loss=0.07485]\n","Step 489706  [4.938 sec/step, loss=0.07354, avg_loss=0.07479]\n","Step 489707  [4.896 sec/step, loss=0.06420, avg_loss=0.07469]\n","Step 489708  [4.865 sec/step, loss=0.06518, avg_loss=0.07463]\n","Step 489709  [4.820 sec/step, loss=0.07760, avg_loss=0.07462]\n","Step 489710  [4.818 sec/step, loss=0.07605, avg_loss=0.07462]\n","Step 489711  [4.798 sec/step, loss=0.07410, avg_loss=0.07456]\n","Step 489712  [4.846 sec/step, loss=0.07853, avg_loss=0.07471]\n","Step 489713  [4.844 sec/step, loss=0.07594, avg_loss=0.07472]\n","Step 489714  [4.866 sec/step, loss=0.07833, avg_loss=0.07474]\n","Step 489715  [4.878 sec/step, loss=0.07669, avg_loss=0.07476]\n","Step 489716  [4.849 sec/step, loss=0.06647, avg_loss=0.07465]\n","Step 489717  [4.811 sec/step, loss=0.07270, avg_loss=0.07459]\n","Step 489718  [4.804 sec/step, loss=0.07208, avg_loss=0.07457]\n","Step 489719  [4.882 sec/step, loss=0.07933, avg_loss=0.07460]\n","Step 489720  [4.883 sec/step, loss=0.07418, avg_loss=0.07456]\n","Step 489721  [4.921 sec/step, loss=0.07566, avg_loss=0.07465]\n","Step 489722  [4.931 sec/step, loss=0.07707, avg_loss=0.07467]\n","Step 489723  [4.886 sec/step, loss=0.07693, avg_loss=0.07464]\n","Step 489724  [4.898 sec/step, loss=0.07561, avg_loss=0.07465]\n","Step 489725  [4.848 sec/step, loss=0.06859, avg_loss=0.07454]\n","Step 489726  [4.838 sec/step, loss=0.06933, avg_loss=0.07452]\n","Step 489727  [4.826 sec/step, loss=0.07403, avg_loss=0.07450]\n","Step 489728  [4.739 sec/step, loss=0.07614, avg_loss=0.07450]\n","Step 489729  [4.699 sec/step, loss=0.06673, avg_loss=0.07438]\n","Step 489730  [4.689 sec/step, loss=0.07842, avg_loss=0.07438]\n","Step 489731  [4.691 sec/step, loss=0.07117, avg_loss=0.07441]\n","Step 489732  [4.709 sec/step, loss=0.07929, avg_loss=0.07443]\n","Step 489733  [4.664 sec/step, loss=0.06423, avg_loss=0.07429]\n","Step 489734  [4.688 sec/step, loss=0.07325, avg_loss=0.07428]\n","Generated 32 batches of size 16 in 9.741 sec\n","Step 489735  [4.665 sec/step, loss=0.07315, avg_loss=0.07421]\n","Step 489736  [4.703 sec/step, loss=0.07762, avg_loss=0.07432]\n","Step 489737  [4.752 sec/step, loss=0.07899, avg_loss=0.07435]\n","Step 489738  [4.781 sec/step, loss=0.07697, avg_loss=0.07449]\n","Step 489739  [4.736 sec/step, loss=0.07691, avg_loss=0.07451]\n","Step 489740  [4.749 sec/step, loss=0.07958, avg_loss=0.07455]\n","Step 489741  [4.797 sec/step, loss=0.07852, avg_loss=0.07462]\n","Step 489742  [4.807 sec/step, loss=0.07447, avg_loss=0.07463]\n","Step 489743  [4.801 sec/step, loss=0.07876, avg_loss=0.07465]\n","Step 489744  [4.793 sec/step, loss=0.07337, avg_loss=0.07462]\n","Step 489745  [4.812 sec/step, loss=0.07664, avg_loss=0.07465]\n","Step 489746  [4.875 sec/step, loss=0.07835, avg_loss=0.07476]\n","Step 489747  [4.930 sec/step, loss=0.07986, avg_loss=0.07486]\n","Step 489748  [4.836 sec/step, loss=0.07310, avg_loss=0.07480]\n","Step 489749  [4.779 sec/step, loss=0.06814, avg_loss=0.07470]\n","Step 489750  [4.748 sec/step, loss=0.07125, avg_loss=0.07463]\n","Step 489751  [4.819 sec/step, loss=0.07643, avg_loss=0.07461]\n","Step 489752  [4.816 sec/step, loss=0.07430, avg_loss=0.07462]\n","Step 489753  [4.771 sec/step, loss=0.06831, avg_loss=0.07450]\n","Step 489754  [4.770 sec/step, loss=0.07864, avg_loss=0.07451]\n","Step 489755  [4.768 sec/step, loss=0.07683, avg_loss=0.07451]\n","Step 489756  [4.801 sec/step, loss=0.07627, avg_loss=0.07462]\n","Step 489757  [4.821 sec/step, loss=0.07643, avg_loss=0.07462]\n","Step 489758  [4.794 sec/step, loss=0.07290, avg_loss=0.07457]\n","Step 489759  [4.784 sec/step, loss=0.07827, avg_loss=0.07457]\n","Step 489760  [4.819 sec/step, loss=0.07920, avg_loss=0.07464]\n","Step 489761  [4.833 sec/step, loss=0.07917, avg_loss=0.07467]\n","Step 489762  [4.852 sec/step, loss=0.07577, avg_loss=0.07474]\n","Step 489763  [4.837 sec/step, loss=0.06592, avg_loss=0.07468]\n","Step 489764  [4.835 sec/step, loss=0.07379, avg_loss=0.07467]\n","Step 489765  [4.832 sec/step, loss=0.07584, avg_loss=0.07466]\n","Generated 32 batches of size 16 in 9.872 sec\n","Step 489766  [4.903 sec/step, loss=0.07601, avg_loss=0.07469]\n","Step 489767  [4.927 sec/step, loss=0.07364, avg_loss=0.07475]\n","Step 489768  [4.976 sec/step, loss=0.07906, avg_loss=0.07477]\n","Step 489769  [4.913 sec/step, loss=0.06766, avg_loss=0.07465]\n","Step 489770  [4.913 sec/step, loss=0.07760, avg_loss=0.07466]\n","Step 489771  [4.908 sec/step, loss=0.07581, avg_loss=0.07469]\n","Step 489772  [4.862 sec/step, loss=0.07657, avg_loss=0.07466]\n","Step 489773  [4.842 sec/step, loss=0.06407, avg_loss=0.07453]\n","Step 489774  [4.770 sec/step, loss=0.07045, avg_loss=0.07446]\n","Step 489775  [4.776 sec/step, loss=0.07429, avg_loss=0.07450]\n","Step 489776  [4.779 sec/step, loss=0.07698, avg_loss=0.07450]\n","Step 489777  [4.813 sec/step, loss=0.07648, avg_loss=0.07455]\n","Step 489778  [4.840 sec/step, loss=0.07556, avg_loss=0.07466]\n","Step 489779  [4.834 sec/step, loss=0.06342, avg_loss=0.07461]\n","Step 489780  [4.788 sec/step, loss=0.06765, avg_loss=0.07450]\n","Step 489781  [4.746 sec/step, loss=0.07165, avg_loss=0.07442]\n","Step 489782  [4.788 sec/step, loss=0.07444, avg_loss=0.07440]\n","Step 489783  [4.766 sec/step, loss=0.07470, avg_loss=0.07436]\n","Step 489784  [4.784 sec/step, loss=0.07818, avg_loss=0.07439]\n","Step 489785  [4.773 sec/step, loss=0.07237, avg_loss=0.07435]\n","Step 489786  [4.806 sec/step, loss=0.07815, avg_loss=0.07443]\n","Step 489787  [4.805 sec/step, loss=0.07307, avg_loss=0.07444]\n","Step 489788  [4.795 sec/step, loss=0.07756, avg_loss=0.07443]\n","Step 489789  [4.816 sec/step, loss=0.07899, avg_loss=0.07445]\n","Step 489790  [4.763 sec/step, loss=0.07654, avg_loss=0.07444]\n","Step 489791  [4.850 sec/step, loss=0.07869, avg_loss=0.07449]\n","Step 489792  [4.865 sec/step, loss=0.07871, avg_loss=0.07452]\n","Step 489793  [4.889 sec/step, loss=0.07660, avg_loss=0.07455]\n","Step 489794  [4.901 sec/step, loss=0.07631, avg_loss=0.07459]\n","Step 489795  [4.906 sec/step, loss=0.07599, avg_loss=0.07458]\n","Step 489796  [4.968 sec/step, loss=0.07874, avg_loss=0.07471]\n","Step 489797  [4.910 sec/step, loss=0.05974, avg_loss=0.07452]\n","Step 489798  [4.892 sec/step, loss=0.06984, avg_loss=0.07442]\n","Generated 32 batches of size 16 in 10.323 sec\n","Step 489799  [4.854 sec/step, loss=0.07887, avg_loss=0.07448]\n","Step 489800  [4.855 sec/step, loss=0.07425, avg_loss=0.07448]\n","Writing summary at step: 489800\n","Step 489801  [4.907 sec/step, loss=0.07729, avg_loss=0.07449]\n","Step 489802  [4.901 sec/step, loss=0.07578, avg_loss=0.07452]\n","Step 489803  [4.831 sec/step, loss=0.06682, avg_loss=0.07440]\n","Step 489804  [4.841 sec/step, loss=0.06958, avg_loss=0.07442]\n","Step 489805  [4.817 sec/step, loss=0.07585, avg_loss=0.07439]\n","Step 489806  [4.851 sec/step, loss=0.07705, avg_loss=0.07443]\n","Step 489807  [4.955 sec/step, loss=0.07420, avg_loss=0.07453]\n","Step 489808  [4.973 sec/step, loss=0.07282, avg_loss=0.07460]\n","Step 489809  [4.973 sec/step, loss=0.07653, avg_loss=0.07459]\n","Step 489810  [4.996 sec/step, loss=0.07978, avg_loss=0.07463]\n","Step 489811  [5.018 sec/step, loss=0.07770, avg_loss=0.07466]\n","Step 489812  [4.988 sec/step, loss=0.07342, avg_loss=0.07461]\n","Step 489813  [4.977 sec/step, loss=0.07066, avg_loss=0.07456]\n","Step 489814  [4.954 sec/step, loss=0.07550, avg_loss=0.07453]\n","Step 489815  [4.976 sec/step, loss=0.07951, avg_loss=0.07456]\n","Step 489816  [4.984 sec/step, loss=0.06968, avg_loss=0.07459]\n","Step 489817  [5.038 sec/step, loss=0.07809, avg_loss=0.07465]\n","Step 489818  [5.022 sec/step, loss=0.06433, avg_loss=0.07457]\n","Step 489819  [4.945 sec/step, loss=0.07491, avg_loss=0.07453]\n","Step 489820  [4.890 sec/step, loss=0.07328, avg_loss=0.07452]\n","Step 489821  [4.862 sec/step, loss=0.07255, avg_loss=0.07448]\n","Step 489822  [4.818 sec/step, loss=0.06198, avg_loss=0.07433]\n","Step 489823  [4.823 sec/step, loss=0.07699, avg_loss=0.07433]\n","Step 489824  [4.824 sec/step, loss=0.07743, avg_loss=0.07435]\n","Step 489825  [4.849 sec/step, loss=0.07765, avg_loss=0.07444]\n","Step 489826  [4.921 sec/step, loss=0.07739, avg_loss=0.07452]\n","Step 489827  [4.944 sec/step, loss=0.07918, avg_loss=0.07458]\n","Step 489828  [4.933 sec/step, loss=0.07411, avg_loss=0.07456]\n","Generated 32 batches of size 16 in 9.721 sec\n","Step 489829  [5.023 sec/step, loss=0.07747, avg_loss=0.07466]\n","Step 489830  [5.008 sec/step, loss=0.07614, avg_loss=0.07464]\n","Step 489831  [5.027 sec/step, loss=0.07486, avg_loss=0.07468]\n","Step 489832  [5.012 sec/step, loss=0.07742, avg_loss=0.07466]\n","Step 489833  [5.034 sec/step, loss=0.07416, avg_loss=0.07476]\n","Step 489834  [5.041 sec/step, loss=0.07905, avg_loss=0.07482]\n","Step 489835  [5.004 sec/step, loss=0.06472, avg_loss=0.07473]\n","Step 489836  [4.986 sec/step, loss=0.07283, avg_loss=0.07468]\n","Step 489837  [4.904 sec/step, loss=0.06804, avg_loss=0.07457]\n","Step 489838  [4.876 sec/step, loss=0.06365, avg_loss=0.07444]\n","Step 489839  [4.897 sec/step, loss=0.07924, avg_loss=0.07446]\n","Step 489840  [4.896 sec/step, loss=0.07945, avg_loss=0.07446]\n","Step 489841  [4.898 sec/step, loss=0.07980, avg_loss=0.07448]\n","Step 489842  [4.925 sec/step, loss=0.07736, avg_loss=0.07450]\n","Step 489843  [4.893 sec/step, loss=0.07202, avg_loss=0.07444]\n","Step 489844  [4.908 sec/step, loss=0.07602, avg_loss=0.07446]\n","Step 489845  [4.986 sec/step, loss=0.07820, avg_loss=0.07448]\n","Step 489846  [4.941 sec/step, loss=0.07306, avg_loss=0.07443]\n","Step 489847  [4.876 sec/step, loss=0.06408, avg_loss=0.07427]\n","Step 489848  [4.911 sec/step, loss=0.07891, avg_loss=0.07433]\n","Step 489849  [4.917 sec/step, loss=0.06392, avg_loss=0.07428]\n","Step 489850  [4.944 sec/step, loss=0.07608, avg_loss=0.07433]\n","Step 489851  [4.867 sec/step, loss=0.07663, avg_loss=0.07433]\n","Step 489852  [4.882 sec/step, loss=0.07565, avg_loss=0.07435]\n","Step 489853  [4.881 sec/step, loss=0.07107, avg_loss=0.07438]\n","Step 489854  [4.855 sec/step, loss=0.07573, avg_loss=0.07435]\n","Step 489855  [4.840 sec/step, loss=0.07063, avg_loss=0.07428]\n","Step 489856  [4.850 sec/step, loss=0.07842, avg_loss=0.07431]\n","Step 489857  [4.810 sec/step, loss=0.07021, avg_loss=0.07424]\n","Step 489858  [4.825 sec/step, loss=0.07742, avg_loss=0.07429]\n","Step 489859  [4.829 sec/step, loss=0.07854, avg_loss=0.07429]\n","Step 489860  [4.808 sec/step, loss=0.07694, avg_loss=0.07427]\n","Generated 32 batches of size 16 in 10.115 sec\n","Step 489861  [4.877 sec/step, loss=0.07348, avg_loss=0.07421]\n","Step 489862  [4.873 sec/step, loss=0.07428, avg_loss=0.07420]\n","Step 489863  [4.878 sec/step, loss=0.06726, avg_loss=0.07421]\n","Step 489864  [4.884 sec/step, loss=0.07389, avg_loss=0.07421]\n","Step 489865  [4.870 sec/step, loss=0.07348, avg_loss=0.07419]\n","Step 489866  [4.812 sec/step, loss=0.07496, avg_loss=0.07418]\n","Step 489867  [4.873 sec/step, loss=0.07767, avg_loss=0.07422]\n","Step 489868  [4.823 sec/step, loss=0.07670, avg_loss=0.07419]\n","Step 489869  [4.858 sec/step, loss=0.07747, avg_loss=0.07429]\n","Step 489870  [4.819 sec/step, loss=0.06574, avg_loss=0.07417]\n","Step 489871  [4.849 sec/step, loss=0.07389, avg_loss=0.07415]\n","Step 489872  [4.856 sec/step, loss=0.07519, avg_loss=0.07414]\n","Step 489873  [4.859 sec/step, loss=0.06620, avg_loss=0.07416]\n","Step 489874  [4.868 sec/step, loss=0.07454, avg_loss=0.07420]\n","Step 489875  [4.882 sec/step, loss=0.07727, avg_loss=0.07423]\n","Step 489876  [4.886 sec/step, loss=0.07512, avg_loss=0.07421]\n","Step 489877  [4.857 sec/step, loss=0.07403, avg_loss=0.07419]\n","Step 489878  [4.918 sec/step, loss=0.07808, avg_loss=0.07422]\n","Step 489879  [4.931 sec/step, loss=0.07231, avg_loss=0.07430]\n","Step 489880  [4.967 sec/step, loss=0.07721, avg_loss=0.07440]\n","Step 489881  [4.974 sec/step, loss=0.07289, avg_loss=0.07441]\n","Step 489882  [4.958 sec/step, loss=0.07902, avg_loss=0.07446]\n","Step 489883  [4.986 sec/step, loss=0.07785, avg_loss=0.07449]\n","Step 489884  [4.982 sec/step, loss=0.07603, avg_loss=0.07447]\n","Step 489885  [4.999 sec/step, loss=0.07609, avg_loss=0.07450]\n","Step 489886  [4.965 sec/step, loss=0.07097, avg_loss=0.07443]\n","Step 489887  [4.999 sec/step, loss=0.07881, avg_loss=0.07449]\n","Step 489888  [4.989 sec/step, loss=0.07378, avg_loss=0.07445]\n","Step 489889  [5.042 sec/step, loss=0.07837, avg_loss=0.07445]\n","Step 489890  [5.051 sec/step, loss=0.07852, avg_loss=0.07447]\n","Step 489891  [4.948 sec/step, loss=0.06686, avg_loss=0.07435]\n","Step 489892  [4.906 sec/step, loss=0.07269, avg_loss=0.07429]\n","Step 489893  [4.894 sec/step, loss=0.06652, avg_loss=0.07419]\n","Generated 32 batches of size 16 in 9.734 sec\n","Step 489894  [4.932 sec/step, loss=0.07648, avg_loss=0.07419]\n","Step 489895  [4.900 sec/step, loss=0.06251, avg_loss=0.07405]\n","Step 489896  [4.900 sec/step, loss=0.07893, avg_loss=0.07406]\n","Step 489897  [4.938 sec/step, loss=0.07264, avg_loss=0.07418]\n","Step 489898  [4.944 sec/step, loss=0.07873, avg_loss=0.07427]\n","Step 489899  [4.889 sec/step, loss=0.07226, avg_loss=0.07421]\n","Step 489900  [4.920 sec/step, loss=0.07922, avg_loss=0.07426]\n","Writing summary at step: 489900\n","Step 489901  [4.870 sec/step, loss=0.07675, avg_loss=0.07425]\n","Step 489902  [4.888 sec/step, loss=0.07830, avg_loss=0.07428]\n","Step 489903  [4.921 sec/step, loss=0.07687, avg_loss=0.07438]\n","Step 489904  [4.922 sec/step, loss=0.07211, avg_loss=0.07440]\n","Step 489905  [4.940 sec/step, loss=0.07575, avg_loss=0.07440]\n","Step 489906  [4.904 sec/step, loss=0.07197, avg_loss=0.07435]\n","Step 489907  [4.796 sec/step, loss=0.06749, avg_loss=0.07428]\n","Step 489908  [4.812 sec/step, loss=0.07549, avg_loss=0.07431]\n","Step 489909  [4.799 sec/step, loss=0.07572, avg_loss=0.07430]\n","Step 489910  [4.758 sec/step, loss=0.06924, avg_loss=0.07420]\n","Step 489911  [4.741 sec/step, loss=0.07675, avg_loss=0.07419]\n","Step 489912  [4.798 sec/step, loss=0.07872, avg_loss=0.07424]\n","Step 489913  [4.837 sec/step, loss=0.07928, avg_loss=0.07433]\n","Step 489914  [4.837 sec/step, loss=0.07469, avg_loss=0.07432]\n","Step 489915  [4.818 sec/step, loss=0.07725, avg_loss=0.07430]\n","Step 489916  [4.826 sec/step, loss=0.07273, avg_loss=0.07433]\n","Step 489917  [4.814 sec/step, loss=0.07781, avg_loss=0.07432]\n","Step 489918  [4.857 sec/step, loss=0.07877, avg_loss=0.07447]\n","Step 489919  [4.880 sec/step, loss=0.07959, avg_loss=0.07451]\n","Step 489920  [4.922 sec/step, loss=0.07883, avg_loss=0.07457]\n","Step 489921  [4.955 sec/step, loss=0.07829, avg_loss=0.07463]\n","Step 489922  [4.955 sec/step, loss=0.07164, avg_loss=0.07472]\n","Step 489923  [4.934 sec/step, loss=0.07483, avg_loss=0.07470]\n","Step 489924  [4.919 sec/step, loss=0.06502, avg_loss=0.07458]\n","Generated 32 batches of size 16 in 9.371 sec\n","Step 489925  [4.948 sec/step, loss=0.07361, avg_loss=0.07454]\n","Step 489926  [4.893 sec/step, loss=0.07340, avg_loss=0.07450]\n","Step 489927  [4.858 sec/step, loss=0.06350, avg_loss=0.07434]\n","Step 489928  [4.877 sec/step, loss=0.07808, avg_loss=0.07438]\n","Step 489929  [4.815 sec/step, loss=0.07694, avg_loss=0.07438]\n","Step 489930  [4.826 sec/step, loss=0.07838, avg_loss=0.07440]\n","Step 489931  [4.797 sec/step, loss=0.06473, avg_loss=0.07430]\n","Step 489932  [4.867 sec/step, loss=0.07650, avg_loss=0.07429]\n","Step 489933  [4.892 sec/step, loss=0.07846, avg_loss=0.07433]\n","Step 489934  [4.920 sec/step, loss=0.07880, avg_loss=0.07433]\n","Step 489935  [4.976 sec/step, loss=0.07844, avg_loss=0.07447]\n","Step 489936  [4.955 sec/step, loss=0.06598, avg_loss=0.07440]\n","Step 489937  [5.009 sec/step, loss=0.07888, avg_loss=0.07451]\n","Step 489938  [5.073 sec/step, loss=0.07820, avg_loss=0.07465]\n","Step 489939  [5.049 sec/step, loss=0.07595, avg_loss=0.07462]\n","Step 489940  [5.024 sec/step, loss=0.07424, avg_loss=0.07457]\n","Step 489941  [4.976 sec/step, loss=0.07377, avg_loss=0.07451]\n","Step 489942  [4.952 sec/step, loss=0.07404, avg_loss=0.07447]\n","Step 489943  [4.981 sec/step, loss=0.07829, avg_loss=0.07454]\n","Step 489944  [4.975 sec/step, loss=0.07346, avg_loss=0.07451]\n","Step 489945  [4.866 sec/step, loss=0.06747, avg_loss=0.07440]\n","Step 489946  [4.894 sec/step, loss=0.07719, avg_loss=0.07444]\n","Step 489947  [4.907 sec/step, loss=0.07151, avg_loss=0.07452]\n","Step 489948  [4.863 sec/step, loss=0.07026, avg_loss=0.07443]\n","Step 489949  [4.856 sec/step, loss=0.06688, avg_loss=0.07446]\n","Step 489950  [4.847 sec/step, loss=0.07672, avg_loss=0.07447]\n","Step 489951  [4.849 sec/step, loss=0.07649, avg_loss=0.07447]\n","Step 489952  [4.850 sec/step, loss=0.07712, avg_loss=0.07448]\n","Step 489953  [4.875 sec/step, loss=0.07577, avg_loss=0.07453]\n","Step 489954  [4.855 sec/step, loss=0.06177, avg_loss=0.07439]\n","Step 489955  [4.856 sec/step, loss=0.07252, avg_loss=0.07441]\n","Generated 32 batches of size 16 in 9.454 sec\n","Step 489956  [4.909 sec/step, loss=0.07768, avg_loss=0.07440]\n","Step 489957  [4.959 sec/step, loss=0.07944, avg_loss=0.07449]\n","Step 489958  [4.950 sec/step, loss=0.07595, avg_loss=0.07448]\n","Step 489959  [5.014 sec/step, loss=0.07778, avg_loss=0.07447]\n","Step 489960  [4.997 sec/step, loss=0.07135, avg_loss=0.07441]\n","Step 489961  [4.882 sec/step, loss=0.07090, avg_loss=0.07439]\n","Step 489962  [4.901 sec/step, loss=0.07644, avg_loss=0.07441]\n","Step 489963  [4.917 sec/step, loss=0.07365, avg_loss=0.07447]\n","Step 489964  [4.919 sec/step, loss=0.07692, avg_loss=0.07450]\n","Step 489965  [4.933 sec/step, loss=0.07658, avg_loss=0.07453]\n","Step 489966  [4.960 sec/step, loss=0.07874, avg_loss=0.07457]\n","Step 489967  [4.901 sec/step, loss=0.07192, avg_loss=0.07452]\n","Step 489968  [4.869 sec/step, loss=0.06711, avg_loss=0.07442]\n","Step 489969  [4.854 sec/step, loss=0.07608, avg_loss=0.07441]\n","Step 489970  [4.890 sec/step, loss=0.07581, avg_loss=0.07451]\n","Step 489971  [4.852 sec/step, loss=0.07651, avg_loss=0.07453]\n","Step 489972  [4.920 sec/step, loss=0.07809, avg_loss=0.07456]\n","Step 489973  [4.960 sec/step, loss=0.07852, avg_loss=0.07468]\n","Step 489974  [4.995 sec/step, loss=0.07830, avg_loss=0.07472]\n","Step 489975  [4.979 sec/step, loss=0.07319, avg_loss=0.07468]\n","Step 489976  [4.986 sec/step, loss=0.07599, avg_loss=0.07469]\n","Step 489977  [4.998 sec/step, loss=0.07655, avg_loss=0.07472]\n","Step 489978  [4.940 sec/step, loss=0.07620, avg_loss=0.07470]\n","Step 489979  [4.940 sec/step, loss=0.07245, avg_loss=0.07470]\n","Step 489980  [4.922 sec/step, loss=0.07294, avg_loss=0.07466]\n","Step 489981  [4.938 sec/step, loss=0.07817, avg_loss=0.07471]\n","Step 489982  [4.892 sec/step, loss=0.06790, avg_loss=0.07460]\n","Step 489983  [4.855 sec/step, loss=0.07202, avg_loss=0.07454]\n","Step 489984  [4.828 sec/step, loss=0.07088, avg_loss=0.07449]\n","Step 489985  [4.803 sec/step, loss=0.06846, avg_loss=0.07441]\n","Step 489986  [4.793 sec/step, loss=0.06535, avg_loss=0.07435]\n","Step 489987  [4.793 sec/step, loss=0.07906, avg_loss=0.07436]\n","Generated 32 batches of size 16 in 9.662 sec\n","Step 489988  [4.873 sec/step, loss=0.07766, avg_loss=0.07440]\n","Step 489989  [4.762 sec/step, loss=0.06410, avg_loss=0.07425]\n","Step 489990  [4.801 sec/step, loss=0.07734, avg_loss=0.07424]\n","Step 489991  [4.866 sec/step, loss=0.07423, avg_loss=0.07431]\n","Step 489992  [4.914 sec/step, loss=0.08015, avg_loss=0.07439]\n","Step 489993  [4.921 sec/step, loss=0.07719, avg_loss=0.07450]\n","Step 489994  [4.894 sec/step, loss=0.07762, avg_loss=0.07451]\n","Step 489995  [4.915 sec/step, loss=0.07520, avg_loss=0.07463]\n","Step 489996  [4.870 sec/step, loss=0.07326, avg_loss=0.07458]\n","Step 489997  [4.889 sec/step, loss=0.07844, avg_loss=0.07464]\n","Step 489998  [4.868 sec/step, loss=0.07560, avg_loss=0.07460]\n","Step 489999  [4.881 sec/step, loss=0.07741, avg_loss=0.07466]\n","Step 490000  [4.839 sec/step, loss=0.07311, avg_loss=0.07459]\n","Writing summary at step: 490000\n","Saving checkpoint to: /content/drive/My Drive/trump_public/logs-tacotron/model.ckpt-490000\n","Saving audio and alignment...\n","Input: it doesn't need to add too many customized features and order to acquire more and there's no inherent reason why it should ever stop growing~___________________\n","Step 490001  [4.835 sec/step, loss=0.07637, avg_loss=0.07459]\n","Step 490002  [4.781 sec/step, loss=0.07130, avg_loss=0.07452]\n","Step 490003  [4.795 sec/step, loss=0.07827, avg_loss=0.07453]\n","Step 490004  [4.825 sec/step, loss=0.07736, avg_loss=0.07459]\n","Step 490005  [4.782 sec/step, loss=0.06405, avg_loss=0.07447]\n","Step 490006  [4.772 sec/step, loss=0.06116, avg_loss=0.07436]\n","Step 490007  [4.805 sec/step, loss=0.07512, avg_loss=0.07444]\n","Step 490008  [4.800 sec/step, loss=0.07648, avg_loss=0.07445]\n","Step 490009  [4.838 sec/step, loss=0.07941, avg_loss=0.07449]\n","Step 490010  [4.881 sec/step, loss=0.07893, avg_loss=0.07458]\n","Step 490011  [4.897 sec/step, loss=0.07879, avg_loss=0.07460]\n","Step 490012  [4.817 sec/step, loss=0.06740, avg_loss=0.07449]\n","Step 490013  [4.817 sec/step, loss=0.07872, avg_loss=0.07448]\n","Step 490014  [4.836 sec/step, loss=0.07635, avg_loss=0.07450]\n","Step 490015  [4.837 sec/step, loss=0.07560, avg_loss=0.07448]\n","Step 490016  [4.829 sec/step, loss=0.06982, avg_loss=0.07445]\n","Step 490017  [4.776 sec/step, loss=0.06515, avg_loss=0.07433]\n","Step 490018  [4.779 sec/step, loss=0.07343, avg_loss=0.07427]\n","Generated 32 batches of size 16 in 10.625 sec\n","Step 490019  [4.793 sec/step, loss=0.07741, avg_loss=0.07425]\n","Step 490020  [4.763 sec/step, loss=0.07421, avg_loss=0.07421]\n","Step 490021  [4.737 sec/step, loss=0.07344, avg_loss=0.07416]\n","Step 490022  [4.843 sec/step, loss=0.07759, avg_loss=0.07422]\n","Step 490023  [4.837 sec/step, loss=0.07255, avg_loss=0.07420]\n","Step 490024  [4.906 sec/step, loss=0.07682, avg_loss=0.07431]\n","Step 490025  [4.872 sec/step, loss=0.07338, avg_loss=0.07431]\n","Step 490026  [4.864 sec/step, loss=0.07143, avg_loss=0.07429]\n","Step 490027  [4.878 sec/step, loss=0.07303, avg_loss=0.07439]\n","Step 490028  [4.873 sec/step, loss=0.07504, avg_loss=0.07436]\n","Step 490029  [4.875 sec/step, loss=0.07650, avg_loss=0.07435]\n","Step 490030  [4.848 sec/step, loss=0.07376, avg_loss=0.07431]\n","Step 490031  [4.861 sec/step, loss=0.07247, avg_loss=0.07438]\n","Step 490032  [4.821 sec/step, loss=0.07381, avg_loss=0.07436]\n","Step 490033  [4.828 sec/step, loss=0.07741, avg_loss=0.07435]\n","Step 490034  [4.753 sec/step, loss=0.06987, avg_loss=0.07426]\n","Step 490035  [4.748 sec/step, loss=0.07746, avg_loss=0.07425]\n","Step 490036  [4.806 sec/step, loss=0.07901, avg_loss=0.07438]\n","Step 490037  [4.752 sec/step, loss=0.06590, avg_loss=0.07425]\n","Step 490038  [4.698 sec/step, loss=0.07027, avg_loss=0.07417]\n","Step 490039  [4.675 sec/step, loss=0.06250, avg_loss=0.07403]\n","Step 490040  [4.735 sec/step, loss=0.07925, avg_loss=0.07408]\n","Step 490041  [4.720 sec/step, loss=0.06492, avg_loss=0.07399]\n","Step 490042  [4.735 sec/step, loss=0.07940, avg_loss=0.07405]\n","Step 490043  [4.712 sec/step, loss=0.07240, avg_loss=0.07399]\n","Step 490044  [4.749 sec/step, loss=0.07875, avg_loss=0.07404]\n","Step 490045  [4.770 sec/step, loss=0.07295, avg_loss=0.07410]\n","Step 490046  [4.723 sec/step, loss=0.06764, avg_loss=0.07400]\n","Step 490047  [4.753 sec/step, loss=0.07667, avg_loss=0.07405]\n","Step 490048  [4.795 sec/step, loss=0.07791, avg_loss=0.07413]\n","Step 490049  [4.830 sec/step, loss=0.07721, avg_loss=0.07423]\n","Generated 32 batches of size 16 in 9.416 sec\n","Step 490050  [4.886 sec/step, loss=0.07651, avg_loss=0.07423]\n","Step 490051  [4.880 sec/step, loss=0.07723, avg_loss=0.07424]\n","Step 490052  [4.860 sec/step, loss=0.07244, avg_loss=0.07419]\n","Step 490053  [4.870 sec/step, loss=0.07728, avg_loss=0.07421]\n","Step 490054  [4.898 sec/step, loss=0.07596, avg_loss=0.07435]\n","Step 490055  [4.911 sec/step, loss=0.07410, avg_loss=0.07436]\n","Step 490056  [4.870 sec/step, loss=0.07971, avg_loss=0.07438]\n","Step 490057  [4.919 sec/step, loss=0.07620, avg_loss=0.07435]\n","Step 490058  [4.922 sec/step, loss=0.07491, avg_loss=0.07434]\n","Step 490059  [4.870 sec/step, loss=0.07951, avg_loss=0.07436]\n","Step 490060  [4.882 sec/step, loss=0.07626, avg_loss=0.07441]\n","Step 490061  [4.888 sec/step, loss=0.07276, avg_loss=0.07443]\n","Step 490062  [4.933 sec/step, loss=0.07812, avg_loss=0.07444]\n","Step 490063  [4.969 sec/step, loss=0.07848, avg_loss=0.07449]\n","Step 490064  [4.981 sec/step, loss=0.07777, avg_loss=0.07450]\n","Step 490065  [4.977 sec/step, loss=0.07545, avg_loss=0.07449]\n","Step 490066  [4.923 sec/step, loss=0.06351, avg_loss=0.07434]\n","Step 490067  [4.909 sec/step, loss=0.07297, avg_loss=0.07435]\n","Step 490068  [4.947 sec/step, loss=0.07630, avg_loss=0.07444]\n","Step 490069  [4.958 sec/step, loss=0.07666, avg_loss=0.07445]\n","Step 490070  [4.949 sec/step, loss=0.07365, avg_loss=0.07442]\n","Step 490071  [4.968 sec/step, loss=0.07702, avg_loss=0.07443]\n","Step 490072  [4.880 sec/step, loss=0.07435, avg_loss=0.07439]\n","Step 490073  [4.883 sec/step, loss=0.07778, avg_loss=0.07438]\n","Step 490074  [4.864 sec/step, loss=0.07556, avg_loss=0.07436]\n","Step 490075  [4.847 sec/step, loss=0.06583, avg_loss=0.07428]\n","Step 490076  [4.808 sec/step, loss=0.06776, avg_loss=0.07420]\n","Step 490077  [4.827 sec/step, loss=0.07887, avg_loss=0.07422]\n","Step 490078  [4.829 sec/step, loss=0.07660, avg_loss=0.07423]\n","Step 490079  [4.856 sec/step, loss=0.07720, avg_loss=0.07428]\n","Step 490080  [4.883 sec/step, loss=0.07834, avg_loss=0.07433]\n","Step 490081  [4.854 sec/step, loss=0.07247, avg_loss=0.07427]\n","Generated 32 batches of size 16 in 11.118 sec\n","Step 490082  [5.002 sec/step, loss=0.07645, avg_loss=0.07436]\n","Step 490083  [5.017 sec/step, loss=0.07604, avg_loss=0.07440]\n","Step 490084  [5.035 sec/step, loss=0.07508, avg_loss=0.07444]\n","Step 490085  [5.034 sec/step, loss=0.06766, avg_loss=0.07443]\n","Step 490086  [5.099 sec/step, loss=0.07696, avg_loss=0.07455]\n","Step 490087  [5.069 sec/step, loss=0.07195, avg_loss=0.07448]\n","Step 490088  [4.984 sec/step, loss=0.07344, avg_loss=0.07443]\n","Step 490089  [4.994 sec/step, loss=0.06906, avg_loss=0.07448]\n","Step 490090  [4.920 sec/step, loss=0.07093, avg_loss=0.07442]\n","Step 490091  [4.894 sec/step, loss=0.07811, avg_loss=0.07446]\n","Step 490092  [4.845 sec/step, loss=0.07003, avg_loss=0.07436]\n","Step 490093  [4.843 sec/step, loss=0.07452, avg_loss=0.07433]\n","Step 490094  [4.835 sec/step, loss=0.07575, avg_loss=0.07431]\n","Step 490095  [4.844 sec/step, loss=0.07580, avg_loss=0.07432]\n","Step 490096  [4.849 sec/step, loss=0.07537, avg_loss=0.07434]\n","Step 490097  [4.871 sec/step, loss=0.07913, avg_loss=0.07435]\n","Step 490098  [4.888 sec/step, loss=0.07644, avg_loss=0.07435]\n","Step 490099  [4.890 sec/step, loss=0.07664, avg_loss=0.07435]\n","Step 490100  [4.914 sec/step, loss=0.07505, avg_loss=0.07437]\n","Writing summary at step: 490100\n","Step 490101  [4.920 sec/step, loss=0.07706, avg_loss=0.07437]\n","Step 490102  [4.972 sec/step, loss=0.07922, avg_loss=0.07445]\n","Step 490103  [4.940 sec/step, loss=0.07144, avg_loss=0.07438]\n","Step 490104  [4.953 sec/step, loss=0.07903, avg_loss=0.07440]\n","Step 490105  [4.971 sec/step, loss=0.07331, avg_loss=0.07449]\n","Step 490106  [4.969 sec/step, loss=0.06827, avg_loss=0.07456]\n","Step 490107  [4.955 sec/step, loss=0.07486, avg_loss=0.07456]\n","Step 490108  [4.934 sec/step, loss=0.06889, avg_loss=0.07449]\n","Step 490109  [4.876 sec/step, loss=0.06327, avg_loss=0.07432]\n","Step 490110  [4.873 sec/step, loss=0.07663, avg_loss=0.07430]\n","Step 490111  [4.874 sec/step, loss=0.07884, avg_loss=0.07430]\n","Step 490112  [4.891 sec/step, loss=0.07359, avg_loss=0.07436]\n","Step 490113  [4.893 sec/step, loss=0.07089, avg_loss=0.07429]\n","Generated 32 batches of size 16 in 9.988 sec\n","Step 490114  [4.975 sec/step, loss=0.07733, avg_loss=0.07430]\n","Step 490115  [4.963 sec/step, loss=0.07314, avg_loss=0.07427]\n","Step 490116  [4.969 sec/step, loss=0.07278, avg_loss=0.07430]\n","Step 490117  [5.000 sec/step, loss=0.07655, avg_loss=0.07441]\n","Step 490118  [5.005 sec/step, loss=0.07892, avg_loss=0.07447]\n","Step 490119  [4.933 sec/step, loss=0.06449, avg_loss=0.07434]\n","Step 490120  [4.908 sec/step, loss=0.06728, avg_loss=0.07427]\n","Step 490121  [4.955 sec/step, loss=0.07892, avg_loss=0.07433]\n","Step 490122  [4.901 sec/step, loss=0.07846, avg_loss=0.07433]\n","Step 490123  [4.929 sec/step, loss=0.07766, avg_loss=0.07439]\n","Step 490124  [4.863 sec/step, loss=0.07178, avg_loss=0.07434]\n","Step 490125  [4.861 sec/step, loss=0.07435, avg_loss=0.07435]\n","Step 490126  [4.869 sec/step, loss=0.07394, avg_loss=0.07437]\n","Step 490127  [4.872 sec/step, loss=0.07602, avg_loss=0.07440]\n","Step 490128  [4.886 sec/step, loss=0.07828, avg_loss=0.07443]\n","Step 490129  [4.865 sec/step, loss=0.07036, avg_loss=0.07437]\n","Step 490130  [4.904 sec/step, loss=0.07657, avg_loss=0.07440]\n","Step 490131  [4.909 sec/step, loss=0.07240, avg_loss=0.07440]\n","Step 490132  [4.904 sec/step, loss=0.07897, avg_loss=0.07445]\n","Step 490133  [4.882 sec/step, loss=0.07555, avg_loss=0.07443]\n","Step 490134  [4.890 sec/step, loss=0.07240, avg_loss=0.07446]\n","Step 490135  [4.838 sec/step, loss=0.06590, avg_loss=0.07434]\n","Step 490136  [4.812 sec/step, loss=0.07621, avg_loss=0.07431]\n","Step 490137  [4.821 sec/step, loss=0.06915, avg_loss=0.07435]\n","Step 490138  [4.835 sec/step, loss=0.07612, avg_loss=0.07440]\n","Step 490139  [4.829 sec/step, loss=0.06698, avg_loss=0.07445]\n","Step 490140  [4.782 sec/step, loss=0.07620, avg_loss=0.07442]\n","Step 490141  [4.845 sec/step, loss=0.07926, avg_loss=0.07456]\n","Step 490142  [4.840 sec/step, loss=0.07730, avg_loss=0.07454]\n","Step 490143  [4.867 sec/step, loss=0.07823, avg_loss=0.07460]\n","Step 490144  [4.846 sec/step, loss=0.07628, avg_loss=0.07457]\n","Step 490145  [4.860 sec/step, loss=0.07265, avg_loss=0.07457]\n","Generated 32 batches of size 16 in 11.030 sec\n","Step 490146  [4.965 sec/step, loss=0.07713, avg_loss=0.07467]\n","Step 490147  [4.924 sec/step, loss=0.06367, avg_loss=0.07454]\n","Step 490148  [4.905 sec/step, loss=0.07674, avg_loss=0.07452]\n","Step 490149  [4.873 sec/step, loss=0.06787, avg_loss=0.07443]\n","Step 490150  [4.896 sec/step, loss=0.07528, avg_loss=0.07442]\n","Step 490151  [4.882 sec/step, loss=0.07339, avg_loss=0.07438]\n","Step 490152  [4.919 sec/step, loss=0.07861, avg_loss=0.07444]\n","Step 490153  [4.907 sec/step, loss=0.07648, avg_loss=0.07443]\n","Step 490154  [4.944 sec/step, loss=0.07844, avg_loss=0.07446]\n","Step 490155  [4.937 sec/step, loss=0.07274, avg_loss=0.07445]\n","Step 490156  [4.905 sec/step, loss=0.07291, avg_loss=0.07438]\n","Step 490157  [4.904 sec/step, loss=0.07725, avg_loss=0.07439]\n","Step 490158  [4.941 sec/step, loss=0.07895, avg_loss=0.07443]\n","Step 490159  [4.891 sec/step, loss=0.06931, avg_loss=0.07433]\n","Step 490160  [4.901 sec/step, loss=0.07646, avg_loss=0.07433]\n","Step 490161  [4.931 sec/step, loss=0.07889, avg_loss=0.07439]\n","Step 490162  [4.887 sec/step, loss=0.07713, avg_loss=0.07438]\n","Step 490163  [4.844 sec/step, loss=0.07191, avg_loss=0.07431]\n","Step 490164  [4.831 sec/step, loss=0.07289, avg_loss=0.07426]\n","Step 490165  [4.860 sec/step, loss=0.07769, avg_loss=0.07429]\n","Step 490166  [4.913 sec/step, loss=0.07954, avg_loss=0.07445]\n","Step 490167  [4.916 sec/step, loss=0.07307, avg_loss=0.07445]\n","Step 490168  [4.898 sec/step, loss=0.07479, avg_loss=0.07443]\n","Step 490169  [4.888 sec/step, loss=0.07653, avg_loss=0.07443]\n","Step 490170  [4.912 sec/step, loss=0.07747, avg_loss=0.07447]\n","Step 490171  [4.888 sec/step, loss=0.07592, avg_loss=0.07446]\n","Step 490172  [4.902 sec/step, loss=0.07564, avg_loss=0.07447]\n","Step 490173  [4.853 sec/step, loss=0.06435, avg_loss=0.07434]\n","Step 490174  [4.829 sec/step, loss=0.06975, avg_loss=0.07428]\n","Step 490175  [4.836 sec/step, loss=0.06916, avg_loss=0.07431]\n","Step 490176  [4.836 sec/step, loss=0.06703, avg_loss=0.07431]\n","Step 490177  [4.803 sec/step, loss=0.06493, avg_loss=0.07417]\n","Generated 32 batches of size 16 in 9.658 sec\n","Step 490178  [4.838 sec/step, loss=0.07636, avg_loss=0.07416]\n","Step 490179  [4.827 sec/step, loss=0.07750, avg_loss=0.07417]\n","Step 490180  [4.815 sec/step, loss=0.07556, avg_loss=0.07414]\n","Step 490181  [4.864 sec/step, loss=0.08016, avg_loss=0.07422]\n","Step 490182  [4.749 sec/step, loss=0.07664, avg_loss=0.07422]\n","Step 490183  [4.805 sec/step, loss=0.07896, avg_loss=0.07425]\n","Step 490184  [4.792 sec/step, loss=0.07270, avg_loss=0.07422]\n","Step 490185  [4.842 sec/step, loss=0.07797, avg_loss=0.07433]\n","Step 490186  [4.796 sec/step, loss=0.07331, avg_loss=0.07429]\n","Step 490187  [4.776 sec/step, loss=0.06554, avg_loss=0.07423]\n","Step 490188  [4.778 sec/step, loss=0.07363, avg_loss=0.07423]\n","Step 490189  [4.805 sec/step, loss=0.07495, avg_loss=0.07429]\n","Step 490190  [4.865 sec/step, loss=0.07250, avg_loss=0.07430]\n","Step 490191  [4.857 sec/step, loss=0.07682, avg_loss=0.07429]\n","Step 490192  [4.862 sec/step, loss=0.07334, avg_loss=0.07432]\n","Step 490193  [4.852 sec/step, loss=0.07132, avg_loss=0.07429]\n","Step 490194  [4.885 sec/step, loss=0.07935, avg_loss=0.07433]\n","Step 490195  [4.866 sec/step, loss=0.07145, avg_loss=0.07428]\n","Step 490196  [4.870 sec/step, loss=0.07412, avg_loss=0.07427]\n","Step 490197  [4.808 sec/step, loss=0.07510, avg_loss=0.07423]\n","Step 490198  [4.803 sec/step, loss=0.07635, avg_loss=0.07423]\n","Step 490199  [4.817 sec/step, loss=0.07957, avg_loss=0.07426]\n","Step 490200  [4.834 sec/step, loss=0.07909, avg_loss=0.07430]\n","Writing summary at step: 490200\n","Step 490201  [4.842 sec/step, loss=0.07714, avg_loss=0.07430]\n","Step 490202  [4.892 sec/step, loss=0.07723, avg_loss=0.07428]\n","Step 490203  [4.881 sec/step, loss=0.06121, avg_loss=0.07418]\n","Step 490204  [4.866 sec/step, loss=0.07733, avg_loss=0.07416]\n","Step 490205  [4.934 sec/step, loss=0.07954, avg_loss=0.07422]\n","Step 490206  [4.977 sec/step, loss=0.07778, avg_loss=0.07432]\n","Step 490207  [4.987 sec/step, loss=0.07736, avg_loss=0.07434]\n","Step 490208  [5.050 sec/step, loss=0.07347, avg_loss=0.07439]\n","Generated 32 batches of size 16 in 10.122 sec\n","Step 490209  [5.062 sec/step, loss=0.06764, avg_loss=0.07443]\n","Step 490210  [5.015 sec/step, loss=0.06768, avg_loss=0.07434]\n","Step 490211  [4.977 sec/step, loss=0.06935, avg_loss=0.07425]\n","Step 490212  [4.968 sec/step, loss=0.07030, avg_loss=0.07422]\n","Step 490213  [4.945 sec/step, loss=0.07746, avg_loss=0.07428]\n","Step 490214  [4.874 sec/step, loss=0.07854, avg_loss=0.07429]\n","Step 490215  [4.900 sec/step, loss=0.07810, avg_loss=0.07434]\n","Step 490216  [4.901 sec/step, loss=0.07339, avg_loss=0.07435]\n","Step 490217  [4.890 sec/step, loss=0.07515, avg_loss=0.07434]\n","Step 490218  [4.885 sec/step, loss=0.07853, avg_loss=0.07433]\n","Step 490219  [4.928 sec/step, loss=0.07882, avg_loss=0.07447]\n","Step 490220  [4.981 sec/step, loss=0.07973, avg_loss=0.07460]\n","Step 490221  [4.937 sec/step, loss=0.07657, avg_loss=0.07458]\n","Step 490222  [4.926 sec/step, loss=0.07760, avg_loss=0.07457]\n","Step 490223  [4.893 sec/step, loss=0.07227, avg_loss=0.07451]\n","Step 490224  [4.950 sec/step, loss=0.07535, avg_loss=0.07455]\n","Step 490225  [4.935 sec/step, loss=0.06319, avg_loss=0.07444]\n","Step 490226  [4.926 sec/step, loss=0.07349, avg_loss=0.07443]\n","Step 490227  [4.961 sec/step, loss=0.07869, avg_loss=0.07446]\n","Step 490228  [4.949 sec/step, loss=0.07688, avg_loss=0.07445]\n","Step 490229  [4.953 sec/step, loss=0.07139, avg_loss=0.07446]\n","Step 490230  [4.931 sec/step, loss=0.07753, avg_loss=0.07447]\n","Step 490231  [4.944 sec/step, loss=0.07634, avg_loss=0.07450]\n","Step 490232  [4.920 sec/step, loss=0.07678, avg_loss=0.07448]\n","Step 490233  [4.891 sec/step, loss=0.06804, avg_loss=0.07441]\n","Step 490234  [4.963 sec/step, loss=0.07807, avg_loss=0.07446]\n","Step 490235  [4.978 sec/step, loss=0.06974, avg_loss=0.07450]\n","Step 490236  [4.949 sec/step, loss=0.06520, avg_loss=0.07439]\n","Step 490237  [5.003 sec/step, loss=0.07899, avg_loss=0.07449]\n","Step 490238  [5.032 sec/step, loss=0.07708, avg_loss=0.07450]\n","Step 490239  [5.060 sec/step, loss=0.07676, avg_loss=0.07460]\n","Step 490240  [5.069 sec/step, loss=0.07121, avg_loss=0.07455]\n","Generated 32 batches of size 16 in 10.344 sec\n","Step 490241  [5.136 sec/step, loss=0.07856, avg_loss=0.07454]\n","Step 490242  [5.128 sec/step, loss=0.07573, avg_loss=0.07453]\n","Step 490243  [5.110 sec/step, loss=0.07298, avg_loss=0.07447]\n","Step 490244  [5.106 sec/step, loss=0.07647, avg_loss=0.07448]\n","Step 490245  [5.086 sec/step, loss=0.07387, avg_loss=0.07449]\n","Step 490246  [4.978 sec/step, loss=0.06438, avg_loss=0.07436]\n","Step 490247  [5.015 sec/step, loss=0.07790, avg_loss=0.07450]\n","Step 490248  [5.004 sec/step, loss=0.07369, avg_loss=0.07447]\n","Step 490249  [5.000 sec/step, loss=0.06201, avg_loss=0.07441]\n","Step 490250  [4.923 sec/step, loss=0.07554, avg_loss=0.07442]\n","Step 490251  [4.992 sec/step, loss=0.07748, avg_loss=0.07446]\n","Step 490252  [4.969 sec/step, loss=0.07579, avg_loss=0.07443]\n","Step 490253  [4.936 sec/step, loss=0.06574, avg_loss=0.07432]\n","Step 490254  [4.893 sec/step, loss=0.07345, avg_loss=0.07427]\n","Step 490255  [4.983 sec/step, loss=0.07599, avg_loss=0.07430]\n","Step 490256  [4.972 sec/step, loss=0.07015, avg_loss=0.07428]\n","Step 490257  [4.863 sec/step, loss=0.06684, avg_loss=0.07417]\n","Step 490258  [4.824 sec/step, loss=0.07584, avg_loss=0.07414]\n","Step 490259  [4.824 sec/step, loss=0.06856, avg_loss=0.07413]\n","Step 490260  [4.802 sec/step, loss=0.07333, avg_loss=0.07410]\n","Step 490261  [4.773 sec/step, loss=0.07326, avg_loss=0.07405]\n","Step 490262  [4.762 sec/step, loss=0.07580, avg_loss=0.07403]\n","Step 490263  [4.769 sec/step, loss=0.07189, avg_loss=0.07403]\n","Step 490264  [4.785 sec/step, loss=0.07713, avg_loss=0.07407]\n","Step 490265  [4.753 sec/step, loss=0.07435, avg_loss=0.07404]\n","Step 490266  [4.753 sec/step, loss=0.07707, avg_loss=0.07402]\n","Step 490267  [4.742 sec/step, loss=0.06818, avg_loss=0.07397]\n","Step 490268  [4.753 sec/step, loss=0.07671, avg_loss=0.07399]\n","Step 490269  [4.761 sec/step, loss=0.07690, avg_loss=0.07399]\n","Step 490270  [4.767 sec/step, loss=0.07876, avg_loss=0.07400]\n","Step 490271  [4.797 sec/step, loss=0.08010, avg_loss=0.07405]\n","Step 490272  [4.805 sec/step, loss=0.07226, avg_loss=0.07401]\n","Generated 32 batches of size 16 in 10.277 sec\n","Step 490273  [4.863 sec/step, loss=0.07646, avg_loss=0.07413]\n","Step 490274  [4.905 sec/step, loss=0.07871, avg_loss=0.07422]\n","Step 490275  [4.965 sec/step, loss=0.07683, avg_loss=0.07430]\n","Step 490276  [5.007 sec/step, loss=0.07809, avg_loss=0.07441]\n","Step 490277  [5.023 sec/step, loss=0.07720, avg_loss=0.07453]\n","Step 490278  [5.004 sec/step, loss=0.07794, avg_loss=0.07455]\n","Step 490279  [4.987 sec/step, loss=0.07285, avg_loss=0.07450]\n","Step 490280  [4.990 sec/step, loss=0.07633, avg_loss=0.07451]\n","Step 490281  [4.960 sec/step, loss=0.07630, avg_loss=0.07447]\n","Step 490282  [4.920 sec/step, loss=0.06671, avg_loss=0.07437]\n","Step 490283  [4.871 sec/step, loss=0.07641, avg_loss=0.07435]\n","Step 490284  [4.895 sec/step, loss=0.07715, avg_loss=0.07439]\n","Step 490285  [4.852 sec/step, loss=0.07024, avg_loss=0.07431]\n","Step 490286  [4.850 sec/step, loss=0.07141, avg_loss=0.07429]\n","Step 490287  [4.904 sec/step, loss=0.07602, avg_loss=0.07440]\n","Step 490288  [4.896 sec/step, loss=0.07335, avg_loss=0.07440]\n","Step 490289  [4.905 sec/step, loss=0.07790, avg_loss=0.07443]\n","Step 490290  [4.880 sec/step, loss=0.07832, avg_loss=0.07448]\n","Step 490291  [4.868 sec/step, loss=0.07540, avg_loss=0.07447]\n","Step 490292  [4.854 sec/step, loss=0.06346, avg_loss=0.07437]\n","Step 490293  [4.876 sec/step, loss=0.07544, avg_loss=0.07441]\n","Step 490294  [4.835 sec/step, loss=0.07597, avg_loss=0.07438]\n","Step 490295  [4.875 sec/step, loss=0.07865, avg_loss=0.07445]\n","Step 490296  [4.873 sec/step, loss=0.07379, avg_loss=0.07445]\n","Step 490297  [4.883 sec/step, loss=0.07600, avg_loss=0.07446]\n","Step 490298  [4.872 sec/step, loss=0.07448, avg_loss=0.07444]\n","Step 490299  [4.841 sec/step, loss=0.07262, avg_loss=0.07437]\n","Step 490300  [4.825 sec/step, loss=0.07808, avg_loss=0.07436]\n","Writing summary at step: 490300\n","Step 490301  [4.787 sec/step, loss=0.06738, avg_loss=0.07426]\n","Step 490302  [4.674 sec/step, loss=0.06591, avg_loss=0.07415]\n","Step 490303  [4.722 sec/step, loss=0.07220, avg_loss=0.07426]\n","Generated 32 batches of size 16 in 10.225 sec\n","Step 490304  [4.731 sec/step, loss=0.07654, avg_loss=0.07425]\n","Step 490305  [4.728 sec/step, loss=0.07889, avg_loss=0.07424]\n","Step 490306  [4.791 sec/step, loss=0.07614, avg_loss=0.07423]\n","Step 490307  [4.827 sec/step, loss=0.07850, avg_loss=0.07424]\n","Step 490308  [4.778 sec/step, loss=0.07198, avg_loss=0.07422]\n","Step 490309  [4.795 sec/step, loss=0.07562, avg_loss=0.07430]\n","Step 490310  [4.799 sec/step, loss=0.06813, avg_loss=0.07431]\n","Step 490311  [4.852 sec/step, loss=0.07934, avg_loss=0.07441]\n","Step 490312  [4.885 sec/step, loss=0.07860, avg_loss=0.07449]\n","Step 490313  [4.861 sec/step, loss=0.06084, avg_loss=0.07432]\n","Step 490314  [4.823 sec/step, loss=0.07073, avg_loss=0.07425]\n","Step 490315  [4.791 sec/step, loss=0.07384, avg_loss=0.07420]\n","Step 490316  [4.808 sec/step, loss=0.07689, avg_loss=0.07424]\n","Step 490317  [4.841 sec/step, loss=0.07664, avg_loss=0.07425]\n","Step 490318  [4.836 sec/step, loss=0.07587, avg_loss=0.07423]\n","Step 490319  [4.830 sec/step, loss=0.07658, avg_loss=0.07420]\n","Step 490320  [4.773 sec/step, loss=0.06629, avg_loss=0.07407]\n","Step 490321  [4.812 sec/step, loss=0.07753, avg_loss=0.07408]\n","Step 490322  [4.771 sec/step, loss=0.06936, avg_loss=0.07400]\n","Step 490323  [4.765 sec/step, loss=0.06253, avg_loss=0.07390]\n","Step 490324  [4.702 sec/step, loss=0.07203, avg_loss=0.07387]\n","Step 490325  [4.722 sec/step, loss=0.07355, avg_loss=0.07397]\n","Step 490326  [4.743 sec/step, loss=0.07710, avg_loss=0.07401]\n","Step 490327  [4.719 sec/step, loss=0.07647, avg_loss=0.07398]\n","Step 490328  [4.794 sec/step, loss=0.08014, avg_loss=0.07402]\n","Step 490329  [4.864 sec/step, loss=0.07790, avg_loss=0.07408]\n","Step 490330  [4.836 sec/step, loss=0.06698, avg_loss=0.07398]\n","Step 490331  [4.843 sec/step, loss=0.07673, avg_loss=0.07398]\n","Step 490332  [4.832 sec/step, loss=0.07703, avg_loss=0.07398]\n","Step 490333  [4.876 sec/step, loss=0.07851, avg_loss=0.07409]\n","Step 490334  [4.856 sec/step, loss=0.07872, avg_loss=0.07409]\n","Step 490335  [4.911 sec/step, loss=0.07450, avg_loss=0.07414]\n","Generated 32 batches of size 16 in 9.392 sec\n","Step 490336  [4.963 sec/step, loss=0.07801, avg_loss=0.07427]\n","Step 490337  [4.928 sec/step, loss=0.07660, avg_loss=0.07424]\n","Step 490338  [4.883 sec/step, loss=0.06917, avg_loss=0.07417]\n","Step 490339  [4.874 sec/step, loss=0.07305, avg_loss=0.07413]\n","Step 490340  [4.883 sec/step, loss=0.07881, avg_loss=0.07420]\n","Step 490341  [4.778 sec/step, loss=0.07661, avg_loss=0.07419]\n","Step 490342  [4.807 sec/step, loss=0.07853, avg_loss=0.07421]\n","Step 490343  [4.796 sec/step, loss=0.07332, avg_loss=0.07422]\n","Step 490344  [4.812 sec/step, loss=0.07651, avg_loss=0.07422]\n","Step 490345  [4.823 sec/step, loss=0.07656, avg_loss=0.07424]\n","Step 490346  [4.823 sec/step, loss=0.06542, avg_loss=0.07425]\n","Step 490347  [4.813 sec/step, loss=0.07634, avg_loss=0.07424]\n","Step 490348  [4.902 sec/step, loss=0.07301, avg_loss=0.07423]\n","Step 490349  [4.923 sec/step, loss=0.07558, avg_loss=0.07437]\n","Step 490350  [4.918 sec/step, loss=0.07255, avg_loss=0.07434]\n","Step 490351  [4.892 sec/step, loss=0.07799, avg_loss=0.07434]\n","Step 490352  [4.864 sec/step, loss=0.06695, avg_loss=0.07425]\n","Step 490353  [4.904 sec/step, loss=0.07495, avg_loss=0.07435]\n","Step 490354  [4.934 sec/step, loss=0.07917, avg_loss=0.07440]\n","Step 490355  [4.831 sec/step, loss=0.07076, avg_loss=0.07435]\n","Step 490356  [4.860 sec/step, loss=0.07705, avg_loss=0.07442]\n","Step 490357  [4.900 sec/step, loss=0.07709, avg_loss=0.07452]\n","Step 490358  [4.963 sec/step, loss=0.07799, avg_loss=0.07454]\n","Step 490359  [4.976 sec/step, loss=0.07419, avg_loss=0.07460]\n","Step 490360  [4.964 sec/step, loss=0.06867, avg_loss=0.07455]\n","Step 490361  [4.993 sec/step, loss=0.07812, avg_loss=0.07460]\n","Step 490362  [4.977 sec/step, loss=0.07221, avg_loss=0.07457]\n","Step 490363  [4.973 sec/step, loss=0.07359, avg_loss=0.07458]\n","Step 490364  [4.960 sec/step, loss=0.07607, avg_loss=0.07457]\n","Step 490365  [4.962 sec/step, loss=0.07444, avg_loss=0.07457]\n","Step 490366  [4.926 sec/step, loss=0.07236, avg_loss=0.07453]\n","Generated 32 batches of size 16 in 10.242 sec\n","Step 490367  [5.040 sec/step, loss=0.07828, avg_loss=0.07463]\n","Step 490368  [5.069 sec/step, loss=0.07754, avg_loss=0.07464]\n","Step 490369  [5.071 sec/step, loss=0.07549, avg_loss=0.07462]\n","Step 490370  [5.034 sec/step, loss=0.07385, avg_loss=0.07457]\n","Step 490371  [4.984 sec/step, loss=0.06807, avg_loss=0.07445]\n","Step 490372  [4.989 sec/step, loss=0.07845, avg_loss=0.07451]\n","Step 490373  [4.934 sec/step, loss=0.06449, avg_loss=0.07439]\n","Step 490374  [4.896 sec/step, loss=0.07265, avg_loss=0.07433]\n","Step 490375  [4.869 sec/step, loss=0.07648, avg_loss=0.07433]\n","Step 490376  [4.854 sec/step, loss=0.07633, avg_loss=0.07431]\n","Step 490377  [4.860 sec/step, loss=0.07869, avg_loss=0.07433]\n","Step 490378  [4.831 sec/step, loss=0.07162, avg_loss=0.07426]\n","Step 490379  [4.840 sec/step, loss=0.07457, avg_loss=0.07428]\n","Step 490380  [4.814 sec/step, loss=0.07147, avg_loss=0.07423]\n","Step 490381  [4.815 sec/step, loss=0.07575, avg_loss=0.07423]\n","Step 490382  [4.869 sec/step, loss=0.07890, avg_loss=0.07435]\n","Step 490383  [4.849 sec/step, loss=0.07272, avg_loss=0.07431]\n","Step 490384  [4.832 sec/step, loss=0.07585, avg_loss=0.07430]\n","Step 490385  [4.875 sec/step, loss=0.07826, avg_loss=0.07438]\n","Step 490386  [4.907 sec/step, loss=0.07667, avg_loss=0.07443]\n","Step 490387  [4.910 sec/step, loss=0.07843, avg_loss=0.07446]\n","Step 490388  [4.924 sec/step, loss=0.07661, avg_loss=0.07449]\n","Step 490389  [4.945 sec/step, loss=0.07713, avg_loss=0.07448]\n","Step 490390  [4.902 sec/step, loss=0.06716, avg_loss=0.07437]\n","Step 490391  [4.917 sec/step, loss=0.07514, avg_loss=0.07437]\n","Step 490392  [4.936 sec/step, loss=0.07168, avg_loss=0.07445]\n","Step 490393  [4.936 sec/step, loss=0.07748, avg_loss=0.07447]\n","Step 490394  [4.916 sec/step, loss=0.06626, avg_loss=0.07437]\n","Step 490395  [4.894 sec/step, loss=0.07606, avg_loss=0.07435]\n","Step 490396  [4.871 sec/step, loss=0.06432, avg_loss=0.07425]\n","Step 490397  [4.920 sec/step, loss=0.07844, avg_loss=0.07428]\n","Step 490398  [4.925 sec/step, loss=0.07260, avg_loss=0.07426]\n","Generated 32 batches of size 16 in 11.409 sec\n","Step 490399  [5.071 sec/step, loss=0.07697, avg_loss=0.07430]\n","Step 490400  [5.065 sec/step, loss=0.07611, avg_loss=0.07428]\n","Writing summary at step: 490400\n","Step 490401  [5.067 sec/step, loss=0.06766, avg_loss=0.07428]\n","Step 490402  [5.106 sec/step, loss=0.07650, avg_loss=0.07439]\n","Step 490403  [5.103 sec/step, loss=0.07823, avg_loss=0.07445]\n","Step 490404  [5.065 sec/step, loss=0.07048, avg_loss=0.07439]\n","Step 490405  [5.028 sec/step, loss=0.07807, avg_loss=0.07438]\n","Step 490406  [4.930 sec/step, loss=0.07253, avg_loss=0.07435]\n","Step 490407  [4.914 sec/step, loss=0.07695, avg_loss=0.07433]\n","Step 490408  [4.940 sec/step, loss=0.07885, avg_loss=0.07440]\n","Step 490409  [5.019 sec/step, loss=0.07808, avg_loss=0.07442]\n","Step 490410  [5.043 sec/step, loss=0.07575, avg_loss=0.07450]\n","Step 490411  [4.989 sec/step, loss=0.06659, avg_loss=0.07437]\n","Step 490412  [4.976 sec/step, loss=0.07564, avg_loss=0.07434]\n","Step 490413  [4.988 sec/step, loss=0.07277, avg_loss=0.07446]\n","Step 490414  [4.986 sec/step, loss=0.07112, avg_loss=0.07447]\n","Step 490415  [5.028 sec/step, loss=0.07862, avg_loss=0.07451]\n","Step 490416  [5.053 sec/step, loss=0.07829, avg_loss=0.07453]\n","Step 490417  [5.020 sec/step, loss=0.07592, avg_loss=0.07452]\n","Step 490418  [4.992 sec/step, loss=0.07167, avg_loss=0.07448]\n","Step 490419  [4.996 sec/step, loss=0.07503, avg_loss=0.07446]\n","Step 490420  [5.034 sec/step, loss=0.07721, avg_loss=0.07457]\n","Step 490421  [5.008 sec/step, loss=0.07590, avg_loss=0.07456]\n","Step 490422  [5.017 sec/step, loss=0.07340, avg_loss=0.07460]\n","Step 490423  [5.031 sec/step, loss=0.07302, avg_loss=0.07470]\n","Step 490424  [5.026 sec/step, loss=0.07182, avg_loss=0.07470]\n","Step 490425  [5.012 sec/step, loss=0.07025, avg_loss=0.07467]\n","Step 490426  [5.009 sec/step, loss=0.07589, avg_loss=0.07465]\n","Step 490427  [4.996 sec/step, loss=0.07465, avg_loss=0.07464]\n","Step 490428  [4.911 sec/step, loss=0.07432, avg_loss=0.07458]\n","Step 490429  [4.828 sec/step, loss=0.06846, avg_loss=0.07448]\n","Generated 32 batches of size 16 in 9.656 sec\n","Step 490430  [4.924 sec/step, loss=0.07802, avg_loss=0.07459]\n","Step 490431  [4.970 sec/step, loss=0.07718, avg_loss=0.07460]\n","Step 490432  [4.942 sec/step, loss=0.06665, avg_loss=0.07449]\n","Step 490433  [4.936 sec/step, loss=0.07789, avg_loss=0.07449]\n","Step 490434  [4.902 sec/step, loss=0.07644, avg_loss=0.07447]\n","Step 490435  [4.865 sec/step, loss=0.07565, avg_loss=0.07448]\n","Step 490436  [4.866 sec/step, loss=0.07961, avg_loss=0.07449]\n","Step 490437  [4.908 sec/step, loss=0.07414, avg_loss=0.07447]\n","Step 490438  [4.897 sec/step, loss=0.06535, avg_loss=0.07443]\n","Step 490439  [4.986 sec/step, loss=0.07699, avg_loss=0.07447]\n","Step 490440  [4.957 sec/step, loss=0.07372, avg_loss=0.07442]\n","Step 490441  [4.974 sec/step, loss=0.07607, avg_loss=0.07441]\n","Step 490442  [4.919 sec/step, loss=0.06709, avg_loss=0.07430]\n","Step 490443  [4.958 sec/step, loss=0.07841, avg_loss=0.07435]\n","Step 490444  [4.908 sec/step, loss=0.06652, avg_loss=0.07425]\n","Step 490445  [4.904 sec/step, loss=0.07562, avg_loss=0.07424]\n","Step 490446  [4.951 sec/step, loss=0.07823, avg_loss=0.07437]\n","Step 490447  [4.941 sec/step, loss=0.07142, avg_loss=0.07432]\n","Step 490448  [4.872 sec/step, loss=0.07742, avg_loss=0.07436]\n","Step 490449  [4.866 sec/step, loss=0.07359, avg_loss=0.07434]\n","Step 490450  [4.892 sec/step, loss=0.07864, avg_loss=0.07440]\n","Step 490451  [4.843 sec/step, loss=0.06793, avg_loss=0.07430]\n","Step 490452  [4.850 sec/step, loss=0.07068, avg_loss=0.07434]\n","Step 490453  [4.833 sec/step, loss=0.07480, avg_loss=0.07434]\n","Step 490454  [4.799 sec/step, loss=0.07388, avg_loss=0.07429]\n","Step 490455  [4.852 sec/step, loss=0.07915, avg_loss=0.07437]\n","Step 490456  [4.812 sec/step, loss=0.06586, avg_loss=0.07426]\n","Step 490457  [4.802 sec/step, loss=0.07670, avg_loss=0.07425]\n","Step 490458  [4.767 sec/step, loss=0.07738, avg_loss=0.07425]\n","Step 490459  [4.759 sec/step, loss=0.07256, avg_loss=0.07423]\n","Step 490460  [4.834 sec/step, loss=0.07856, avg_loss=0.07433]\n","Step 490461  [4.826 sec/step, loss=0.07570, avg_loss=0.07431]\n","Step 490462  [4.880 sec/step, loss=0.07632, avg_loss=0.07435]\n","Generated 32 batches of size 16 in 9.743 sec\n","Step 490463  [4.902 sec/step, loss=0.07626, avg_loss=0.07437]\n","Step 490464  [4.874 sec/step, loss=0.06335, avg_loss=0.07425]\n","Step 490465  [4.888 sec/step, loss=0.07696, avg_loss=0.07427]\n","Step 490466  [4.937 sec/step, loss=0.07776, avg_loss=0.07433]\n","Step 490467  [4.851 sec/step, loss=0.07525, avg_loss=0.07430]\n","Step 490468  [4.805 sec/step, loss=0.07294, avg_loss=0.07425]\n","Step 490469  [4.802 sec/step, loss=0.07686, avg_loss=0.07426]\n","Step 490470  [4.829 sec/step, loss=0.07819, avg_loss=0.07431]\n","Step 490471  [4.861 sec/step, loss=0.07684, avg_loss=0.07440]\n","Step 490472  [4.840 sec/step, loss=0.07412, avg_loss=0.07435]\n","Step 490473  [4.889 sec/step, loss=0.07860, avg_loss=0.07449]\n","Step 490474  [4.895 sec/step, loss=0.07192, avg_loss=0.07449]\n","Step 490475  [4.855 sec/step, loss=0.06634, avg_loss=0.07438]\n","Step 490476  [4.845 sec/step, loss=0.07166, avg_loss=0.07434]\n","Step 490477  [4.864 sec/step, loss=0.07761, avg_loss=0.07433]\n","Step 490478  [4.870 sec/step, loss=0.07627, avg_loss=0.07437]\n","Step 490479  [4.888 sec/step, loss=0.07749, avg_loss=0.07440]\n","Step 490480  [4.879 sec/step, loss=0.06775, avg_loss=0.07437]\n","Step 490481  [4.862 sec/step, loss=0.07179, avg_loss=0.07433]\n","Step 490482  [4.819 sec/step, loss=0.07237, avg_loss=0.07426]\n","Step 490483  [4.842 sec/step, loss=0.07647, avg_loss=0.07430]\n","Step 490484  [4.849 sec/step, loss=0.07691, avg_loss=0.07431]\n","Step 490485  [4.817 sec/step, loss=0.07447, avg_loss=0.07427]\n","Step 490486  [4.811 sec/step, loss=0.07837, avg_loss=0.07429]\n","Step 490487  [4.808 sec/step, loss=0.07691, avg_loss=0.07427]\n","Step 490488  [4.810 sec/step, loss=0.07594, avg_loss=0.07427]\n","Step 490489  [4.788 sec/step, loss=0.07840, avg_loss=0.07428]\n","Step 490490  [4.898 sec/step, loss=0.07737, avg_loss=0.07438]\n","Step 490491  [4.888 sec/step, loss=0.07625, avg_loss=0.07439]\n","Step 490492  [4.876 sec/step, loss=0.06883, avg_loss=0.07436]\n","Step 490493  [4.908 sec/step, loss=0.07314, avg_loss=0.07432]\n","Step 490494  [4.927 sec/step, loss=0.06732, avg_loss=0.07433]\n","Generated 32 batches of size 16 in 9.769 sec\n","Step 490495  [4.963 sec/step, loss=0.07640, avg_loss=0.07433]\n","Step 490496  [4.971 sec/step, loss=0.07062, avg_loss=0.07440]\n","Step 490497  [4.968 sec/step, loss=0.07956, avg_loss=0.07441]\n","Step 490498  [4.957 sec/step, loss=0.07382, avg_loss=0.07442]\n","Step 490499  [4.824 sec/step, loss=0.07536, avg_loss=0.07440]\n","Step 490500  [4.846 sec/step, loss=0.07903, avg_loss=0.07443]\n","Writing summary at step: 490500\n","Step 490501  [4.838 sec/step, loss=0.06292, avg_loss=0.07439]\n","Step 490502  [4.829 sec/step, loss=0.07575, avg_loss=0.07438]\n","Step 490503  [4.833 sec/step, loss=0.07624, avg_loss=0.07436]\n","Step 490504  [4.875 sec/step, loss=0.07849, avg_loss=0.07444]\n","Step 490505  [4.845 sec/step, loss=0.07272, avg_loss=0.07439]\n","Step 490506  [4.938 sec/step, loss=0.07640, avg_loss=0.07442]\n","Step 490507  [4.917 sec/step, loss=0.07628, avg_loss=0.07442]\n","Step 490508  [4.891 sec/step, loss=0.07574, avg_loss=0.07439]\n","Step 490509  [4.783 sec/step, loss=0.06642, avg_loss=0.07427]\n","Step 490510  [4.801 sec/step, loss=0.07944, avg_loss=0.07431]\n","Step 490511  [4.859 sec/step, loss=0.07791, avg_loss=0.07442]\n","Step 490512  [4.872 sec/step, loss=0.07843, avg_loss=0.07445]\n","Step 490513  [4.883 sec/step, loss=0.07637, avg_loss=0.07448]\n","Step 490514  [4.893 sec/step, loss=0.07435, avg_loss=0.07452]\n","Step 490515  [4.846 sec/step, loss=0.07200, avg_loss=0.07445]\n","Step 490516  [4.836 sec/step, loss=0.07925, avg_loss=0.07446]\n","Step 490517  [4.858 sec/step, loss=0.07553, avg_loss=0.07446]\n","Step 490518  [4.862 sec/step, loss=0.07374, avg_loss=0.07448]\n","Step 490519  [4.882 sec/step, loss=0.07896, avg_loss=0.07452]\n","Step 490520  [4.877 sec/step, loss=0.07578, avg_loss=0.07450]\n","Step 490521  [4.879 sec/step, loss=0.07749, avg_loss=0.07452]\n","Step 490522  [4.890 sec/step, loss=0.07562, avg_loss=0.07454]\n","Step 490523  [4.882 sec/step, loss=0.06934, avg_loss=0.07450]\n","Step 490524  [4.883 sec/step, loss=0.06091, avg_loss=0.07439]\n","Step 490525  [4.882 sec/step, loss=0.06621, avg_loss=0.07435]\n","Generated 32 batches of size 16 in 10.757 sec\n","Step 490526  [4.964 sec/step, loss=0.07868, avg_loss=0.07438]\n","Step 490527  [4.944 sec/step, loss=0.06316, avg_loss=0.07427]\n","Step 490528  [4.942 sec/step, loss=0.07354, avg_loss=0.07426]\n","Step 490529  [4.958 sec/step, loss=0.07195, avg_loss=0.07429]\n","Step 490530  [4.905 sec/step, loss=0.07830, avg_loss=0.07430]\n","Step 490531  [4.855 sec/step, loss=0.07531, avg_loss=0.07428]\n","Step 490532  [4.867 sec/step, loss=0.06965, avg_loss=0.07431]\n","Step 490533  [4.838 sec/step, loss=0.07275, avg_loss=0.07426]\n","Step 490534  [4.916 sec/step, loss=0.07694, avg_loss=0.07426]\n","Step 490535  [4.953 sec/step, loss=0.07755, avg_loss=0.07428]\n","Step 490536  [4.932 sec/step, loss=0.07654, avg_loss=0.07425]\n","Step 490537  [4.888 sec/step, loss=0.07546, avg_loss=0.07426]\n","Step 490538  [4.912 sec/step, loss=0.07377, avg_loss=0.07435]\n","Step 490539  [4.816 sec/step, loss=0.07232, avg_loss=0.07430]\n","Step 490540  [4.823 sec/step, loss=0.07690, avg_loss=0.07433]\n","Step 490541  [4.826 sec/step, loss=0.07812, avg_loss=0.07435]\n","Step 490542  [4.874 sec/step, loss=0.07923, avg_loss=0.07447]\n","Step 490543  [4.851 sec/step, loss=0.07605, avg_loss=0.07445]\n","Step 490544  [4.850 sec/step, loss=0.06678, avg_loss=0.07445]\n","Step 490545  [4.882 sec/step, loss=0.07934, avg_loss=0.07449]\n","Step 490546  [4.851 sec/step, loss=0.07270, avg_loss=0.07443]\n","Step 490547  [4.861 sec/step, loss=0.07591, avg_loss=0.07448]\n","Step 490548  [4.904 sec/step, loss=0.07919, avg_loss=0.07450]\n","Step 490549  [4.910 sec/step, loss=0.07253, avg_loss=0.07449]\n","Step 490550  [4.855 sec/step, loss=0.06680, avg_loss=0.07437]\n","Step 490551  [4.885 sec/step, loss=0.07735, avg_loss=0.07446]\n","Step 490552  [4.894 sec/step, loss=0.07180, avg_loss=0.07447]\n","Step 490553  [4.917 sec/step, loss=0.07861, avg_loss=0.07451]\n","Step 490554  [4.940 sec/step, loss=0.07815, avg_loss=0.07455]\n","Step 490555  [4.889 sec/step, loss=0.07041, avg_loss=0.07447]\n","Step 490556  [4.904 sec/step, loss=0.07310, avg_loss=0.07454]\n","Generated 32 batches of size 16 in 10.039 sec\n","Step 490557  [4.982 sec/step, loss=0.07690, avg_loss=0.07454]\n","Step 490558  [4.955 sec/step, loss=0.07449, avg_loss=0.07451]\n","Step 490559  [4.951 sec/step, loss=0.07040, avg_loss=0.07449]\n","Step 490560  [4.907 sec/step, loss=0.07744, avg_loss=0.07448]\n","Step 490561  [4.911 sec/step, loss=0.07530, avg_loss=0.07448]\n","Step 490562  [4.902 sec/step, loss=0.07894, avg_loss=0.07450]\n","Step 490563  [4.866 sec/step, loss=0.06227, avg_loss=0.07436]\n","Step 490564  [4.871 sec/step, loss=0.06067, avg_loss=0.07433]\n","Step 490565  [4.855 sec/step, loss=0.07632, avg_loss=0.07433]\n","Step 490566  [4.819 sec/step, loss=0.07661, avg_loss=0.07432]\n","Step 490567  [4.845 sec/step, loss=0.07808, avg_loss=0.07435]\n","Step 490568  [4.940 sec/step, loss=0.07632, avg_loss=0.07438]\n","Step 490569  [4.918 sec/step, loss=0.06561, avg_loss=0.07427]\n","Step 490570  [4.912 sec/step, loss=0.07791, avg_loss=0.07426]\n","Step 490571  [4.906 sec/step, loss=0.07643, avg_loss=0.07426]\n","Step 490572  [4.897 sec/step, loss=0.07191, avg_loss=0.07424]\n","Step 490573  [4.871 sec/step, loss=0.07298, avg_loss=0.07418]\n","Step 490574  [4.890 sec/step, loss=0.07584, avg_loss=0.07422]\n","Step 490575  [4.974 sec/step, loss=0.07940, avg_loss=0.07435]\n","Step 490576  [4.967 sec/step, loss=0.06988, avg_loss=0.07433]\n","Step 490577  [4.946 sec/step, loss=0.07842, avg_loss=0.07434]\n","Step 490578  [4.955 sec/step, loss=0.07663, avg_loss=0.07435]\n","Step 490579  [4.944 sec/step, loss=0.07699, avg_loss=0.07434]\n","Step 490580  [4.972 sec/step, loss=0.07608, avg_loss=0.07442]\n","Step 490581  [4.959 sec/step, loss=0.06184, avg_loss=0.07432]\n","Step 490582  [4.966 sec/step, loss=0.07282, avg_loss=0.07433]\n","Step 490583  [4.982 sec/step, loss=0.07830, avg_loss=0.07435]\n","Step 490584  [4.966 sec/step, loss=0.07170, avg_loss=0.07429]\n","Step 490585  [4.953 sec/step, loss=0.07119, avg_loss=0.07426]\n","Step 490586  [4.963 sec/step, loss=0.07910, avg_loss=0.07427]\n","Step 490587  [4.931 sec/step, loss=0.07452, avg_loss=0.07425]\n","Step 490588  [4.949 sec/step, loss=0.07821, avg_loss=0.07427]\n","Step 490589  [4.927 sec/step, loss=0.06806, avg_loss=0.07416]\n","Generated 32 batches of size 16 in 9.991 sec\n","Step 490590  [4.894 sec/step, loss=0.07869, avg_loss=0.07418]\n","Step 490591  [4.890 sec/step, loss=0.07446, avg_loss=0.07416]\n","Step 490592  [4.912 sec/step, loss=0.07713, avg_loss=0.07424]\n","Step 490593  [4.904 sec/step, loss=0.07906, avg_loss=0.07430]\n","Step 490594  [4.936 sec/step, loss=0.07670, avg_loss=0.07440]\n","Step 490595  [4.891 sec/step, loss=0.07502, avg_loss=0.07438]\n","Step 490596  [4.896 sec/step, loss=0.07323, avg_loss=0.07441]\n","Step 490597  [4.817 sec/step, loss=0.06893, avg_loss=0.07430]\n","Step 490598  [4.820 sec/step, loss=0.07219, avg_loss=0.07429]\n","Step 490599  [4.807 sec/step, loss=0.07255, avg_loss=0.07426]\n","Step 490600  [4.801 sec/step, loss=0.07701, avg_loss=0.07424]\n","Writing summary at step: 490600\n","Step 490601  [4.807 sec/step, loss=0.06745, avg_loss=0.07428]\n","Step 490602  [4.889 sec/step, loss=0.07727, avg_loss=0.07430]\n","Step 490603  [4.875 sec/step, loss=0.07579, avg_loss=0.07429]\n","Step 490604  [4.850 sec/step, loss=0.07712, avg_loss=0.07428]\n","Step 490605  [4.845 sec/step, loss=0.06965, avg_loss=0.07425]\n","Step 490606  [4.776 sec/step, loss=0.07615, avg_loss=0.07425]\n","Step 490607  [4.800 sec/step, loss=0.07883, avg_loss=0.07427]\n","Step 490608  [4.819 sec/step, loss=0.07719, avg_loss=0.07429]\n","Step 490609  [4.843 sec/step, loss=0.07420, avg_loss=0.07436]\n","Step 490610  [4.825 sec/step, loss=0.07597, avg_loss=0.07433]\n","Step 490611  [4.797 sec/step, loss=0.07700, avg_loss=0.07432]\n","Step 490612  [4.777 sec/step, loss=0.07501, avg_loss=0.07429]\n","Step 490613  [4.743 sec/step, loss=0.06692, avg_loss=0.07419]\n","Step 490614  [4.766 sec/step, loss=0.07780, avg_loss=0.07423]\n","Step 490615  [4.766 sec/step, loss=0.07161, avg_loss=0.07422]\n","Step 490616  [4.770 sec/step, loss=0.07873, avg_loss=0.07422]\n","Step 490617  [4.731 sec/step, loss=0.06548, avg_loss=0.07412]\n","Step 490618  [4.767 sec/step, loss=0.07880, avg_loss=0.07417]\n","Step 490619  [4.739 sec/step, loss=0.07691, avg_loss=0.07415]\n","Step 490620  [4.768 sec/step, loss=0.07287, avg_loss=0.07412]\n","Generated 32 batches of size 16 in 9.840 sec\n","Step 490621  [4.765 sec/step, loss=0.07470, avg_loss=0.07409]\n","Step 490622  [4.755 sec/step, loss=0.07329, avg_loss=0.07407]\n","Step 490623  [4.776 sec/step, loss=0.07593, avg_loss=0.07413]\n","Step 490624  [4.851 sec/step, loss=0.07879, avg_loss=0.07431]\n","Step 490625  [4.842 sec/step, loss=0.06327, avg_loss=0.07428]\n","Step 490626  [4.741 sec/step, loss=0.07263, avg_loss=0.07422]\n","Step 490627  [4.743 sec/step, loss=0.06649, avg_loss=0.07425]\n","Step 490628  [4.786 sec/step, loss=0.07755, avg_loss=0.07429]\n","Step 490629  [4.789 sec/step, loss=0.07260, avg_loss=0.07430]\n","Step 490630  [4.777 sec/step, loss=0.07588, avg_loss=0.07428]\n","Step 490631  [4.794 sec/step, loss=0.07645, avg_loss=0.07429]\n","Step 490632  [4.810 sec/step, loss=0.07637, avg_loss=0.07436]\n","Step 490633  [4.840 sec/step, loss=0.07806, avg_loss=0.07441]\n","Step 490634  [4.786 sec/step, loss=0.07898, avg_loss=0.07443]\n","Step 490635  [4.782 sec/step, loss=0.07892, avg_loss=0.07444]\n","Step 490636  [4.763 sec/step, loss=0.07198, avg_loss=0.07440]\n","Step 490637  [4.737 sec/step, loss=0.06205, avg_loss=0.07426]\n","Step 490638  [4.777 sec/step, loss=0.07881, avg_loss=0.07431]\n","Step 490639  [4.775 sec/step, loss=0.06920, avg_loss=0.07428]\n","Step 490640  [4.761 sec/step, loss=0.07278, avg_loss=0.07424]\n","Step 490641  [4.748 sec/step, loss=0.07291, avg_loss=0.07419]\n","Step 490642  [4.735 sec/step, loss=0.07764, avg_loss=0.07417]\n","Step 490643  [4.752 sec/step, loss=0.07918, avg_loss=0.07420]\n","Step 490644  [4.748 sec/step, loss=0.06645, avg_loss=0.07420]\n","Step 490645  [4.774 sec/step, loss=0.07946, avg_loss=0.07420]\n","Step 490646  [4.781 sec/step, loss=0.07500, avg_loss=0.07423]\n","Step 490647  [4.764 sec/step, loss=0.07220, avg_loss=0.07419]\n","Step 490648  [4.737 sec/step, loss=0.07864, avg_loss=0.07418]\n","Step 490649  [4.756 sec/step, loss=0.07581, avg_loss=0.07422]\n","Step 490650  [4.787 sec/step, loss=0.07629, avg_loss=0.07431]\n","Step 490651  [4.794 sec/step, loss=0.07818, avg_loss=0.07432]\n","Step 490652  [4.800 sec/step, loss=0.06747, avg_loss=0.07428]\n","Generated 32 batches of size 16 in 9.914 sec\n","Step 490653  [4.824 sec/step, loss=0.07670, avg_loss=0.07426]\n","Step 490654  [4.890 sec/step, loss=0.07639, avg_loss=0.07424]\n","Step 490655  [4.887 sec/step, loss=0.06883, avg_loss=0.07422]\n","Step 490656  [4.908 sec/step, loss=0.07662, avg_loss=0.07426]\n","Step 490657  [4.830 sec/step, loss=0.07681, avg_loss=0.07426]\n","Step 490658  [4.823 sec/step, loss=0.07324, avg_loss=0.07424]\n","Step 490659  [4.837 sec/step, loss=0.07653, avg_loss=0.07431]\n","Step 490660  [4.801 sec/step, loss=0.06689, avg_loss=0.07420]\n","Step 490661  [4.774 sec/step, loss=0.07153, avg_loss=0.07416]\n","Step 490662  [4.750 sec/step, loss=0.07621, avg_loss=0.07414]\n","Step 490663  [4.769 sec/step, loss=0.07163, avg_loss=0.07423]\n","Step 490664  [4.772 sec/step, loss=0.07007, avg_loss=0.07432]\n","Step 490665  [4.789 sec/step, loss=0.07689, avg_loss=0.07433]\n","Step 490666  [4.811 sec/step, loss=0.07677, avg_loss=0.07433]\n","Step 490667  [4.772 sec/step, loss=0.07415, avg_loss=0.07429]\n","Step 490668  [4.692 sec/step, loss=0.07697, avg_loss=0.07430]\n","Step 490669  [4.711 sec/step, loss=0.07415, avg_loss=0.07438]\n","Step 490670  [4.708 sec/step, loss=0.07446, avg_loss=0.07435]\n","Step 490671  [4.700 sec/step, loss=0.07308, avg_loss=0.07432]\n","Step 490672  [4.728 sec/step, loss=0.07848, avg_loss=0.07438]\n","Step 490673  [4.785 sec/step, loss=0.07737, avg_loss=0.07442]\n","Step 490674  [4.776 sec/step, loss=0.07575, avg_loss=0.07442]\n","Step 490675  [4.759 sec/step, loss=0.07748, avg_loss=0.07440]\n","Step 490676  [4.767 sec/step, loss=0.07471, avg_loss=0.07445]\n","Step 490677  [4.729 sec/step, loss=0.06662, avg_loss=0.07433]\n","Step 490678  [4.716 sec/step, loss=0.07269, avg_loss=0.07430]\n","Step 490679  [4.742 sec/step, loss=0.07844, avg_loss=0.07431]\n","Step 490680  [4.753 sec/step, loss=0.07851, avg_loss=0.07433]\n","Step 490681  [4.751 sec/step, loss=0.06629, avg_loss=0.07438]\n","Step 490682  [4.738 sec/step, loss=0.06907, avg_loss=0.07434]\n","Step 490683  [4.685 sec/step, loss=0.06345, avg_loss=0.07419]\n","Generated 32 batches of size 16 in 10.063 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o6ZJgJDyS0UQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596540300416,"user_tz":-180,"elapsed":114578,"user":{"displayName":"Mohammed Buallay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5kKjTotsiVfFyh_UBKjF5IzlejzIE4inAGqASEA=s64","userId":"12854686241086794145"}},"outputId":"9de2233c-b827-4b12-8ca8-bee5fb1e57ac"},"source":["!python eval.py --checkpoint logs-tacotron/model.ckpt-491000"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Hyperparameters:\n","  adam_beta1: 0.9\n","  adam_beta2: 0.999\n","  attention_depth: 256\n","  batch_size: 16\n","  cleaners: english_cleaners\n","  decay_learning_rate: True\n","  decoder_depth: 256\n","  embed_depth: 256\n","  encoder_depth: 256\n","  frame_length_ms: 50\n","  frame_shift_ms: 12.5\n","  griffin_lim_iters: 60\n","  initial_learning_rate: 0.002\n","  max_iters: 800\n","  min_level_db: -100\n","  num_freq: 1025\n","  num_mels: 80\n","  outputs_per_step: 5\n","  postnet_depth: 256\n","  power: 1.5\n","  preemphasis: 0.97\n","  prenet_depths: [256, 128]\n","  ref_level_db: 20\n","  sample_rate: 20000\n","  use_cmudict: False\n","Constructing model: tacotron\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/synthesizer.py:14: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/synthesizer.py:16: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/tacotron.py:40: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:10: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:11: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dropout instead.\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:106: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv1D` instead.\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:107: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:52: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.MaxPooling1D instead.\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:75: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/modules.py:79: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/models/tacotron.py:68: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:Entity <bound method ConcatOutputAndAttentionWrapper.call of <models.rnn_wrappers.ConcatOutputAndAttentionWrapper object at 0x7f935bbedf98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method DecoderPrenetWrapper.call of <models.rnn_wrappers.DecoderPrenetWrapper object at 0x7f935bd36cf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","Initialized Tacotron model. Dimensions: \n","  embedding:               256\n","  prenet out:              128\n","  encoder out:             256\n","  attention out:           256\n","  concat attn & out:       512\n","  decoder cell out:        256\n","  decoder out (5 frames):  400\n","  decoder out (1 frame):   80\n","  postnet out:             256\n","  linear out:              1025\n","Loading checkpoint: logs-tacotron/model.ckpt-491000\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/synthesizer.py:22: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/synthesizer.py:23: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/trump_public/synthesizer.py:24: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","Synthesizing: logs-tacotron/eval-491000-0.wav\n","Synthesizing: logs-tacotron/eval-491000-1.wav\n","Synthesizing: logs-tacotron/eval-491000-2.wav\n","Synthesizing: logs-tacotron/eval-491000-3.wav\n","Synthesizing: logs-tacotron/eval-491000-4.wav\n","Synthesizing: logs-tacotron/eval-491000-5.wav\n","Synthesizing: logs-tacotron/eval-491000-6.wav\n","Synthesizing: logs-tacotron/eval-491000-7.wav\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BiS36gE38c12","colab_type":"code","colab":{}},"source":["!ls /content/drive/My*Drive/trump_public/logs-tacotron"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EFcQI6hj-bq8","colab_type":"code","colab":{}},"source":["sentences = [\n","  # From July 8, 2017 New York Times:\n","  'Scientists at the CERN laboratory say they have discovered a new particle.',\n","  'There’s a way to measure the acute emotional intelligence that has never gone out of style.',\n","  'President Trump met with other leaders at the Group of 20 conference.',\n","  'The Senate\\'s bill to repeal and replace the Affordable Care Act is now imperiled.',\n","  # From Google's Tacotron example page:\n","  'Generative adversarial network or variational auto-encoder.',\n","  'The buses aren\\'t the problem, they actually provide a solution.',\n","  'Does the quick brown fox jump over the lazy dog?',\n","  'Talib Kweli confirmed to AllHipHop that he will be releasing an album in the next year.',\n","]"],"execution_count":null,"outputs":[]}]}